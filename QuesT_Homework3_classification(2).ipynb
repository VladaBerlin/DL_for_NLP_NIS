{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0fOWhqwW-AT",
        "outputId": "b2cb1391-5ccb-448b-c34b-4e9a38720e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting sklearn\n",
            "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "#!pip install pandas\n",
        "#!pip install torch\n",
        "#!pip install nltk\n",
        "#!pip install tqdm\n",
        "#!pip install seaborn\n",
        "#!pip install numpy\n",
        "#!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wugeOHW-AV",
        "outputId": "cc7e63bf-8143-4dee-8a49-a17c66d9cc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9XIrxSmW-AX"
      },
      "source": [
        "# Скачиваем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep1FB3IBW-AY",
        "outputId": "eb1e36d8-838c-443f-b20d-9fdd3d5ead9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-09 15:24:25--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M  63.9MB/s    in 0.4s    \n",
            "\n",
            "2023-12-09 15:24:26 (63.9 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWA7IClKW-Aa"
      },
      "outputs": [],
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJpFTPpsW-Ac",
        "outputId": "dab56b1e-c747-4630-e136-6206a9d9564c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28052\n",
            "-rw-r--r-- 1 root root 28717126 Dec  9 15:24 answers_subsample.csv\n",
            "drwxr-xr-x 1 root root     4096 Dec  4 14:27 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "qmzaEwy9W-Ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "BbDKxq4EW-Ag"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hcAdsbS7W-Ai",
        "outputId": "692fb86e-96cc-4131-e833-21d97a03a2d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c527919-b96d-4c50-b1f3-e060f29b9f1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c527919-b96d-4c50-b1f3-e060f29b9f1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c527919-b96d-4c50-b1f3-e060f29b9f1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c527919-b96d-4c50-b1f3-e060f29b9f1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1cc3757-0e37-4ccb-a5fc-d6e9f1419d75\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1cc3757-0e37-4ccb-a5fc-d6e9f1419d75')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1cc3757-0e37-4ccb-a5fc-d6e9f1419d75 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tXLjfsW-Aj",
        "outputId": "626b22c6-ec6a-4e67-c2ff-75e8241f0ba1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfHbifWIW-Al"
      },
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVhCzM3LW-Al",
        "outputId": "a746847c-0a72-4043-ce48-c41e8e0d561c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-09 15:24:49--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.35.7.38, 13.35.7.50, 13.35.7.82, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.35.7.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G   130MB/s    in 13s     \n",
            "\n",
            "2023-12-09 15:25:02 (96.2 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJcT1qPZW-An",
        "outputId": "258994fe-da3d-47c1-bb5f-667ce9f0335a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4458144\n",
            "-rw-r--r-- 1 root root   28717126 Dec  9 15:24 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Dec  4 14:27 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "M0lwyZUFW-Ap"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "QQpX51Y4W-Aq"
      },
      "outputs": [],
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "\n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyI2erCDW-Ar",
        "outputId": "eb0caa97-36cf-4c3f-accd-1d2227266234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:03<00:00, 74400.04it/s]\n"
          ]
        }
      ],
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "\n",
        "    words = process_text(text)\n",
        "\n",
        "    lengths.append(len(words))\n",
        "\n",
        "    for word in words:\n",
        "\n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "FGzDm0ptW-At"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "iZBR-aYDW-Av",
        "outputId": "d27e148a-115f-488f-c14a-e553e1eb3337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-97-71ec2d8d2434>:5: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(lengths)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Распределение длин слов в текстах'}, xlabel='Длина предложения', ylabel='Доля'>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OBzmPqXIW-Aw",
        "outputId": "177e751c-b778-4664-b65c-afe204d8222b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths\n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSer_0bW-Ay",
        "outputId": "8494677d-53b4-42ae-b3a7-aa185a7db7be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "len(word2freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "szg6XD3EW-Az",
        "outputId": "031b94ba-16a5-4593-c8d2-398027e89aff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZbOg0FqW-A1"
      },
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "T1Yx_qr-W-A2"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLEgfnaWW-A4",
        "outputId": "a1f9675f-411f-487f-cb51-1845bcd96e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   0%|          | 0/107000 [03:25<?, ?it/s]\n",
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:19<00:00, 25281.36it/s]\n"
          ]
        }
      ],
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "\n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "\n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "\n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYJMzgpnW-A7",
        "outputId": "f076138d-eba4-42ee-9bcd-28445f5ce982"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "len(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE06fafiW-A8",
        "outputId": "da4c5130-4ef0-4c96-f3e3-c86ba846d959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ],
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFPNApUjW-A9"
      },
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "_fo1fB6JW-A-"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEKAjCg3W-BA"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "D19pDyQBW-BA"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "Yxsxr7edW-BB"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZy0lKr2W-BC",
        "outputId": "bbac7c1e-07a9-4fdd-cbdd-92e9f64a7d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.09 s ± 272 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s611e34SW-BE"
      },
      "source": [
        "# А что GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjFlWdgtW-BE",
        "outputId": "9a2decb0-50e3-42aa-d979-d0b80171f6ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ],
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "jaMMD5CDW-BG"
      },
      "outputs": [],
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "GeQCiSYdW-BH"
      },
      "outputs": [],
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "S_qUdMcbW-BJ"
      },
      "outputs": [],
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSUQmRgtW-BK",
        "outputId": "42cdd6fd-a9c0-424f-ef88-29298a770112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 ms ± 61.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPvqNWkQW-BM"
      },
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaPKGO5aW-BN"
      },
      "outputs": [],
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NX5HHDOW-BO"
      },
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKr22rklW-BP"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bny8SvCgW-BQ"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "vc-bLok2W-BQ"
      },
      "outputs": [],
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHpit-1tW-BR",
        "outputId": "38b1f758-f7d3-4d9f-a2ad-7108c257a1b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "ru_WzGSJW-BS"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHdBavTWW-BT",
        "outputId": "95eb56b9-f512-4d81-cb8e-1375dc31d3e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcxv55j7W-BV",
        "outputId": "493055a3-e5b6-4a5c-fa37-fdb74cab61b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmJt6cqkW-BW"
      },
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyM8Xl24W-BX",
        "outputId": "a3b4c137-6ca2-4532-9326-0c9c0250d00c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grPNMjEZW-BY"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "btJ-ApiOW-BY"
      },
      "outputs": [],
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIYff7YyW-Bb"
      },
      "outputs": [],
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tVn6YKLW-Bd",
        "outputId": "2f0bf8c3-b3e1-4ee8-d6d8-5a0b28f1eef8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N4w6-iWW-Be",
        "outputId": "d011374e-9a89-4f1d-ab9d-c0867c4c0354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-C3_phaW-Bf",
        "outputId": "2b88bb76-9629-4351-cd2f-34afc0546935"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stBQ3yhqW-Bi"
      },
      "source": [
        "# Подготовим данные в DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "vPX_m5M4W-Bi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV76BdN0W-Bj",
        "outputId": "4cf39646-7b48-4aca-f57d-c9bd167dbbf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "'UNK' in word2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "INB_dPAnW-Bk",
        "outputId": "c6a2e5b2-e294-49c7-c28e-b679fb243b14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bb08cca-25ac-420f-9943-b05c9b3465ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bb08cca-25ac-420f-9943-b05c9b3465ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bb08cca-25ac-420f-9943-b05c9b3465ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bb08cca-25ac-420f-9943-b05c9b3465ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-870709d4-d026-4132-93ca-0643d27f8db4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-870709d4-d026-4132-93ca-0643d27f8db4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-870709d4-d026-4132-93ca-0643d27f8db4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qv1mKAeW-Bl"
      },
      "source": [
        "# Замапим категории в индексы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "iHeFzZe1W-Bl"
      },
      "outputs": [],
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x9QhXYW-Bn",
        "outputId": "06a89ecb-f64e-4a0f-ff6b-61f0d6c96245"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'law': 1, 'love': 2, 'relax': 3, 'food': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "cat_mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "ef--8SWbW-Bo"
      },
      "outputs": [],
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc48ALg_W-Bp"
      },
      "source": [
        "# Читалка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFIQEv6nvE4c"
      },
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "ZkX8SC_sW-Bp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "class WordData(Dataset):\n",
        "\n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "\n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "\n",
        "        self.load(x_data, verbose=verbose)\n",
        "\n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "\n",
        "        # Место для вашей предобработки\n",
        "\n",
        "        #words = wordpunct_tokenize(text.lower())\n",
        "        words = re.findall('\\w+', text.lower())\n",
        "\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        return words\n",
        "\n",
        "    def load(self, data, verbose=True):\n",
        "\n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "\n",
        "        for text in data_iterator:\n",
        "\n",
        "            words = self.process_text(text)\n",
        "\n",
        "            indexed_words = self.indexing(words)\n",
        "\n",
        "            self.x_data.append(indexed_words)\n",
        "\n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "\n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "\n",
        "    def padding(self, sequence):\n",
        "\n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "\n",
        "        y = self.y_data[idx]\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "R3WW8V9lyLm0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnc2nD8gW-Br",
        "outputId": "9b460be8-d599-4ecb-c1d2-0fe2d828cb00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:02<00:00, 90851.57it/s] \n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 96370.94it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "dGeftxdgW-Br"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkGQffBW-Bs",
        "outputId": "acf5505f-b74a-4e60-9caa-1291e64a4dde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  172,   341,     4,  ...,     0,     0,     0],\n",
              "        [  101,     3,   115,  ...,     0,     0,     0],\n",
              "        [ 1642,  7954,  1170,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [   38,   806,    74,  ...,     0,     0,     0],\n",
              "        [ 3989,    24,     8,  ...,     0,     0,     0],\n",
              "        [25220,     4,   174,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUk4nGcW-Bt",
        "outputId": "3085a449-4f5c-4ced-c8e7-b471053a47f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 2, 3, 4, 1, 2, 0, 3, 1, 4, 4, 3, 0, 4, 0, 4, 1, 1, 2, 3, 0, 3, 0,\n",
              "        2, 1, 4, 3, 2, 2, 2, 1, 2, 2, 4, 0, 3, 3, 3, 0, 4, 4, 1, 4, 0, 0, 3, 1,\n",
              "        1, 3, 4, 0, 3, 1, 1, 3, 2, 3, 1, 3, 0, 3, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0dkkTIW-Bw"
      },
      "source": [
        "# Обучить нейронку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "3wwkxZm1vE43"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n, hidden_size=200): #n - количетсво категорий\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        self.LSTM = torch.nn.LSTM(input_size=self.emb_layer.embedding_dim, hidden_size=self.hidden_size, num_layers=2, bidirectional=True) # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "\n",
        "        self.q_proj = torch.nn.Linear(self.hidden_size * 2, self.hidden_size * 2) # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.k_proj = torch.nn.Linear(self.hidden_size * 2, self.hidden_size * 2)\n",
        "        self.v_proj = torch.nn.Linear(self.hidden_size * 2, self.hidden_size * 2)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "\n",
        "        self.cnn_3gr = torch.nn.Conv1d(hidden_size * 2, hidden_size, 3)  # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_4gr = torch.nn.Conv1d(hidden_size * 2, hidden_size, 4)\n",
        "        self.cnn_5gr = torch.nn.Conv1d(hidden_size * 2, hidden_size, 5)\n",
        "\n",
        "        self.linear_1 = torch.nn.Linear(self.hidden_size * 3, self.hidden_size)  # сверху накидываем два полносвязных слоя для классификации\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(self.hidden_size, out_features=n)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      x_emb = self.emb_layer(x)  #примените эмбеддинги\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x_emb = x_emb.transpose(0, 1)\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(1, 2)) / np.sqrt(x_q.shape[-1])\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_dist, x_v)  # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "\n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "\n",
        "      x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "      x = self.relu(x)\n",
        "      x = self.linear_2(x)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "jFbyUXLE0WPv"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "OZgh4ONx0HvT"
      },
      "outputs": [],
      "source": [
        "model = model_with_att(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNO6VSbJgQ36",
        "outputId": "fb61410e-8fd7-4d42-d9b0-d77868676af5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 200, num_layers=2, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=400, out_features=400, bias=True)\n",
              "  (k_proj): Linear(in_features=400, out_features=400, bias=True)\n",
              "  (v_proj): Linear(in_features=400, out_features=400, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(400, 200, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(400, 200, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(400, 200, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=600, out_features=200, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=200, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "E66MWNgM0QKM"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "ErboeQbv0dnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf54307a-6785-4e1f-ef37-6ec2b283462b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "bL6zIZSt0h9W"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "Vsxw4M2m0m2B"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rUTc0l60pV9",
        "outputId": "18f2f363-178c-4a62-c647-2ef6902d220e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 1:   0%|          | 0/107000 [02:10<?, ?it/s]\n",
            "\n",
            "Epoch 1:   0%|          | 0/214001 [00:01<?, ?it/s, train_loss=1.6]\u001b[A\n",
            "Epoch 1:   0%|          | 32/214001 [00:01<3:06:34, 19.11it/s, train_loss=1.6]\u001b[A\n",
            "Epoch 1:   0%|          | 32/214001 [00:01<3:06:34, 19.11it/s, train_loss=1.61]\u001b[A\n",
            "Epoch 1:   0%|          | 64/214001 [00:01<3:06:32, 19.11it/s, train_loss=1.6] \u001b[A\n",
            "Epoch 1:   0%|          | 96/214001 [00:01<3:06:30, 19.11it/s, train_loss=1.6]\u001b[A\n",
            "Epoch 1:   0%|          | 128/214001 [00:01<39:35, 90.02it/s, train_loss=1.6] \u001b[A\n",
            "Epoch 1:   0%|          | 128/214001 [00:01<39:35, 90.02it/s, train_loss=1.6]\u001b[A\n",
            "Epoch 1:   0%|          | 160/214001 [00:01<39:35, 90.02it/s, train_loss=1.59]\u001b[A\n",
            "Epoch 1:   0%|          | 192/214001 [00:01<39:35, 90.02it/s, train_loss=1.59]\u001b[A\n",
            "Epoch 1:   0%|          | 224/214001 [00:01<21:09, 168.37it/s, train_loss=1.59]\u001b[A\n",
            "Epoch 1:   0%|          | 224/214001 [00:01<21:09, 168.37it/s, train_loss=1.58]\u001b[A\n",
            "Epoch 1:   0%|          | 256/214001 [00:02<21:09, 168.37it/s, train_loss=1.59]\u001b[A\n",
            "Epoch 1:   0%|          | 288/214001 [00:02<21:09, 168.37it/s, train_loss=1.59]\u001b[A\n",
            "Epoch 1:   0%|          | 320/214001 [00:02<21:09, 168.37it/s, train_loss=1.58]\u001b[A\n",
            "Epoch 1:   0%|          | 352/214001 [00:02<12:18, 289.20it/s, train_loss=1.58]\u001b[A\n",
            "Epoch 1:   0%|          | 352/214001 [00:02<12:18, 289.20it/s, train_loss=1.58]\u001b[A\n",
            "Epoch 1:   0%|          | 384/214001 [00:02<12:18, 289.20it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 416/214001 [00:02<12:18, 289.20it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 448/214001 [00:02<12:18, 289.20it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 480/214001 [00:02<08:37, 412.81it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 480/214001 [00:02<08:37, 412.81it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 512/214001 [00:02<08:37, 412.81it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 544/214001 [00:02<08:37, 412.81it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 576/214001 [00:02<08:37, 412.81it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 608/214001 [00:02<06:33, 541.85it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 608/214001 [00:02<06:33, 541.85it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 640/214001 [00:02<06:33, 541.85it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 672/214001 [00:02<06:33, 541.85it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 704/214001 [00:02<06:33, 541.85it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 736/214001 [00:02<05:20, 664.70it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 736/214001 [00:02<05:20, 664.70it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 768/214001 [00:02<05:20, 664.70it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 800/214001 [00:02<05:20, 664.70it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 832/214001 [00:02<05:20, 664.70it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 864/214001 [00:02<04:38, 765.61it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 864/214001 [00:02<04:38, 765.61it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 896/214001 [00:02<04:38, 765.61it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   0%|          | 928/214001 [00:02<04:38, 765.61it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   0%|          | 960/214001 [00:02<04:38, 765.61it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   0%|          | 992/214001 [00:02<04:05, 868.73it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   0%|          | 992/214001 [00:02<04:05, 868.73it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   0%|          | 1024/214001 [00:02<04:05, 868.73it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   0%|          | 1056/214001 [00:02<04:05, 868.73it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1088/214001 [00:02<04:05, 868.73it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1120/214001 [00:02<03:43, 950.96it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1120/214001 [00:02<03:43, 950.96it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1152/214001 [00:02<03:43, 950.96it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1184/214001 [00:02<03:43, 950.96it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1216/214001 [00:02<03:43, 950.96it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1248/214001 [00:02<03:29, 1015.72it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1248/214001 [00:02<03:29, 1015.72it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1280/214001 [00:02<03:29, 1015.72it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1312/214001 [00:02<03:29, 1015.72it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1344/214001 [00:02<03:29, 1015.72it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1376/214001 [00:02<03:21, 1056.30it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1376/214001 [00:03<03:21, 1056.30it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1408/214001 [00:03<03:21, 1056.30it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1440/214001 [00:03<03:21, 1056.30it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1472/214001 [00:03<03:21, 1056.30it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1504/214001 [00:03<03:15, 1084.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1504/214001 [00:03<03:15, 1084.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1536/214001 [00:03<03:15, 1084.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1568/214001 [00:03<03:15, 1084.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1600/214001 [00:03<03:15, 1084.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1632/214001 [00:03<03:10, 1111.94it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1632/214001 [00:03<03:10, 1111.94it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1664/214001 [00:03<03:10, 1111.94it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1696/214001 [00:03<03:10, 1111.94it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1728/214001 [00:03<03:10, 1111.94it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1760/214001 [00:03<03:08, 1126.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1760/214001 [00:03<03:08, 1126.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1792/214001 [00:03<03:08, 1126.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1824/214001 [00:03<03:08, 1126.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1856/214001 [00:03<03:08, 1126.38it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1888/214001 [00:03<03:07, 1131.83it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1888/214001 [00:03<03:07, 1131.83it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1920/214001 [00:03<03:07, 1131.83it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1952/214001 [00:03<03:07, 1131.83it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 1984/214001 [00:03<03:07, 1131.83it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 2016/214001 [00:03<03:09, 1120.84it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 2016/214001 [00:03<03:09, 1120.84it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 2048/214001 [00:03<03:09, 1120.84it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 2080/214001 [00:03<03:09, 1120.84it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 2112/214001 [00:03<03:09, 1120.84it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 2144/214001 [00:03<03:11, 1104.77it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 2144/214001 [00:03<03:11, 1104.77it/s, train_loss=1.57]\u001b[A\n",
            "Epoch 1:   1%|          | 2176/214001 [00:03<03:11, 1104.77it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2208/214001 [00:03<03:11, 1104.77it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2240/214001 [00:03<03:11, 1104.77it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2272/214001 [00:03<03:08, 1121.02it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2272/214001 [00:03<03:08, 1121.02it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2304/214001 [00:03<03:08, 1121.02it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2336/214001 [00:03<03:08, 1121.02it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2368/214001 [00:03<03:08, 1121.02it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2400/214001 [00:03<03:04, 1149.35it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2400/214001 [00:03<03:04, 1149.35it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2432/214001 [00:03<03:04, 1149.35it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2464/214001 [00:03<03:04, 1149.35it/s, train_loss=1.56]\u001b[A\n",
            "Epoch 1:   1%|          | 2496/214001 [00:03<03:04, 1149.35it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|          | 2528/214001 [00:03<03:03, 1154.40it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|          | 2528/214001 [00:04<03:03, 1154.40it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|          | 2560/214001 [00:04<03:03, 1154.40it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|          | 2592/214001 [00:04<03:03, 1154.40it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|          | 2624/214001 [00:04<03:03, 1154.40it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|          | 2656/214001 [00:04<03:03, 1154.26it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|          | 2656/214001 [00:04<03:03, 1154.26it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2688/214001 [00:04<03:03, 1154.26it/s, train_loss=1.55]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2720/214001 [00:04<03:03, 1154.26it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2752/214001 [00:04<03:03, 1154.26it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2784/214001 [00:04<03:00, 1168.88it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2784/214001 [00:04<03:00, 1168.88it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2816/214001 [00:04<03:00, 1168.88it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2848/214001 [00:04<03:00, 1168.88it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2880/214001 [00:04<03:00, 1168.88it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2912/214001 [00:04<03:02, 1155.19it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2912/214001 [00:04<03:02, 1155.19it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2944/214001 [00:04<03:02, 1155.19it/s, train_loss=1.54]\u001b[A\n",
            "Epoch 1:   1%|▏         | 2976/214001 [00:04<03:02, 1155.19it/s, train_loss=1.53]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3008/214001 [00:04<03:02, 1155.19it/s, train_loss=1.53]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3040/214001 [00:04<03:03, 1148.45it/s, train_loss=1.53]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3040/214001 [00:04<03:03, 1148.45it/s, train_loss=1.53]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3072/214001 [00:04<03:03, 1148.45it/s, train_loss=1.53]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3104/214001 [00:04<03:03, 1148.45it/s, train_loss=1.53]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3136/214001 [00:04<03:03, 1148.45it/s, train_loss=1.53]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3168/214001 [00:04<03:04, 1141.00it/s, train_loss=1.53]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3168/214001 [00:04<03:04, 1141.00it/s, train_loss=1.52]\u001b[A\n",
            "Epoch 1:   1%|▏         | 3200/214001 [00:04<03:04, 1141.00it/s, train_loss=1.52]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3232/214001 [00:04<03:04, 1141.00it/s, train_loss=1.52]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3264/214001 [00:04<03:04, 1141.00it/s, train_loss=1.52]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3296/214001 [00:04<03:05, 1138.93it/s, train_loss=1.52]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3296/214001 [00:04<03:05, 1138.93it/s, train_loss=1.52]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3328/214001 [00:04<03:04, 1138.93it/s, train_loss=1.51]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3360/214001 [00:04<03:04, 1138.93it/s, train_loss=1.51]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3392/214001 [00:04<03:04, 1138.93it/s, train_loss=1.51]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3424/214001 [00:04<03:05, 1135.12it/s, train_loss=1.51]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3424/214001 [00:04<03:05, 1135.12it/s, train_loss=1.5] \u001b[A\n",
            "Epoch 1:   2%|▏         | 3456/214001 [00:04<03:05, 1135.12it/s, train_loss=1.5]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3488/214001 [00:04<03:05, 1135.12it/s, train_loss=1.5]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3520/214001 [00:04<03:05, 1135.12it/s, train_loss=1.5]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3552/214001 [00:04<03:03, 1146.49it/s, train_loss=1.5]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3552/214001 [00:04<03:03, 1146.49it/s, train_loss=1.5]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3584/214001 [00:04<03:03, 1146.49it/s, train_loss=1.49]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3616/214001 [00:04<03:03, 1146.49it/s, train_loss=1.49]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3648/214001 [00:04<03:03, 1146.49it/s, train_loss=1.49]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3680/214001 [00:04<03:03, 1143.83it/s, train_loss=1.49]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3680/214001 [00:05<03:03, 1143.83it/s, train_loss=1.48]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3712/214001 [00:05<03:03, 1143.83it/s, train_loss=1.48]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3744/214001 [00:05<03:03, 1143.83it/s, train_loss=1.48]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3776/214001 [00:05<03:03, 1143.83it/s, train_loss=1.48]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3808/214001 [00:05<03:02, 1150.01it/s, train_loss=1.48]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3808/214001 [00:05<03:02, 1150.01it/s, train_loss=1.47]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3840/214001 [00:05<03:02, 1150.01it/s, train_loss=1.47]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3872/214001 [00:05<03:02, 1150.01it/s, train_loss=1.47]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3904/214001 [00:05<03:02, 1150.01it/s, train_loss=1.46]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3936/214001 [00:05<02:58, 1176.75it/s, train_loss=1.46]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3936/214001 [00:05<02:58, 1176.75it/s, train_loss=1.46]\u001b[A\n",
            "Epoch 1:   2%|▏         | 3968/214001 [00:05<02:58, 1176.75it/s, train_loss=1.46]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4000/214001 [00:05<02:58, 1176.75it/s, train_loss=1.45]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4032/214001 [00:05<02:58, 1176.75it/s, train_loss=1.45]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4064/214001 [00:05<02:58, 1176.08it/s, train_loss=1.45]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4064/214001 [00:05<02:58, 1176.08it/s, train_loss=1.45]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4096/214001 [00:05<02:58, 1176.08it/s, train_loss=1.44]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4128/214001 [00:05<02:58, 1176.08it/s, train_loss=1.44]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4160/214001 [00:05<02:58, 1176.08it/s, train_loss=1.44]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4192/214001 [00:05<02:59, 1167.74it/s, train_loss=1.44]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4192/214001 [00:05<02:59, 1167.74it/s, train_loss=1.44]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4224/214001 [00:05<02:59, 1167.74it/s, train_loss=1.44]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4256/214001 [00:05<02:59, 1167.74it/s, train_loss=1.43]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4288/214001 [00:05<02:59, 1167.74it/s, train_loss=1.43]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4320/214001 [00:05<02:57, 1179.77it/s, train_loss=1.43]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4320/214001 [00:05<02:57, 1179.77it/s, train_loss=1.43]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4352/214001 [00:05<02:57, 1179.77it/s, train_loss=1.42]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4384/214001 [00:05<02:57, 1179.77it/s, train_loss=1.42]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4416/214001 [00:05<02:57, 1179.77it/s, train_loss=1.42]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4448/214001 [00:05<02:56, 1184.40it/s, train_loss=1.42]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4448/214001 [00:05<02:56, 1184.40it/s, train_loss=1.42]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4480/214001 [00:05<02:56, 1184.40it/s, train_loss=1.42]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4512/214001 [00:05<02:56, 1184.40it/s, train_loss=1.41]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4544/214001 [00:05<02:56, 1184.40it/s, train_loss=1.41]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4576/214001 [00:05<02:57, 1177.45it/s, train_loss=1.41]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4576/214001 [00:05<02:57, 1177.45it/s, train_loss=1.41]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4608/214001 [00:05<02:57, 1177.45it/s, train_loss=1.4] \u001b[A\n",
            "Epoch 1:   2%|▏         | 4640/214001 [00:05<02:57, 1177.45it/s, train_loss=1.4]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4672/214001 [00:05<02:57, 1177.45it/s, train_loss=1.4]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4704/214001 [00:05<02:57, 1179.09it/s, train_loss=1.4]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4704/214001 [00:05<02:57, 1179.09it/s, train_loss=1.4]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4736/214001 [00:05<02:57, 1179.09it/s, train_loss=1.39]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4768/214001 [00:05<02:57, 1179.09it/s, train_loss=1.39]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4800/214001 [00:05<02:57, 1179.09it/s, train_loss=1.39]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4832/214001 [00:05<03:00, 1159.88it/s, train_loss=1.39]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4832/214001 [00:06<03:00, 1159.88it/s, train_loss=1.39]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4864/214001 [00:06<03:00, 1159.88it/s, train_loss=1.39]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4896/214001 [00:06<03:00, 1159.88it/s, train_loss=1.38]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4928/214001 [00:06<03:00, 1159.88it/s, train_loss=1.38]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4960/214001 [00:06<03:01, 1149.53it/s, train_loss=1.38]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4960/214001 [00:06<03:01, 1149.53it/s, train_loss=1.38]\u001b[A\n",
            "Epoch 1:   2%|▏         | 4992/214001 [00:06<03:01, 1149.53it/s, train_loss=1.38]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5024/214001 [00:06<03:01, 1149.53it/s, train_loss=1.38]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5056/214001 [00:06<03:01, 1149.53it/s, train_loss=1.38]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5088/214001 [00:06<03:02, 1144.91it/s, train_loss=1.38]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5088/214001 [00:06<03:02, 1144.91it/s, train_loss=1.37]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5120/214001 [00:06<03:02, 1144.91it/s, train_loss=1.37]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5152/214001 [00:06<03:02, 1144.91it/s, train_loss=1.37]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5184/214001 [00:06<03:02, 1144.91it/s, train_loss=1.37]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5216/214001 [00:06<03:03, 1138.75it/s, train_loss=1.37]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5216/214001 [00:06<03:03, 1138.75it/s, train_loss=1.36]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5248/214001 [00:06<03:03, 1138.75it/s, train_loss=1.36]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5280/214001 [00:06<03:03, 1138.75it/s, train_loss=1.36]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5312/214001 [00:06<03:03, 1138.75it/s, train_loss=1.36]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5344/214001 [00:06<03:00, 1153.54it/s, train_loss=1.36]\u001b[A\n",
            "Epoch 1:   2%|▏         | 5344/214001 [00:06<03:00, 1153.54it/s, train_loss=1.36]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5376/214001 [00:06<03:00, 1153.54it/s, train_loss=1.35]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5408/214001 [00:06<03:00, 1153.54it/s, train_loss=1.35]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5440/214001 [00:06<03:00, 1153.54it/s, train_loss=1.35]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5472/214001 [00:06<03:00, 1154.94it/s, train_loss=1.35]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5472/214001 [00:06<03:00, 1154.94it/s, train_loss=1.35]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5504/214001 [00:06<03:00, 1154.94it/s, train_loss=1.35]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5536/214001 [00:06<03:00, 1154.94it/s, train_loss=1.35]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5568/214001 [00:06<03:00, 1154.94it/s, train_loss=1.34]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5600/214001 [00:06<03:03, 1136.23it/s, train_loss=1.34]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5600/214001 [00:06<03:03, 1136.23it/s, train_loss=1.34]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5632/214001 [00:06<03:03, 1136.23it/s, train_loss=1.34]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5664/214001 [00:06<03:03, 1136.23it/s, train_loss=1.34]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5696/214001 [00:06<03:03, 1136.23it/s, train_loss=1.34]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5728/214001 [00:06<03:04, 1126.77it/s, train_loss=1.34]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5728/214001 [00:06<03:04, 1126.77it/s, train_loss=1.34]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5760/214001 [00:06<03:04, 1126.77it/s, train_loss=1.33]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5792/214001 [00:06<03:04, 1126.77it/s, train_loss=1.33]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5824/214001 [00:06<03:04, 1126.77it/s, train_loss=1.33]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5856/214001 [00:06<03:00, 1155.65it/s, train_loss=1.33]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5856/214001 [00:06<03:00, 1155.65it/s, train_loss=1.33]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5888/214001 [00:06<03:00, 1155.65it/s, train_loss=1.33]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5920/214001 [00:06<03:00, 1155.65it/s, train_loss=1.33]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5952/214001 [00:06<03:00, 1155.65it/s, train_loss=1.32]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5984/214001 [00:06<02:59, 1161.50it/s, train_loss=1.32]\u001b[A\n",
            "Epoch 1:   3%|▎         | 5984/214001 [00:07<02:59, 1161.50it/s, train_loss=1.32]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6016/214001 [00:07<02:59, 1161.50it/s, train_loss=1.32]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6048/214001 [00:07<02:59, 1161.50it/s, train_loss=1.32]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6080/214001 [00:07<02:59, 1161.50it/s, train_loss=1.32]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6112/214001 [00:07<03:00, 1152.04it/s, train_loss=1.32]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6112/214001 [00:07<03:00, 1152.04it/s, train_loss=1.31]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6144/214001 [00:07<03:00, 1152.04it/s, train_loss=1.31]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6176/214001 [00:07<03:00, 1152.04it/s, train_loss=1.31]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6208/214001 [00:07<03:00, 1152.04it/s, train_loss=1.31]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6240/214001 [00:07<03:00, 1152.52it/s, train_loss=1.31]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6240/214001 [00:07<03:00, 1152.52it/s, train_loss=1.31]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6272/214001 [00:07<03:00, 1152.52it/s, train_loss=1.3] \u001b[A\n",
            "Epoch 1:   3%|▎         | 6304/214001 [00:07<03:00, 1152.52it/s, train_loss=1.3]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6336/214001 [00:07<03:00, 1152.52it/s, train_loss=1.3]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6368/214001 [00:07<03:00, 1152.52it/s, train_loss=1.3]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6400/214001 [00:07<02:53, 1197.04it/s, train_loss=1.3]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6400/214001 [00:07<02:53, 1197.04it/s, train_loss=1.3]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6432/214001 [00:07<02:53, 1197.04it/s, train_loss=1.3]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6464/214001 [00:07<02:53, 1197.04it/s, train_loss=1.3]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6496/214001 [00:07<02:53, 1197.04it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6528/214001 [00:07<02:51, 1207.78it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6528/214001 [00:07<02:51, 1207.78it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6560/214001 [00:07<02:51, 1207.78it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6592/214001 [00:07<02:51, 1207.78it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6624/214001 [00:07<02:51, 1207.78it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6656/214001 [00:07<02:54, 1186.31it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6656/214001 [00:07<02:54, 1186.31it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6688/214001 [00:07<02:54, 1186.31it/s, train_loss=1.29]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6720/214001 [00:07<02:54, 1186.31it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6752/214001 [00:07<02:54, 1186.31it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6784/214001 [00:07<02:55, 1182.53it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6784/214001 [00:07<02:55, 1182.53it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6816/214001 [00:07<02:55, 1182.53it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6848/214001 [00:07<02:55, 1182.53it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6880/214001 [00:07<02:55, 1182.53it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6912/214001 [00:07<02:57, 1165.39it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6912/214001 [00:07<02:57, 1165.39it/s, train_loss=1.28]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6944/214001 [00:07<02:57, 1165.39it/s, train_loss=1.27]\u001b[A\n",
            "Epoch 1:   3%|▎         | 6976/214001 [00:07<02:57, 1165.39it/s, train_loss=1.27]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7008/214001 [00:07<02:57, 1165.39it/s, train_loss=1.27]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7040/214001 [00:07<02:54, 1183.80it/s, train_loss=1.27]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7040/214001 [00:07<02:54, 1183.80it/s, train_loss=1.27]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7072/214001 [00:07<02:54, 1183.80it/s, train_loss=1.27]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7104/214001 [00:07<02:54, 1183.80it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7136/214001 [00:07<02:54, 1183.80it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7168/214001 [00:07<02:55, 1181.15it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7168/214001 [00:08<02:55, 1181.15it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7200/214001 [00:08<02:55, 1181.15it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7232/214001 [00:08<02:55, 1181.15it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7264/214001 [00:08<02:55, 1181.15it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7296/214001 [00:08<02:54, 1181.76it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7296/214001 [00:08<02:54, 1181.76it/s, train_loss=1.26]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7328/214001 [00:08<02:54, 1181.76it/s, train_loss=1.25]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7360/214001 [00:08<02:54, 1181.76it/s, train_loss=1.25]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7392/214001 [00:08<02:54, 1181.76it/s, train_loss=1.25]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7424/214001 [00:08<02:53, 1191.27it/s, train_loss=1.25]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7424/214001 [00:08<02:53, 1191.27it/s, train_loss=1.25]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7456/214001 [00:08<02:53, 1191.27it/s, train_loss=1.25]\u001b[A\n",
            "Epoch 1:   3%|▎         | 7488/214001 [00:08<02:53, 1191.27it/s, train_loss=1.25]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7520/214001 [00:08<02:53, 1191.27it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7552/214001 [00:08<02:57, 1164.46it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7552/214001 [00:08<02:57, 1164.46it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7584/214001 [00:08<02:57, 1164.46it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7616/214001 [00:08<02:57, 1164.46it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7648/214001 [00:08<02:57, 1164.46it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7680/214001 [00:08<02:55, 1174.65it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7680/214001 [00:08<02:55, 1174.65it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7712/214001 [00:08<02:55, 1174.65it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7744/214001 [00:08<02:55, 1174.65it/s, train_loss=1.24]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7776/214001 [00:08<02:55, 1174.65it/s, train_loss=1.23]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7808/214001 [00:08<02:57, 1162.71it/s, train_loss=1.23]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7808/214001 [00:08<02:57, 1162.71it/s, train_loss=1.23]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7840/214001 [00:08<02:57, 1162.71it/s, train_loss=1.23]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7872/214001 [00:08<02:57, 1162.71it/s, train_loss=1.23]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7904/214001 [00:08<02:57, 1162.71it/s, train_loss=1.23]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7936/214001 [00:08<02:58, 1152.04it/s, train_loss=1.23]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7936/214001 [00:08<02:58, 1152.04it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▎         | 7968/214001 [00:08<02:58, 1152.04it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▎         | 8000/214001 [00:08<02:58, 1152.04it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8032/214001 [00:08<02:58, 1152.04it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8064/214001 [00:08<02:57, 1161.39it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8064/214001 [00:08<02:57, 1161.39it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8096/214001 [00:08<02:57, 1161.39it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8128/214001 [00:08<02:57, 1161.39it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8160/214001 [00:08<02:57, 1161.39it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8192/214001 [00:08<02:54, 1178.23it/s, train_loss=1.22]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8192/214001 [00:08<02:54, 1178.23it/s, train_loss=1.21]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8224/214001 [00:08<02:54, 1178.23it/s, train_loss=1.21]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8256/214001 [00:08<02:54, 1178.23it/s, train_loss=1.21]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8288/214001 [00:08<02:54, 1178.23it/s, train_loss=1.21]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8320/214001 [00:08<02:55, 1170.95it/s, train_loss=1.21]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8320/214001 [00:08<02:55, 1170.95it/s, train_loss=1.21]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8352/214001 [00:09<02:55, 1170.95it/s, train_loss=1.21]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8384/214001 [00:09<02:55, 1170.95it/s, train_loss=1.21]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8416/214001 [00:09<02:55, 1170.95it/s, train_loss=1.2] \u001b[A\n",
            "Epoch 1:   4%|▍         | 8448/214001 [00:09<02:59, 1144.48it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8448/214001 [00:09<02:59, 1144.48it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8480/214001 [00:09<02:59, 1144.48it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8512/214001 [00:09<02:59, 1144.48it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8544/214001 [00:09<02:59, 1144.48it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8576/214001 [00:09<02:54, 1179.51it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8576/214001 [00:09<02:54, 1179.51it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8608/214001 [00:09<02:54, 1179.51it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8640/214001 [00:09<02:54, 1179.51it/s, train_loss=1.2]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8672/214001 [00:09<02:54, 1179.51it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8704/214001 [00:09<02:52, 1191.40it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8704/214001 [00:09<02:52, 1191.40it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8736/214001 [00:09<02:52, 1191.40it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8768/214001 [00:09<02:52, 1191.40it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8800/214001 [00:09<02:52, 1191.40it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8832/214001 [00:09<02:52, 1191.40it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8864/214001 [00:09<02:47, 1221.44it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8864/214001 [00:09<02:47, 1221.44it/s, train_loss=1.19]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8896/214001 [00:09<02:47, 1221.44it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8928/214001 [00:09<02:47, 1221.44it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8960/214001 [00:09<02:47, 1221.44it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8992/214001 [00:09<02:48, 1217.19it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 8992/214001 [00:09<02:48, 1217.19it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9024/214001 [00:09<02:48, 1217.19it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9056/214001 [00:09<02:48, 1217.19it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9088/214001 [00:09<02:48, 1217.19it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9120/214001 [00:09<02:52, 1190.45it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9120/214001 [00:09<02:52, 1190.45it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9152/214001 [00:09<02:52, 1190.45it/s, train_loss=1.18]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9184/214001 [00:09<02:52, 1190.45it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9216/214001 [00:09<02:52, 1190.45it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9248/214001 [00:09<02:53, 1176.83it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9248/214001 [00:09<02:53, 1176.83it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9280/214001 [00:09<02:53, 1176.83it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9312/214001 [00:09<02:53, 1176.83it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9344/214001 [00:09<02:53, 1176.83it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9376/214001 [00:09<02:58, 1145.17it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9376/214001 [00:09<02:58, 1145.17it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9408/214001 [00:09<02:58, 1145.17it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9440/214001 [00:09<02:58, 1145.17it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9472/214001 [00:09<02:58, 1145.17it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9504/214001 [00:09<03:04, 1110.82it/s, train_loss=1.17]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9504/214001 [00:10<03:04, 1110.82it/s, train_loss=1.16]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9536/214001 [00:10<03:04, 1110.82it/s, train_loss=1.16]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9568/214001 [00:10<03:04, 1110.82it/s, train_loss=1.16]\u001b[A\n",
            "Epoch 1:   4%|▍         | 9600/214001 [00:10<03:04, 1110.82it/s, train_loss=1.16]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9632/214001 [00:10<02:57, 1152.61it/s, train_loss=1.16]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9632/214001 [00:10<02:57, 1152.61it/s, train_loss=1.16]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9664/214001 [00:10<02:57, 1152.61it/s, train_loss=1.16]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9696/214001 [00:10<02:57, 1152.61it/s, train_loss=1.16]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9728/214001 [00:10<02:57, 1152.61it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9760/214001 [00:10<02:53, 1180.37it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9760/214001 [00:10<02:53, 1180.37it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9792/214001 [00:10<02:53, 1180.37it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9824/214001 [00:10<02:52, 1180.37it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9856/214001 [00:10<02:52, 1180.37it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9888/214001 [00:10<02:50, 1198.96it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9888/214001 [00:10<02:50, 1198.96it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9920/214001 [00:10<02:50, 1198.96it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9952/214001 [00:10<02:50, 1198.96it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 9984/214001 [00:10<02:50, 1198.96it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10016/214001 [00:10<02:47, 1219.60it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10016/214001 [00:10<02:47, 1219.60it/s, train_loss=1.15]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10048/214001 [00:10<02:47, 1219.60it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10080/214001 [00:10<02:47, 1219.60it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10112/214001 [00:10<02:47, 1219.60it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10144/214001 [00:10<02:48, 1212.66it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10144/214001 [00:10<02:48, 1212.66it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10176/214001 [00:10<02:48, 1212.66it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10208/214001 [00:10<02:48, 1212.66it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10240/214001 [00:10<02:48, 1212.66it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10272/214001 [00:10<02:46, 1225.64it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10272/214001 [00:10<02:46, 1225.64it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10304/214001 [00:10<02:46, 1225.64it/s, train_loss=1.14]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10336/214001 [00:10<02:46, 1225.64it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10368/214001 [00:10<02:46, 1225.64it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10400/214001 [00:10<02:54, 1169.70it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10400/214001 [00:10<02:54, 1169.70it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10432/214001 [00:10<02:54, 1169.70it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10464/214001 [00:10<02:54, 1169.70it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10496/214001 [00:10<02:53, 1169.70it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10528/214001 [00:10<02:57, 1143.59it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10528/214001 [00:10<02:57, 1143.59it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10560/214001 [00:10<02:57, 1143.59it/s, train_loss=1.13]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10592/214001 [00:10<02:57, 1143.59it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10624/214001 [00:10<02:57, 1143.59it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10656/214001 [00:10<02:52, 1175.88it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10656/214001 [00:10<02:52, 1175.88it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▍         | 10688/214001 [00:10<02:52, 1175.88it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10720/214001 [00:11<02:52, 1175.88it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10752/214001 [00:11<02:52, 1175.88it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10784/214001 [00:11<02:49, 1196.47it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10784/214001 [00:11<02:49, 1196.47it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10816/214001 [00:11<02:49, 1196.47it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10848/214001 [00:11<02:49, 1196.47it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10880/214001 [00:11<02:49, 1196.47it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10912/214001 [00:11<02:47, 1215.32it/s, train_loss=1.12]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10912/214001 [00:11<02:47, 1215.32it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10944/214001 [00:11<02:47, 1215.32it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 10976/214001 [00:11<02:47, 1215.32it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11008/214001 [00:11<02:47, 1215.32it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11040/214001 [00:11<02:45, 1226.18it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11040/214001 [00:11<02:45, 1226.18it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11072/214001 [00:11<02:45, 1226.18it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11104/214001 [00:11<02:45, 1226.18it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11136/214001 [00:11<02:45, 1226.18it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11168/214001 [00:11<02:51, 1183.23it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11168/214001 [00:11<02:51, 1183.23it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11200/214001 [00:11<02:51, 1183.23it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11232/214001 [00:11<02:51, 1183.23it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11264/214001 [00:11<02:51, 1183.23it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11296/214001 [00:11<02:47, 1210.34it/s, train_loss=1.11]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11296/214001 [00:11<02:47, 1210.34it/s, train_loss=1.1] \u001b[A\n",
            "Epoch 1:   5%|▌         | 11328/214001 [00:11<02:47, 1210.34it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11360/214001 [00:11<02:47, 1210.34it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11392/214001 [00:11<02:47, 1210.34it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11424/214001 [00:11<02:45, 1221.99it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11424/214001 [00:11<02:45, 1221.99it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11456/214001 [00:11<02:45, 1221.99it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11488/214001 [00:11<02:45, 1221.99it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11520/214001 [00:11<02:45, 1221.99it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11552/214001 [00:11<02:54, 1163.05it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11552/214001 [00:11<02:54, 1163.05it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11584/214001 [00:11<02:54, 1163.05it/s, train_loss=1.1]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11616/214001 [00:11<02:54, 1163.05it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11648/214001 [00:11<02:53, 1163.05it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11680/214001 [00:11<02:53, 1163.23it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11680/214001 [00:11<02:53, 1163.23it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11712/214001 [00:11<02:53, 1163.23it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   5%|▌         | 11744/214001 [00:11<02:53, 1163.23it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11776/214001 [00:11<02:53, 1163.23it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11808/214001 [00:11<02:50, 1182.47it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11808/214001 [00:11<02:50, 1182.47it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11840/214001 [00:11<02:50, 1182.47it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11872/214001 [00:11<02:50, 1182.47it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11904/214001 [00:12<02:50, 1182.47it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11936/214001 [00:12<02:49, 1195.14it/s, train_loss=1.09]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11936/214001 [00:12<02:49, 1195.14it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 11968/214001 [00:12<02:49, 1195.14it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12000/214001 [00:12<02:49, 1195.14it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12032/214001 [00:12<02:48, 1195.14it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12064/214001 [00:12<02:48, 1196.82it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12064/214001 [00:12<02:48, 1196.82it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12096/214001 [00:12<02:48, 1196.82it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12128/214001 [00:12<02:48, 1196.82it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12160/214001 [00:12<02:48, 1196.82it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12192/214001 [00:12<02:51, 1178.81it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12192/214001 [00:12<02:51, 1178.81it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12224/214001 [00:12<02:51, 1178.81it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12256/214001 [00:12<02:51, 1178.81it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12288/214001 [00:12<02:51, 1178.81it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12320/214001 [00:12<02:50, 1182.44it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12320/214001 [00:12<02:50, 1182.44it/s, train_loss=1.08]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12352/214001 [00:12<02:50, 1182.44it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12384/214001 [00:12<02:50, 1182.44it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12416/214001 [00:12<02:50, 1182.44it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12448/214001 [00:12<02:48, 1194.34it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12448/214001 [00:12<02:48, 1194.34it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12480/214001 [00:12<02:48, 1194.34it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12512/214001 [00:12<02:48, 1194.34it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12544/214001 [00:12<02:48, 1194.34it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12576/214001 [00:12<02:55, 1146.76it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12576/214001 [00:12<02:55, 1146.76it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12608/214001 [00:12<02:55, 1146.76it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12640/214001 [00:12<02:55, 1146.76it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12672/214001 [00:12<02:55, 1146.76it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12704/214001 [00:12<03:03, 1095.42it/s, train_loss=1.07]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12704/214001 [00:12<03:03, 1095.42it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12736/214001 [00:12<03:03, 1095.42it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12768/214001 [00:12<03:03, 1095.42it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12800/214001 [00:12<03:03, 1095.42it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12832/214001 [00:12<03:07, 1073.04it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12832/214001 [00:12<03:07, 1073.04it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12864/214001 [00:12<03:07, 1073.04it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12896/214001 [00:12<03:07, 1073.04it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12928/214001 [00:12<03:07, 1073.04it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12960/214001 [00:12<03:17, 1016.43it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12960/214001 [00:12<03:17, 1016.43it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 12992/214001 [00:13<03:17, 1016.43it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13024/214001 [00:13<03:17, 1016.43it/s, train_loss=1.06]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13056/214001 [00:13<03:17, 1016.43it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13088/214001 [00:13<03:23, 988.71it/s, train_loss=1.05] \u001b[A\n",
            "Epoch 1:   6%|▌         | 13088/214001 [00:13<03:23, 988.71it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13120/214001 [00:13<03:23, 988.71it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13152/214001 [00:13<03:23, 988.71it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13184/214001 [00:13<03:23, 988.71it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13216/214001 [00:13<03:26, 971.33it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13216/214001 [00:13<03:26, 971.33it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13248/214001 [00:13<03:26, 971.33it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13280/214001 [00:13<03:26, 971.33it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13312/214001 [00:13<03:26, 971.33it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13344/214001 [00:13<03:23, 984.65it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▌         | 13344/214001 [00:13<03:23, 984.65it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13376/214001 [00:13<03:23, 984.65it/s, train_loss=1.05]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13408/214001 [00:13<03:23, 984.65it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13440/214001 [00:13<03:23, 984.65it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13472/214001 [00:13<03:28, 961.07it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13472/214001 [00:13<03:28, 961.07it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13504/214001 [00:13<03:28, 961.07it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13536/214001 [00:13<03:28, 961.07it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13568/214001 [00:13<03:28, 961.07it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13600/214001 [00:13<03:36, 926.78it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13600/214001 [00:13<03:36, 926.78it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13632/214001 [00:13<03:36, 926.78it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13664/214001 [00:13<03:36, 926.78it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13696/214001 [00:13<03:36, 926.78it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13728/214001 [00:13<03:25, 973.58it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13728/214001 [00:13<03:25, 973.58it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13760/214001 [00:13<03:25, 973.58it/s, train_loss=1.04]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13792/214001 [00:13<03:25, 973.58it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13824/214001 [00:13<03:25, 973.58it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13856/214001 [00:13<03:13, 1036.53it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13856/214001 [00:13<03:13, 1036.53it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   6%|▋         | 13888/214001 [00:13<03:13, 1036.53it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13920/214001 [00:13<03:13, 1036.53it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13952/214001 [00:13<03:12, 1036.53it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13984/214001 [00:13<03:10, 1048.50it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 13984/214001 [00:14<03:10, 1048.50it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14016/214001 [00:14<03:10, 1048.50it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14048/214001 [00:14<03:10, 1048.50it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14080/214001 [00:14<03:10, 1048.50it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14112/214001 [00:14<03:03, 1087.12it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14112/214001 [00:14<03:03, 1087.12it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14144/214001 [00:14<03:03, 1087.12it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14176/214001 [00:14<03:03, 1087.12it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14208/214001 [00:14<03:03, 1087.12it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14240/214001 [00:14<02:56, 1131.50it/s, train_loss=1.03]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14240/214001 [00:14<02:56, 1131.50it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14272/214001 [00:14<02:56, 1131.50it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14304/214001 [00:14<02:56, 1131.50it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14336/214001 [00:14<02:56, 1131.50it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14368/214001 [00:14<02:58, 1119.38it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14368/214001 [00:14<02:58, 1119.38it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14400/214001 [00:14<02:58, 1119.38it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14432/214001 [00:14<02:58, 1119.38it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14464/214001 [00:14<02:58, 1119.38it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14496/214001 [00:14<02:52, 1155.14it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14496/214001 [00:14<02:52, 1155.14it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14528/214001 [00:14<02:52, 1155.14it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14560/214001 [00:14<02:52, 1155.14it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14592/214001 [00:14<02:52, 1155.14it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14624/214001 [00:14<02:58, 1118.65it/s, train_loss=1.02]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14624/214001 [00:14<02:58, 1118.65it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14656/214001 [00:14<02:58, 1118.65it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14688/214001 [00:14<02:58, 1118.65it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14720/214001 [00:14<02:58, 1118.65it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14752/214001 [00:14<03:07, 1063.62it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14752/214001 [00:14<03:07, 1063.62it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14784/214001 [00:14<03:07, 1063.62it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14816/214001 [00:14<03:07, 1063.62it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14848/214001 [00:14<03:07, 1063.62it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14880/214001 [00:14<03:20, 991.35it/s, train_loss=1.01] \u001b[A\n",
            "Epoch 1:   7%|▋         | 14880/214001 [00:14<03:20, 991.35it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14912/214001 [00:14<03:20, 991.35it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14944/214001 [00:14<03:20, 991.35it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 14976/214001 [00:14<03:20, 991.35it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15008/214001 [00:14<03:27, 958.01it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15008/214001 [00:14<03:27, 958.01it/s, train_loss=1.01]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15040/214001 [00:15<03:27, 958.01it/s, train_loss=1]   \u001b[A\n",
            "Epoch 1:   7%|▋         | 15072/214001 [00:15<03:27, 958.01it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15104/214001 [00:15<03:27, 958.01it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15136/214001 [00:15<03:24, 972.87it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15136/214001 [00:15<03:24, 972.87it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15168/214001 [00:15<03:24, 972.87it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15200/214001 [00:15<03:24, 972.87it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15232/214001 [00:15<03:24, 972.87it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15264/214001 [00:15<03:18, 1001.25it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15264/214001 [00:15<03:18, 1001.25it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15296/214001 [00:15<03:18, 1001.25it/s, train_loss=1]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15328/214001 [00:15<03:18, 1001.25it/s, train_loss=0.999]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15360/214001 [00:15<03:18, 1001.25it/s, train_loss=0.999]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15392/214001 [00:15<03:13, 1026.70it/s, train_loss=0.999]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15392/214001 [00:15<03:13, 1026.70it/s, train_loss=0.998]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15424/214001 [00:15<03:13, 1026.70it/s, train_loss=0.998]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15456/214001 [00:15<03:13, 1026.70it/s, train_loss=0.997]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15488/214001 [00:15<03:13, 1026.70it/s, train_loss=0.996]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15520/214001 [00:15<03:09, 1047.34it/s, train_loss=0.996]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15520/214001 [00:15<03:09, 1047.34it/s, train_loss=0.996]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15552/214001 [00:15<03:09, 1047.34it/s, train_loss=0.995]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15584/214001 [00:15<03:09, 1047.34it/s, train_loss=0.994]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15616/214001 [00:15<03:09, 1047.34it/s, train_loss=0.994]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15648/214001 [00:15<03:03, 1079.94it/s, train_loss=0.994]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15648/214001 [00:15<03:03, 1079.94it/s, train_loss=0.993]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15680/214001 [00:15<03:03, 1079.94it/s, train_loss=0.993]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15712/214001 [00:15<03:03, 1079.94it/s, train_loss=0.992]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15744/214001 [00:15<03:03, 1079.94it/s, train_loss=0.992]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15776/214001 [00:15<02:57, 1117.36it/s, train_loss=0.992]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15776/214001 [00:15<02:57, 1117.36it/s, train_loss=0.991]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15808/214001 [00:15<02:57, 1117.36it/s, train_loss=0.99] \u001b[A\n",
            "Epoch 1:   7%|▋         | 15840/214001 [00:15<02:57, 1117.36it/s, train_loss=0.989]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15872/214001 [00:15<02:57, 1117.36it/s, train_loss=0.988]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15904/214001 [00:15<02:56, 1124.76it/s, train_loss=0.988]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15904/214001 [00:15<02:56, 1124.76it/s, train_loss=0.988]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15936/214001 [00:15<02:56, 1124.76it/s, train_loss=0.988]\u001b[A\n",
            "Epoch 1:   7%|▋         | 15968/214001 [00:15<02:56, 1124.76it/s, train_loss=0.987]\u001b[A\n",
            "Epoch 1:   7%|▋         | 16000/214001 [00:15<02:56, 1124.76it/s, train_loss=0.985]\u001b[A\n",
            "Epoch 1:   7%|▋         | 16032/214001 [00:15<02:54, 1134.08it/s, train_loss=0.985]\u001b[A\n",
            "Epoch 1:   7%|▋         | 16032/214001 [00:15<02:54, 1134.08it/s, train_loss=0.983]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16064/214001 [00:15<02:54, 1134.08it/s, train_loss=0.981]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16096/214001 [00:15<02:54, 1134.08it/s, train_loss=0.98] \u001b[A\n",
            "Epoch 1:   8%|▊         | 16128/214001 [00:15<02:54, 1134.08it/s, train_loss=0.978]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16160/214001 [00:16<02:53, 1138.28it/s, train_loss=0.978]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16160/214001 [00:16<02:53, 1138.28it/s, train_loss=0.976]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16192/214001 [00:16<02:53, 1138.28it/s, train_loss=0.974]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16224/214001 [00:16<02:53, 1138.28it/s, train_loss=0.972]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16256/214001 [00:16<02:53, 1138.28it/s, train_loss=0.971]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16288/214001 [00:16<02:48, 1173.93it/s, train_loss=0.971]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16288/214001 [00:16<02:48, 1173.93it/s, train_loss=0.969]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16320/214001 [00:16<02:48, 1173.93it/s, train_loss=0.967]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16352/214001 [00:16<02:48, 1173.93it/s, train_loss=0.965]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16384/214001 [00:16<02:48, 1173.93it/s, train_loss=0.964]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16416/214001 [00:16<02:47, 1181.50it/s, train_loss=0.964]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16416/214001 [00:16<02:47, 1181.50it/s, train_loss=0.962]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16448/214001 [00:16<02:47, 1181.50it/s, train_loss=0.96] \u001b[A\n",
            "Epoch 1:   8%|▊         | 16480/214001 [00:16<02:47, 1181.50it/s, train_loss=0.958]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16512/214001 [00:16<02:47, 1181.50it/s, train_loss=0.956]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16544/214001 [00:16<02:51, 1151.27it/s, train_loss=0.956]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16544/214001 [00:16<02:51, 1151.27it/s, train_loss=0.955]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16576/214001 [00:16<02:51, 1151.27it/s, train_loss=0.953]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16608/214001 [00:16<02:51, 1151.27it/s, train_loss=0.951]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16640/214001 [00:16<02:51, 1151.27it/s, train_loss=0.949]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16672/214001 [00:16<02:51, 1150.06it/s, train_loss=0.949]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16672/214001 [00:16<02:51, 1150.06it/s, train_loss=0.947]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16704/214001 [00:16<02:51, 1150.06it/s, train_loss=0.945]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16736/214001 [00:16<02:51, 1150.06it/s, train_loss=0.944]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16768/214001 [00:16<02:51, 1150.06it/s, train_loss=0.942]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16800/214001 [00:16<02:48, 1166.97it/s, train_loss=0.942]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16800/214001 [00:16<02:48, 1166.97it/s, train_loss=0.941]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16832/214001 [00:16<02:48, 1166.97it/s, train_loss=0.939]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16864/214001 [00:16<02:48, 1166.97it/s, train_loss=0.937]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16896/214001 [00:16<02:48, 1166.97it/s, train_loss=0.935]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16928/214001 [00:16<02:45, 1189.71it/s, train_loss=0.935]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16928/214001 [00:16<02:45, 1189.71it/s, train_loss=0.933]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16960/214001 [00:16<02:45, 1189.71it/s, train_loss=0.931]\u001b[A\n",
            "Epoch 1:   8%|▊         | 16992/214001 [00:16<02:45, 1189.71it/s, train_loss=0.929]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17024/214001 [00:16<02:45, 1189.71it/s, train_loss=0.928]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17056/214001 [00:16<02:45, 1188.85it/s, train_loss=0.928]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17056/214001 [00:16<02:45, 1188.85it/s, train_loss=0.925]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17088/214001 [00:16<02:45, 1188.85it/s, train_loss=0.923]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17120/214001 [00:16<02:45, 1188.85it/s, train_loss=0.921]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17152/214001 [00:16<02:45, 1188.85it/s, train_loss=0.919]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17184/214001 [00:16<02:48, 1169.76it/s, train_loss=0.919]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17184/214001 [00:16<02:48, 1169.76it/s, train_loss=0.918]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17216/214001 [00:16<02:48, 1169.76it/s, train_loss=0.916]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17248/214001 [00:16<02:48, 1169.76it/s, train_loss=0.915]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17280/214001 [00:16<02:48, 1169.76it/s, train_loss=0.913]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17312/214001 [00:16<02:48, 1169.04it/s, train_loss=0.913]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17312/214001 [00:17<02:48, 1169.04it/s, train_loss=0.911]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17344/214001 [00:17<02:48, 1169.04it/s, train_loss=0.909]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17376/214001 [00:17<02:48, 1169.04it/s, train_loss=0.907]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17408/214001 [00:17<02:48, 1169.04it/s, train_loss=0.906]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17440/214001 [00:17<02:48, 1164.43it/s, train_loss=0.906]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17440/214001 [00:17<02:48, 1164.43it/s, train_loss=0.904]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17472/214001 [00:17<02:48, 1164.43it/s, train_loss=0.902]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17504/214001 [00:17<02:48, 1164.43it/s, train_loss=0.9]  \u001b[A\n",
            "Epoch 1:   8%|▊         | 17536/214001 [00:17<02:48, 1164.43it/s, train_loss=0.898]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17568/214001 [00:17<02:47, 1174.25it/s, train_loss=0.898]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17568/214001 [00:17<02:47, 1174.25it/s, train_loss=0.896]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17600/214001 [00:17<02:47, 1174.25it/s, train_loss=0.894]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17632/214001 [00:17<02:47, 1174.25it/s, train_loss=0.892]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17664/214001 [00:17<02:47, 1174.25it/s, train_loss=0.89] \u001b[A\n",
            "Epoch 1:   8%|▊         | 17696/214001 [00:17<02:45, 1187.77it/s, train_loss=0.89]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17696/214001 [00:17<02:45, 1187.77it/s, train_loss=0.888]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17728/214001 [00:17<02:45, 1187.77it/s, train_loss=0.886]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17760/214001 [00:17<02:45, 1187.77it/s, train_loss=0.884]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17792/214001 [00:17<02:45, 1187.77it/s, train_loss=0.882]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17824/214001 [00:17<02:46, 1175.99it/s, train_loss=0.882]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17824/214001 [00:17<02:46, 1175.99it/s, train_loss=0.88] \u001b[A\n",
            "Epoch 1:   8%|▊         | 17856/214001 [00:17<02:46, 1175.99it/s, train_loss=0.878]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17888/214001 [00:17<02:46, 1175.99it/s, train_loss=0.877]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17920/214001 [00:17<02:46, 1175.99it/s, train_loss=0.875]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17952/214001 [00:17<02:44, 1192.46it/s, train_loss=0.875]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17952/214001 [00:17<02:44, 1192.46it/s, train_loss=0.873]\u001b[A\n",
            "Epoch 1:   8%|▊         | 17984/214001 [00:17<02:44, 1192.46it/s, train_loss=0.872]\u001b[A\n",
            "Epoch 1:   8%|▊         | 18016/214001 [00:17<02:44, 1192.46it/s, train_loss=0.869]\u001b[A\n",
            "Epoch 1:   8%|▊         | 18048/214001 [00:17<02:44, 1192.46it/s, train_loss=0.867]\u001b[A\n",
            "Epoch 1:   8%|▊         | 18080/214001 [00:17<02:42, 1204.72it/s, train_loss=0.867]\u001b[A\n",
            "Epoch 1:   8%|▊         | 18080/214001 [00:17<02:42, 1204.72it/s, train_loss=0.866]\u001b[A\n",
            "Epoch 1:   8%|▊         | 18112/214001 [00:17<02:42, 1204.72it/s, train_loss=0.864]\u001b[A\n",
            "Epoch 1:   8%|▊         | 18144/214001 [00:17<02:42, 1204.72it/s, train_loss=0.862]\u001b[A\n",
            "Epoch 1:   8%|▊         | 18176/214001 [00:17<02:42, 1204.72it/s, train_loss=0.86] \u001b[A\n",
            "Epoch 1:   9%|▊         | 18208/214001 [00:17<02:42, 1202.50it/s, train_loss=0.86]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18208/214001 [00:17<02:42, 1202.50it/s, train_loss=0.858]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18240/214001 [00:17<02:42, 1202.50it/s, train_loss=0.856]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18272/214001 [00:17<02:42, 1202.50it/s, train_loss=0.855]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18304/214001 [00:17<02:42, 1202.50it/s, train_loss=0.853]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18336/214001 [00:17<02:47, 1169.35it/s, train_loss=0.853]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18336/214001 [00:17<02:47, 1169.35it/s, train_loss=0.851]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18368/214001 [00:17<02:47, 1169.35it/s, train_loss=0.849]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18400/214001 [00:17<02:47, 1169.35it/s, train_loss=0.848]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18432/214001 [00:17<02:47, 1169.35it/s, train_loss=0.847]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18464/214001 [00:17<02:48, 1157.85it/s, train_loss=0.847]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18464/214001 [00:17<02:48, 1157.85it/s, train_loss=0.845]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18496/214001 [00:18<02:48, 1157.85it/s, train_loss=0.844]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18528/214001 [00:18<02:48, 1157.85it/s, train_loss=0.842]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18560/214001 [00:18<02:48, 1157.85it/s, train_loss=0.84] \u001b[A\n",
            "Epoch 1:   9%|▊         | 18592/214001 [00:18<02:48, 1157.35it/s, train_loss=0.84]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18592/214001 [00:18<02:48, 1157.35it/s, train_loss=0.839]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18624/214001 [00:18<02:48, 1157.35it/s, train_loss=0.837]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18656/214001 [00:18<02:48, 1157.35it/s, train_loss=0.835]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18688/214001 [00:18<02:48, 1157.35it/s, train_loss=0.834]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18720/214001 [00:18<02:49, 1155.20it/s, train_loss=0.834]\u001b[A\n",
            "Epoch 1:   9%|▊         | 18720/214001 [00:18<02:49, 1155.20it/s, train_loss=0.832]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18752/214001 [00:18<02:49, 1155.20it/s, train_loss=0.83] \u001b[A\n",
            "Epoch 1:   9%|▉         | 18784/214001 [00:18<02:48, 1155.20it/s, train_loss=0.829]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18816/214001 [00:18<02:48, 1155.20it/s, train_loss=0.827]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18848/214001 [00:18<02:45, 1179.25it/s, train_loss=0.827]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18848/214001 [00:18<02:45, 1179.25it/s, train_loss=0.826]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18880/214001 [00:18<02:45, 1179.25it/s, train_loss=0.824]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18912/214001 [00:18<02:45, 1179.25it/s, train_loss=0.822]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18944/214001 [00:18<02:45, 1179.25it/s, train_loss=0.821]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18976/214001 [00:18<02:42, 1203.28it/s, train_loss=0.821]\u001b[A\n",
            "Epoch 1:   9%|▉         | 18976/214001 [00:18<02:42, 1203.28it/s, train_loss=0.819]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19008/214001 [00:18<02:42, 1203.28it/s, train_loss=0.817]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19040/214001 [00:18<02:42, 1203.28it/s, train_loss=0.816]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19072/214001 [00:18<02:41, 1203.28it/s, train_loss=0.814]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19104/214001 [00:18<02:39, 1221.26it/s, train_loss=0.814]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19104/214001 [00:18<02:39, 1221.26it/s, train_loss=0.813]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19136/214001 [00:18<02:39, 1221.26it/s, train_loss=0.811]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19168/214001 [00:18<02:39, 1221.26it/s, train_loss=0.81] \u001b[A\n",
            "Epoch 1:   9%|▉         | 19200/214001 [00:18<02:39, 1221.26it/s, train_loss=0.809]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19232/214001 [00:18<02:40, 1216.21it/s, train_loss=0.809]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19232/214001 [00:18<02:40, 1216.21it/s, train_loss=0.808]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19264/214001 [00:18<02:40, 1216.21it/s, train_loss=0.806]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19296/214001 [00:18<02:40, 1216.21it/s, train_loss=0.805]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19328/214001 [00:18<02:40, 1216.21it/s, train_loss=0.804]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19360/214001 [00:18<02:38, 1227.74it/s, train_loss=0.804]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19360/214001 [00:18<02:38, 1227.74it/s, train_loss=0.803]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19392/214001 [00:18<02:38, 1227.74it/s, train_loss=0.802]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19424/214001 [00:18<02:38, 1227.74it/s, train_loss=0.801]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19456/214001 [00:18<02:38, 1227.74it/s, train_loss=0.8]  \u001b[A\n",
            "Epoch 1:   9%|▉         | 19488/214001 [00:18<02:39, 1220.57it/s, train_loss=0.8]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19488/214001 [00:18<02:39, 1220.57it/s, train_loss=0.799]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19520/214001 [00:18<02:39, 1220.57it/s, train_loss=0.797]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19552/214001 [00:18<02:39, 1220.57it/s, train_loss=0.796]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19584/214001 [00:18<02:39, 1220.57it/s, train_loss=0.795]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19616/214001 [00:18<02:38, 1226.78it/s, train_loss=0.795]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19616/214001 [00:18<02:38, 1226.78it/s, train_loss=0.794]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19648/214001 [00:18<02:38, 1226.78it/s, train_loss=0.793]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19680/214001 [00:18<02:38, 1226.78it/s, train_loss=0.792]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19712/214001 [00:19<02:38, 1226.78it/s, train_loss=0.79] \u001b[A\n",
            "Epoch 1:   9%|▉         | 19744/214001 [00:19<02:38, 1226.62it/s, train_loss=0.79]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19744/214001 [00:19<02:38, 1226.62it/s, train_loss=0.789]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19776/214001 [00:19<02:38, 1226.62it/s, train_loss=0.788]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19808/214001 [00:19<02:38, 1226.62it/s, train_loss=0.787]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19840/214001 [00:19<02:38, 1226.62it/s, train_loss=0.786]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19872/214001 [00:19<02:39, 1214.21it/s, train_loss=0.786]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19872/214001 [00:19<02:39, 1214.21it/s, train_loss=0.785]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19904/214001 [00:19<02:39, 1214.21it/s, train_loss=0.785]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19936/214001 [00:19<02:39, 1214.21it/s, train_loss=0.784]\u001b[A\n",
            "Epoch 1:   9%|▉         | 19968/214001 [00:19<02:39, 1214.21it/s, train_loss=0.783]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20000/214001 [00:19<02:38, 1222.87it/s, train_loss=0.783]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20000/214001 [00:19<02:38, 1222.87it/s, train_loss=0.782]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20032/214001 [00:19<02:38, 1222.87it/s, train_loss=0.781]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20064/214001 [00:19<02:38, 1222.87it/s, train_loss=0.78] \u001b[A\n",
            "Epoch 1:   9%|▉         | 20096/214001 [00:19<02:38, 1222.87it/s, train_loss=0.779]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20128/214001 [00:19<02:38, 1222.87it/s, train_loss=0.778]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20160/214001 [00:19<02:35, 1248.23it/s, train_loss=0.778]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20160/214001 [00:19<02:35, 1248.23it/s, train_loss=0.777]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20192/214001 [00:19<02:35, 1248.23it/s, train_loss=0.776]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20224/214001 [00:19<02:35, 1248.23it/s, train_loss=0.775]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20256/214001 [00:19<02:35, 1248.23it/s, train_loss=0.774]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20288/214001 [00:19<02:34, 1253.67it/s, train_loss=0.774]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20288/214001 [00:19<02:34, 1253.67it/s, train_loss=0.773]\u001b[A\n",
            "Epoch 1:   9%|▉         | 20320/214001 [00:19<02:34, 1253.67it/s, train_loss=0.772]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20352/214001 [00:19<02:34, 1253.67it/s, train_loss=0.771]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20384/214001 [00:19<02:34, 1253.67it/s, train_loss=0.77] \u001b[A\n",
            "Epoch 1:  10%|▉         | 20416/214001 [00:19<02:35, 1243.95it/s, train_loss=0.77]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20416/214001 [00:19<02:35, 1243.95it/s, train_loss=0.769]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20448/214001 [00:19<02:35, 1243.95it/s, train_loss=0.768]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20480/214001 [00:19<02:35, 1243.95it/s, train_loss=0.767]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20512/214001 [00:19<02:35, 1243.95it/s, train_loss=0.766]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20544/214001 [00:19<02:34, 1250.86it/s, train_loss=0.766]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20544/214001 [00:19<02:34, 1250.86it/s, train_loss=0.765]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20576/214001 [00:19<02:34, 1250.86it/s, train_loss=0.764]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20608/214001 [00:19<02:34, 1250.86it/s, train_loss=0.764]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20640/214001 [00:19<02:34, 1250.86it/s, train_loss=0.762]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20672/214001 [00:19<02:35, 1243.29it/s, train_loss=0.762]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20672/214001 [00:19<02:35, 1243.29it/s, train_loss=0.761]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20704/214001 [00:19<02:35, 1243.29it/s, train_loss=0.76] \u001b[A\n",
            "Epoch 1:  10%|▉         | 20736/214001 [00:19<02:35, 1243.29it/s, train_loss=0.759]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20768/214001 [00:19<02:35, 1243.29it/s, train_loss=0.759]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20800/214001 [00:19<02:35, 1243.23it/s, train_loss=0.759]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20800/214001 [00:19<02:35, 1243.23it/s, train_loss=0.758]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20832/214001 [00:19<02:35, 1243.23it/s, train_loss=0.757]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20864/214001 [00:19<02:35, 1243.23it/s, train_loss=0.756]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20896/214001 [00:19<02:35, 1243.23it/s, train_loss=0.754]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20928/214001 [00:19<02:35, 1242.47it/s, train_loss=0.754]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20928/214001 [00:19<02:35, 1242.47it/s, train_loss=0.753]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20960/214001 [00:20<02:35, 1242.47it/s, train_loss=0.752]\u001b[A\n",
            "Epoch 1:  10%|▉         | 20992/214001 [00:20<02:35, 1242.47it/s, train_loss=0.751]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21024/214001 [00:20<02:35, 1242.47it/s, train_loss=0.75] \u001b[A\n",
            "Epoch 1:  10%|▉         | 21056/214001 [00:20<02:34, 1248.65it/s, train_loss=0.75]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21056/214001 [00:20<02:34, 1248.65it/s, train_loss=0.749]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21088/214001 [00:20<02:34, 1248.65it/s, train_loss=0.748]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21120/214001 [00:20<02:34, 1248.65it/s, train_loss=0.747]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21152/214001 [00:20<02:34, 1248.65it/s, train_loss=0.746]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21184/214001 [00:20<02:35, 1243.36it/s, train_loss=0.746]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21184/214001 [00:20<02:35, 1243.36it/s, train_loss=0.745]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21216/214001 [00:20<02:35, 1243.36it/s, train_loss=0.744]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21248/214001 [00:20<02:35, 1243.36it/s, train_loss=0.743]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21280/214001 [00:20<02:35, 1243.36it/s, train_loss=0.742]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21312/214001 [00:20<02:41, 1195.65it/s, train_loss=0.742]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21312/214001 [00:20<02:41, 1195.65it/s, train_loss=0.742]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21344/214001 [00:20<02:41, 1195.65it/s, train_loss=0.741]\u001b[A\n",
            "Epoch 1:  10%|▉         | 21376/214001 [00:20<02:41, 1195.65it/s, train_loss=0.74] \u001b[A\n",
            "Epoch 1:  10%|█         | 21408/214001 [00:20<02:41, 1195.65it/s, train_loss=0.74]\u001b[A\n",
            "Epoch 1:  10%|█         | 21440/214001 [00:20<02:43, 1176.88it/s, train_loss=0.74]\u001b[A\n",
            "Epoch 1:  10%|█         | 21440/214001 [00:20<02:43, 1176.88it/s, train_loss=0.738]\u001b[A\n",
            "Epoch 1:  10%|█         | 21472/214001 [00:20<02:43, 1176.88it/s, train_loss=0.737]\u001b[A\n",
            "Epoch 1:  10%|█         | 21504/214001 [00:20<02:43, 1176.88it/s, train_loss=0.737]\u001b[A\n",
            "Epoch 1:  10%|█         | 21536/214001 [00:20<02:43, 1176.88it/s, train_loss=0.736]\u001b[A\n",
            "Epoch 1:  10%|█         | 21568/214001 [00:20<02:47, 1145.67it/s, train_loss=0.736]\u001b[A\n",
            "Epoch 1:  10%|█         | 21568/214001 [00:20<02:47, 1145.67it/s, train_loss=0.735]\u001b[A\n",
            "Epoch 1:  10%|█         | 21600/214001 [00:20<02:47, 1145.67it/s, train_loss=0.735]\u001b[A\n",
            "Epoch 1:  10%|█         | 21632/214001 [00:20<02:47, 1145.67it/s, train_loss=0.734]\u001b[A\n",
            "Epoch 1:  10%|█         | 21664/214001 [00:20<02:47, 1145.67it/s, train_loss=0.732]\u001b[A\n",
            "Epoch 1:  10%|█         | 21696/214001 [00:20<02:43, 1177.60it/s, train_loss=0.732]\u001b[A\n",
            "Epoch 1:  10%|█         | 21696/214001 [00:20<02:43, 1177.60it/s, train_loss=0.732]\u001b[A\n",
            "Epoch 1:  10%|█         | 21728/214001 [00:20<02:43, 1177.60it/s, train_loss=0.731]\u001b[A\n",
            "Epoch 1:  10%|█         | 21760/214001 [00:20<02:43, 1177.60it/s, train_loss=0.73] \u001b[A\n",
            "Epoch 1:  10%|█         | 21792/214001 [00:20<02:43, 1177.60it/s, train_loss=0.729]\u001b[A\n",
            "Epoch 1:  10%|█         | 21824/214001 [00:20<02:43, 1177.60it/s, train_loss=0.728]\u001b[A\n",
            "Epoch 1:  10%|█         | 21856/214001 [00:20<02:38, 1213.29it/s, train_loss=0.728]\u001b[A\n",
            "Epoch 1:  10%|█         | 21856/214001 [00:20<02:38, 1213.29it/s, train_loss=0.727]\u001b[A\n",
            "Epoch 1:  10%|█         | 21888/214001 [00:20<02:38, 1213.29it/s, train_loss=0.725]\u001b[A\n",
            "Epoch 1:  10%|█         | 21920/214001 [00:20<02:38, 1213.29it/s, train_loss=0.724]\u001b[A\n",
            "Epoch 1:  10%|█         | 21952/214001 [00:20<02:38, 1213.29it/s, train_loss=0.724]\u001b[A\n",
            "Epoch 1:  10%|█         | 21984/214001 [00:20<02:37, 1218.26it/s, train_loss=0.724]\u001b[A\n",
            "Epoch 1:  10%|█         | 21984/214001 [00:20<02:37, 1218.26it/s, train_loss=0.723]\u001b[A\n",
            "Epoch 1:  10%|█         | 22016/214001 [00:20<02:37, 1218.26it/s, train_loss=0.723]\u001b[A\n",
            "Epoch 1:  10%|█         | 22048/214001 [00:20<02:37, 1218.26it/s, train_loss=0.722]\u001b[A\n",
            "Epoch 1:  10%|█         | 22080/214001 [00:20<02:37, 1218.26it/s, train_loss=0.721]\u001b[A\n",
            "Epoch 1:  10%|█         | 22112/214001 [00:20<02:37, 1218.26it/s, train_loss=0.72] \u001b[A\n",
            "Epoch 1:  10%|█         | 22144/214001 [00:20<02:33, 1246.69it/s, train_loss=0.72]\u001b[A\n",
            "Epoch 1:  10%|█         | 22144/214001 [00:20<02:33, 1246.69it/s, train_loss=0.719]\u001b[A\n",
            "Epoch 1:  10%|█         | 22176/214001 [00:21<02:33, 1246.69it/s, train_loss=0.719]\u001b[A\n",
            "Epoch 1:  10%|█         | 22208/214001 [00:21<02:33, 1246.69it/s, train_loss=0.718]\u001b[A\n",
            "Epoch 1:  10%|█         | 22240/214001 [00:21<02:33, 1246.69it/s, train_loss=0.718]\u001b[A\n",
            "Epoch 1:  10%|█         | 22272/214001 [00:21<02:32, 1254.67it/s, train_loss=0.718]\u001b[A\n",
            "Epoch 1:  10%|█         | 22272/214001 [00:21<02:32, 1254.67it/s, train_loss=0.717]\u001b[A\n",
            "Epoch 1:  10%|█         | 22304/214001 [00:21<02:32, 1254.67it/s, train_loss=0.717]\u001b[A\n",
            "Epoch 1:  10%|█         | 22336/214001 [00:21<02:32, 1254.67it/s, train_loss=0.716]\u001b[A\n",
            "Epoch 1:  10%|█         | 22368/214001 [00:21<02:32, 1254.67it/s, train_loss=0.716]\u001b[A\n",
            "Epoch 1:  10%|█         | 22400/214001 [00:21<02:32, 1259.16it/s, train_loss=0.716]\u001b[A\n",
            "Epoch 1:  10%|█         | 22400/214001 [00:21<02:32, 1259.16it/s, train_loss=0.715]\u001b[A\n",
            "Epoch 1:  10%|█         | 22432/214001 [00:21<02:32, 1259.16it/s, train_loss=0.714]\u001b[A\n",
            "Epoch 1:  10%|█         | 22464/214001 [00:21<02:32, 1259.16it/s, train_loss=0.713]\u001b[A\n",
            "Epoch 1:  11%|█         | 22496/214001 [00:21<02:32, 1259.16it/s, train_loss=0.712]\u001b[A\n",
            "Epoch 1:  11%|█         | 22528/214001 [00:21<02:35, 1229.04it/s, train_loss=0.712]\u001b[A\n",
            "Epoch 1:  11%|█         | 22528/214001 [00:21<02:35, 1229.04it/s, train_loss=0.711]\u001b[A\n",
            "Epoch 1:  11%|█         | 22560/214001 [00:21<02:35, 1229.04it/s, train_loss=0.71] \u001b[A\n",
            "Epoch 1:  11%|█         | 22592/214001 [00:21<02:35, 1229.04it/s, train_loss=0.71]\u001b[A\n",
            "Epoch 1:  11%|█         | 22624/214001 [00:21<02:35, 1229.04it/s, train_loss=0.709]\u001b[A\n",
            "Epoch 1:  11%|█         | 22656/214001 [00:21<02:35, 1230.63it/s, train_loss=0.709]\u001b[A\n",
            "Epoch 1:  11%|█         | 22656/214001 [00:21<02:35, 1230.63it/s, train_loss=0.708]\u001b[A\n",
            "Epoch 1:  11%|█         | 22688/214001 [00:21<02:35, 1230.63it/s, train_loss=0.707]\u001b[A\n",
            "Epoch 1:  11%|█         | 22720/214001 [00:21<02:35, 1230.63it/s, train_loss=0.706]\u001b[A\n",
            "Epoch 1:  11%|█         | 22752/214001 [00:21<02:35, 1230.63it/s, train_loss=0.706]\u001b[A\n",
            "Epoch 1:  11%|█         | 22784/214001 [00:21<02:35, 1231.83it/s, train_loss=0.706]\u001b[A\n",
            "Epoch 1:  11%|█         | 22784/214001 [00:21<02:35, 1231.83it/s, train_loss=0.705]\u001b[A\n",
            "Epoch 1:  11%|█         | 22816/214001 [00:21<02:35, 1231.83it/s, train_loss=0.703]\u001b[A\n",
            "Epoch 1:  11%|█         | 22848/214001 [00:21<02:35, 1231.83it/s, train_loss=0.703]\u001b[A\n",
            "Epoch 1:  11%|█         | 22880/214001 [00:21<02:35, 1231.83it/s, train_loss=0.703]\u001b[A\n",
            "Epoch 1:  11%|█         | 22912/214001 [00:21<02:35, 1228.08it/s, train_loss=0.703]\u001b[A\n",
            "Epoch 1:  11%|█         | 22912/214001 [00:21<02:35, 1228.08it/s, train_loss=0.702]\u001b[A\n",
            "Epoch 1:  11%|█         | 22944/214001 [00:21<02:35, 1228.08it/s, train_loss=0.701]\u001b[A\n",
            "Epoch 1:  11%|█         | 22976/214001 [00:21<02:35, 1228.08it/s, train_loss=0.701]\u001b[A\n",
            "Epoch 1:  11%|█         | 23008/214001 [00:21<02:35, 1228.08it/s, train_loss=0.7]  \u001b[A\n",
            "Epoch 1:  11%|█         | 23040/214001 [00:21<02:35, 1228.50it/s, train_loss=0.7]\u001b[A\n",
            "Epoch 1:  11%|█         | 23040/214001 [00:21<02:35, 1228.50it/s, train_loss=0.699]\u001b[A\n",
            "Epoch 1:  11%|█         | 23072/214001 [00:21<02:35, 1228.50it/s, train_loss=0.699]\u001b[A\n",
            "Epoch 1:  11%|█         | 23104/214001 [00:21<02:35, 1228.50it/s, train_loss=0.699]\u001b[A\n",
            "Epoch 1:  11%|█         | 23136/214001 [00:21<02:35, 1228.50it/s, train_loss=0.698]\u001b[A\n",
            "Epoch 1:  11%|█         | 23168/214001 [00:21<02:40, 1189.69it/s, train_loss=0.698]\u001b[A\n",
            "Epoch 1:  11%|█         | 23168/214001 [00:21<02:40, 1189.69it/s, train_loss=0.697]\u001b[A\n",
            "Epoch 1:  11%|█         | 23200/214001 [00:21<02:40, 1189.69it/s, train_loss=0.697]\u001b[A\n",
            "Epoch 1:  11%|█         | 23232/214001 [00:21<02:40, 1189.69it/s, train_loss=0.696]\u001b[A\n",
            "Epoch 1:  11%|█         | 23264/214001 [00:21<02:40, 1189.69it/s, train_loss=0.695]\u001b[A\n",
            "Epoch 1:  11%|█         | 23296/214001 [00:21<02:38, 1203.59it/s, train_loss=0.695]\u001b[A\n",
            "Epoch 1:  11%|█         | 23296/214001 [00:21<02:38, 1203.59it/s, train_loss=0.695]\u001b[A\n",
            "Epoch 1:  11%|█         | 23328/214001 [00:21<02:38, 1203.59it/s, train_loss=0.694]\u001b[A\n",
            "Epoch 1:  11%|█         | 23360/214001 [00:21<02:38, 1203.59it/s, train_loss=0.694]\u001b[A\n",
            "Epoch 1:  11%|█         | 23392/214001 [00:22<02:38, 1203.59it/s, train_loss=0.693]\u001b[A\n",
            "Epoch 1:  11%|█         | 23424/214001 [00:22<02:38, 1202.16it/s, train_loss=0.693]\u001b[A\n",
            "Epoch 1:  11%|█         | 23424/214001 [00:22<02:38, 1202.16it/s, train_loss=0.693]\u001b[A\n",
            "Epoch 1:  11%|█         | 23456/214001 [00:22<02:38, 1202.16it/s, train_loss=0.693]\u001b[A\n",
            "Epoch 1:  11%|█         | 23488/214001 [00:22<02:38, 1202.16it/s, train_loss=0.692]\u001b[A\n",
            "Epoch 1:  11%|█         | 23520/214001 [00:22<02:38, 1202.16it/s, train_loss=0.692]\u001b[A\n",
            "Epoch 1:  11%|█         | 23552/214001 [00:22<02:36, 1213.47it/s, train_loss=0.692]\u001b[A\n",
            "Epoch 1:  11%|█         | 23552/214001 [00:22<02:36, 1213.47it/s, train_loss=0.691]\u001b[A\n",
            "Epoch 1:  11%|█         | 23584/214001 [00:22<02:36, 1213.47it/s, train_loss=0.69] \u001b[A\n",
            "Epoch 1:  11%|█         | 23616/214001 [00:22<02:36, 1213.47it/s, train_loss=0.689]\u001b[A\n",
            "Epoch 1:  11%|█         | 23648/214001 [00:22<02:36, 1213.47it/s, train_loss=0.689]\u001b[A\n",
            "Epoch 1:  11%|█         | 23680/214001 [00:22<02:35, 1227.18it/s, train_loss=0.689]\u001b[A\n",
            "Epoch 1:  11%|█         | 23680/214001 [00:22<02:35, 1227.18it/s, train_loss=0.688]\u001b[A\n",
            "Epoch 1:  11%|█         | 23712/214001 [00:22<02:35, 1227.18it/s, train_loss=0.688]\u001b[A\n",
            "Epoch 1:  11%|█         | 23744/214001 [00:22<02:35, 1227.18it/s, train_loss=0.687]\u001b[A\n",
            "Epoch 1:  11%|█         | 23776/214001 [00:22<02:35, 1227.18it/s, train_loss=0.687]\u001b[A\n",
            "Epoch 1:  11%|█         | 23808/214001 [00:22<02:35, 1220.66it/s, train_loss=0.687]\u001b[A\n",
            "Epoch 1:  11%|█         | 23808/214001 [00:22<02:35, 1220.66it/s, train_loss=0.686]\u001b[A\n",
            "Epoch 1:  11%|█         | 23840/214001 [00:22<02:35, 1220.66it/s, train_loss=0.686]\u001b[A\n",
            "Epoch 1:  11%|█         | 23872/214001 [00:22<02:35, 1220.66it/s, train_loss=0.686]\u001b[A\n",
            "Epoch 1:  11%|█         | 23904/214001 [00:22<02:35, 1220.66it/s, train_loss=0.685]\u001b[A\n",
            "Epoch 1:  11%|█         | 23936/214001 [00:22<02:35, 1224.14it/s, train_loss=0.685]\u001b[A\n",
            "Epoch 1:  11%|█         | 23936/214001 [00:22<02:35, 1224.14it/s, train_loss=0.685]\u001b[A\n",
            "Epoch 1:  11%|█         | 23968/214001 [00:22<02:35, 1224.14it/s, train_loss=0.684]\u001b[A\n",
            "Epoch 1:  11%|█         | 24000/214001 [00:22<02:35, 1224.14it/s, train_loss=0.683]\u001b[A\n",
            "Epoch 1:  11%|█         | 24032/214001 [00:22<02:35, 1224.14it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1:  11%|█         | 24064/214001 [00:22<02:36, 1213.27it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1:  11%|█         | 24064/214001 [00:22<02:36, 1213.27it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24096/214001 [00:22<02:36, 1213.27it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24128/214001 [00:22<02:36, 1213.27it/s, train_loss=0.68] \u001b[A\n",
            "Epoch 1:  11%|█▏        | 24160/214001 [00:22<02:36, 1213.27it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24192/214001 [00:22<02:34, 1232.18it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24192/214001 [00:22<02:34, 1232.18it/s, train_loss=0.679]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24224/214001 [00:22<02:34, 1232.18it/s, train_loss=0.679]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24256/214001 [00:22<02:33, 1232.18it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24288/214001 [00:22<02:33, 1232.18it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24320/214001 [00:22<02:34, 1226.07it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24320/214001 [00:22<02:34, 1226.07it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24352/214001 [00:22<02:34, 1226.07it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24384/214001 [00:22<02:34, 1226.07it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24416/214001 [00:22<02:34, 1226.07it/s, train_loss=0.675]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24448/214001 [00:22<02:34, 1226.38it/s, train_loss=0.675]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24448/214001 [00:22<02:34, 1226.38it/s, train_loss=0.674]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24480/214001 [00:22<02:34, 1226.38it/s, train_loss=0.674]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24512/214001 [00:22<02:34, 1226.38it/s, train_loss=0.673]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24544/214001 [00:22<02:34, 1226.38it/s, train_loss=0.672]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24576/214001 [00:22<02:33, 1235.75it/s, train_loss=0.672]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24576/214001 [00:22<02:33, 1235.75it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 24608/214001 [00:23<02:33, 1235.75it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24640/214001 [00:23<02:33, 1235.75it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24672/214001 [00:23<02:33, 1235.75it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24704/214001 [00:23<02:34, 1223.76it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24704/214001 [00:23<02:34, 1223.76it/s, train_loss=0.67] \u001b[A\n",
            "Epoch 1:  12%|█▏        | 24736/214001 [00:23<02:34, 1223.76it/s, train_loss=0.67]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24768/214001 [00:23<02:34, 1223.76it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24800/214001 [00:23<02:34, 1223.76it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24832/214001 [00:23<02:34, 1224.57it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24832/214001 [00:23<02:34, 1224.57it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24864/214001 [00:23<02:34, 1224.57it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24896/214001 [00:23<02:34, 1224.57it/s, train_loss=0.666]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24928/214001 [00:23<02:34, 1224.57it/s, train_loss=0.666]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24960/214001 [00:23<02:34, 1222.10it/s, train_loss=0.666]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24960/214001 [00:23<02:34, 1222.10it/s, train_loss=0.665]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 24992/214001 [00:23<02:34, 1222.10it/s, train_loss=0.665]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25024/214001 [00:23<02:34, 1222.10it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25056/214001 [00:23<02:34, 1222.10it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25088/214001 [00:23<02:33, 1227.62it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25088/214001 [00:23<02:33, 1227.62it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25120/214001 [00:23<02:33, 1227.62it/s, train_loss=0.662]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25152/214001 [00:23<02:33, 1227.62it/s, train_loss=0.662]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25184/214001 [00:23<02:33, 1227.62it/s, train_loss=0.662]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25216/214001 [00:23<02:33, 1225.88it/s, train_loss=0.662]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25216/214001 [00:23<02:33, 1225.88it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25248/214001 [00:23<02:33, 1225.88it/s, train_loss=0.66] \u001b[A\n",
            "Epoch 1:  12%|█▏        | 25280/214001 [00:23<02:33, 1225.88it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25312/214001 [00:23<02:33, 1225.88it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25344/214001 [00:23<02:33, 1227.71it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25344/214001 [00:23<02:33, 1227.71it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25376/214001 [00:23<02:33, 1227.71it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25408/214001 [00:23<02:33, 1227.71it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25440/214001 [00:23<02:33, 1227.71it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25472/214001 [00:23<02:34, 1216.53it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25472/214001 [00:23<02:34, 1216.53it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25504/214001 [00:23<02:34, 1216.53it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25536/214001 [00:23<02:34, 1216.53it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25568/214001 [00:23<02:34, 1216.53it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25600/214001 [00:23<02:36, 1207.69it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25600/214001 [00:23<02:36, 1207.69it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25632/214001 [00:23<02:35, 1207.69it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25664/214001 [00:23<02:35, 1207.69it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25696/214001 [00:23<02:35, 1207.69it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25728/214001 [00:23<02:34, 1221.00it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25728/214001 [00:23<02:34, 1221.00it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25760/214001 [00:23<02:34, 1221.00it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25792/214001 [00:23<02:34, 1221.00it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25824/214001 [00:23<02:34, 1221.00it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25856/214001 [00:23<02:33, 1227.83it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25856/214001 [00:24<02:33, 1227.83it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25888/214001 [00:24<02:33, 1227.83it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  12%|█▏        | 25920/214001 [00:24<02:33, 1227.83it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25952/214001 [00:24<02:33, 1227.83it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25984/214001 [00:24<02:32, 1229.76it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 25984/214001 [00:24<02:32, 1229.76it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26016/214001 [00:24<02:32, 1229.76it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26048/214001 [00:24<02:32, 1229.76it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26080/214001 [00:24<02:32, 1229.76it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26112/214001 [00:24<02:33, 1224.48it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26112/214001 [00:24<02:33, 1224.48it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26144/214001 [00:24<02:33, 1224.48it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26176/214001 [00:24<02:33, 1224.48it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26208/214001 [00:24<02:33, 1224.48it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26240/214001 [00:24<02:36, 1201.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26240/214001 [00:24<02:36, 1201.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26272/214001 [00:24<02:36, 1201.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26304/214001 [00:24<02:36, 1201.57it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26336/214001 [00:24<02:36, 1201.57it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26368/214001 [00:24<02:35, 1203.58it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26368/214001 [00:24<02:35, 1203.58it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26400/214001 [00:24<02:35, 1203.58it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26432/214001 [00:24<02:35, 1203.58it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26464/214001 [00:24<02:35, 1203.58it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26496/214001 [00:24<02:34, 1211.27it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26496/214001 [00:24<02:34, 1211.27it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26528/214001 [00:24<02:34, 1211.27it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26560/214001 [00:24<02:34, 1211.27it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26592/214001 [00:24<02:34, 1211.27it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26624/214001 [00:24<02:34, 1213.50it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26624/214001 [00:24<02:34, 1213.50it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26656/214001 [00:24<02:34, 1213.50it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26688/214001 [00:24<02:34, 1213.50it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 26720/214001 [00:24<02:34, 1213.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26752/214001 [00:24<02:35, 1205.05it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26752/214001 [00:24<02:35, 1205.05it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26784/214001 [00:24<02:35, 1205.05it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26816/214001 [00:24<02:35, 1205.05it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26848/214001 [00:24<02:35, 1205.05it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  13%|█▎        | 26880/214001 [00:24<02:34, 1211.20it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26880/214001 [00:24<02:34, 1211.20it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26912/214001 [00:24<02:34, 1211.20it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26944/214001 [00:24<02:34, 1211.20it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 26976/214001 [00:24<02:34, 1211.20it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27008/214001 [00:24<02:33, 1216.35it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27008/214001 [00:24<02:33, 1216.35it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27040/214001 [00:25<02:33, 1216.35it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27072/214001 [00:25<02:33, 1216.35it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27104/214001 [00:25<02:33, 1216.35it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27136/214001 [00:25<02:34, 1212.39it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27136/214001 [00:25<02:34, 1212.39it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27168/214001 [00:25<02:34, 1212.39it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27200/214001 [00:25<02:34, 1212.39it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27232/214001 [00:25<02:34, 1212.39it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27264/214001 [00:25<02:33, 1214.10it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27264/214001 [00:25<02:33, 1214.10it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27296/214001 [00:25<02:33, 1214.10it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27328/214001 [00:25<02:33, 1214.10it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27360/214001 [00:25<02:33, 1214.10it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27392/214001 [00:25<02:38, 1178.74it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27392/214001 [00:25<02:38, 1178.74it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27424/214001 [00:25<02:38, 1178.74it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27456/214001 [00:25<02:38, 1178.74it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27488/214001 [00:25<02:38, 1178.74it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27520/214001 [00:25<02:41, 1154.94it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27520/214001 [00:25<02:41, 1154.94it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27552/214001 [00:25<02:41, 1154.94it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27584/214001 [00:25<02:41, 1154.94it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27616/214001 [00:25<02:41, 1154.94it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27648/214001 [00:25<02:42, 1148.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27648/214001 [00:25<02:42, 1148.83it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27680/214001 [00:25<02:42, 1148.83it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27712/214001 [00:25<02:42, 1148.83it/s, train_loss=0.63] \u001b[A\n",
            "Epoch 1:  13%|█▎        | 27744/214001 [00:25<02:42, 1148.83it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27776/214001 [00:25<02:45, 1126.39it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27776/214001 [00:25<02:45, 1126.39it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27808/214001 [00:25<02:45, 1126.39it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27840/214001 [00:25<02:45, 1126.39it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27872/214001 [00:25<02:45, 1126.39it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27904/214001 [00:25<02:45, 1125.95it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27904/214001 [00:25<02:45, 1125.95it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27936/214001 [00:25<02:45, 1125.95it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 27968/214001 [00:25<02:45, 1125.95it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28000/214001 [00:25<02:45, 1125.95it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28032/214001 [00:25<02:46, 1115.04it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28032/214001 [00:25<02:46, 1115.04it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28064/214001 [00:25<02:46, 1115.04it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28096/214001 [00:25<02:46, 1115.04it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28128/214001 [00:25<02:46, 1115.04it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28160/214001 [00:25<02:45, 1121.76it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28160/214001 [00:25<02:45, 1121.76it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28192/214001 [00:26<02:45, 1121.76it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28224/214001 [00:26<02:45, 1121.76it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28256/214001 [00:26<02:45, 1121.76it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28288/214001 [00:26<02:45, 1121.32it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28288/214001 [00:26<02:45, 1121.32it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28320/214001 [00:26<02:45, 1121.32it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28352/214001 [00:26<02:45, 1121.32it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28384/214001 [00:26<02:45, 1121.32it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28416/214001 [00:26<02:43, 1133.86it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28416/214001 [00:26<02:43, 1133.86it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28448/214001 [00:26<02:43, 1133.86it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28480/214001 [00:26<02:43, 1133.86it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28512/214001 [00:26<02:43, 1133.86it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28544/214001 [00:26<02:39, 1161.47it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28544/214001 [00:26<02:39, 1161.47it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28576/214001 [00:26<02:39, 1161.47it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28608/214001 [00:26<02:39, 1161.47it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28640/214001 [00:26<02:39, 1161.47it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28672/214001 [00:26<02:39, 1161.69it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28672/214001 [00:26<02:39, 1161.69it/s, train_loss=0.62] \u001b[A\n",
            "Epoch 1:  13%|█▎        | 28704/214001 [00:26<02:39, 1161.69it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28736/214001 [00:26<02:39, 1161.69it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28768/214001 [00:26<02:39, 1161.69it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28800/214001 [00:26<02:48, 1099.35it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28800/214001 [00:26<02:48, 1099.35it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28832/214001 [00:26<02:48, 1099.35it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 28864/214001 [00:26<02:48, 1099.35it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 28896/214001 [00:26<02:48, 1099.35it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 28928/214001 [00:26<02:52, 1071.36it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 28928/214001 [00:26<02:52, 1071.36it/s, train_loss=0.62] \u001b[A\n",
            "Epoch 1:  14%|█▎        | 28960/214001 [00:26<02:52, 1071.36it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 28992/214001 [00:26<02:52, 1071.36it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29024/214001 [00:26<02:52, 1071.36it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29056/214001 [00:26<02:58, 1033.67it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29056/214001 [00:26<02:58, 1033.67it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29088/214001 [00:26<02:58, 1033.67it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29120/214001 [00:26<02:58, 1033.67it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29152/214001 [00:26<02:58, 1033.67it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29184/214001 [00:26<02:56, 1047.50it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29184/214001 [00:26<02:56, 1047.50it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29216/214001 [00:26<02:56, 1047.50it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29248/214001 [00:27<02:56, 1047.50it/s, train_loss=0.618]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29280/214001 [00:27<02:56, 1047.50it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29312/214001 [00:27<02:57, 1041.17it/s, train_loss=0.619]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29312/214001 [00:27<02:57, 1041.17it/s, train_loss=0.618]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29344/214001 [00:27<02:57, 1041.17it/s, train_loss=0.617]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29376/214001 [00:27<02:57, 1041.17it/s, train_loss=0.617]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 29408/214001 [00:27<02:57, 1041.17it/s, train_loss=0.616]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29440/214001 [00:27<03:00, 1025.22it/s, train_loss=0.616]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29440/214001 [00:27<03:00, 1025.22it/s, train_loss=0.616]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29472/214001 [00:27<02:59, 1025.22it/s, train_loss=0.616]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29504/214001 [00:27<02:59, 1025.22it/s, train_loss=0.616]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29536/214001 [00:27<02:59, 1025.22it/s, train_loss=0.616]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29568/214001 [00:27<02:59, 1029.55it/s, train_loss=0.616]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29568/214001 [00:27<02:59, 1029.55it/s, train_loss=0.616]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29600/214001 [00:27<02:59, 1029.55it/s, train_loss=0.615]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29632/214001 [00:27<02:59, 1029.55it/s, train_loss=0.615]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29664/214001 [00:27<02:59, 1029.55it/s, train_loss=0.614]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29696/214001 [00:27<02:56, 1042.94it/s, train_loss=0.614]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29696/214001 [00:27<02:56, 1042.94it/s, train_loss=0.614]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29728/214001 [00:27<02:56, 1042.94it/s, train_loss=0.613]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29760/214001 [00:27<02:56, 1042.94it/s, train_loss=0.613]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29792/214001 [00:27<02:56, 1042.94it/s, train_loss=0.613]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29824/214001 [00:27<03:00, 1017.99it/s, train_loss=0.613]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29824/214001 [00:27<03:00, 1017.99it/s, train_loss=0.612]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29856/214001 [00:27<03:00, 1017.99it/s, train_loss=0.612]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29888/214001 [00:27<03:00, 1017.99it/s, train_loss=0.612]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29920/214001 [00:27<03:00, 1017.99it/s, train_loss=0.612]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29952/214001 [00:27<03:00, 1019.26it/s, train_loss=0.612]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29952/214001 [00:27<03:00, 1019.26it/s, train_loss=0.612]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 29984/214001 [00:27<03:00, 1019.26it/s, train_loss=0.612]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30016/214001 [00:27<03:00, 1019.26it/s, train_loss=0.61] \u001b[A\n",
            "Epoch 1:  14%|█▍        | 30048/214001 [00:27<03:00, 1019.26it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30080/214001 [00:27<03:02, 1009.72it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30080/214001 [00:27<03:02, 1009.72it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30112/214001 [00:27<03:02, 1009.72it/s, train_loss=0.61]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30144/214001 [00:27<03:02, 1009.72it/s, train_loss=0.609]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30176/214001 [00:27<03:02, 1009.72it/s, train_loss=0.609]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30208/214001 [00:27<03:05, 990.98it/s, train_loss=0.609] \u001b[A\n",
            "Epoch 1:  14%|█▍        | 30208/214001 [00:27<03:05, 990.98it/s, train_loss=0.609]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30240/214001 [00:28<03:05, 990.98it/s, train_loss=0.609]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30272/214001 [00:28<03:05, 990.98it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30304/214001 [00:28<03:05, 990.98it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30336/214001 [00:28<03:07, 980.79it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30336/214001 [00:28<03:07, 980.79it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30368/214001 [00:28<03:07, 980.79it/s, train_loss=0.608]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30400/214001 [00:28<03:07, 980.79it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30432/214001 [00:28<03:07, 980.79it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30464/214001 [00:28<03:11, 956.86it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30464/214001 [00:28<03:11, 956.86it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30496/214001 [00:28<03:11, 956.86it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30528/214001 [00:28<03:11, 956.86it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30560/214001 [00:28<03:14, 945.27it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30560/214001 [00:28<03:14, 945.27it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30592/214001 [00:28<03:14, 945.27it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30624/214001 [00:28<03:13, 945.27it/s, train_loss=0.607]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30656/214001 [00:28<03:13, 945.27it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30688/214001 [00:28<03:10, 963.91it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30688/214001 [00:28<03:10, 963.91it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30720/214001 [00:28<03:10, 963.91it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30752/214001 [00:28<03:10, 963.91it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30784/214001 [00:28<03:10, 963.91it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30816/214001 [00:28<03:13, 945.61it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30816/214001 [00:28<03:13, 945.61it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30848/214001 [00:28<03:13, 945.61it/s, train_loss=0.606]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30880/214001 [00:28<03:13, 945.61it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30912/214001 [00:28<03:13, 944.75it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30912/214001 [00:28<03:13, 944.75it/s, train_loss=0.605]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30944/214001 [00:28<03:13, 944.75it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 30976/214001 [00:28<03:13, 944.75it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 31008/214001 [00:28<03:13, 944.75it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31040/214001 [00:28<03:12, 950.88it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31040/214001 [00:28<03:12, 950.88it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31072/214001 [00:28<03:12, 950.88it/s, train_loss=0.604]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31104/214001 [00:28<03:12, 950.88it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31136/214001 [00:28<03:12, 950.88it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31168/214001 [00:28<03:08, 969.53it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31168/214001 [00:28<03:08, 969.53it/s, train_loss=0.603]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31200/214001 [00:29<03:08, 969.53it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31232/214001 [00:29<03:08, 969.53it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31264/214001 [00:29<03:08, 969.53it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31296/214001 [00:29<03:04, 988.62it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31296/214001 [00:29<03:04, 988.62it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31328/214001 [00:29<03:04, 988.62it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31360/214001 [00:29<03:04, 988.62it/s, train_loss=0.602]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31392/214001 [00:29<03:04, 988.62it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31424/214001 [00:29<02:52, 1060.81it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31424/214001 [00:29<02:52, 1060.81it/s, train_loss=0.601]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31456/214001 [00:29<02:52, 1060.81it/s, train_loss=0.6]  \u001b[A\n",
            "Epoch 1:  15%|█▍        | 31488/214001 [00:29<02:52, 1060.81it/s, train_loss=0.6]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31520/214001 [00:29<02:52, 1060.81it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31552/214001 [00:29<02:43, 1115.70it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31552/214001 [00:29<02:43, 1115.70it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31584/214001 [00:29<02:43, 1115.70it/s, train_loss=0.599]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31616/214001 [00:29<02:43, 1115.70it/s, train_loss=0.598]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31648/214001 [00:29<02:43, 1115.70it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31680/214001 [00:29<02:50, 1067.19it/s, train_loss=0.597]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31680/214001 [00:29<02:50, 1067.19it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31712/214001 [00:29<02:50, 1067.19it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31744/214001 [00:29<02:50, 1067.19it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31776/214001 [00:29<02:50, 1067.19it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31808/214001 [00:29<02:52, 1053.17it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31808/214001 [00:29<02:52, 1053.17it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31840/214001 [00:29<02:52, 1053.17it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31872/214001 [00:29<02:52, 1053.17it/s, train_loss=0.596]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31904/214001 [00:29<02:52, 1053.17it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31936/214001 [00:29<02:59, 1016.98it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31936/214001 [00:29<02:59, 1016.98it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 31968/214001 [00:29<02:58, 1016.98it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 32000/214001 [00:29<02:58, 1016.98it/s, train_loss=0.595]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 32032/214001 [00:29<02:58, 1016.98it/s, train_loss=0.594]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 32064/214001 [00:29<02:54, 1042.54it/s, train_loss=0.594]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 32064/214001 [00:29<02:54, 1042.54it/s, train_loss=0.594]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 32096/214001 [00:29<02:54, 1042.54it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32128/214001 [00:29<02:54, 1042.54it/s, train_loss=0.593]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32160/214001 [00:29<02:54, 1042.54it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32192/214001 [00:29<02:47, 1088.00it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32192/214001 [00:29<02:47, 1088.00it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32224/214001 [00:29<02:47, 1088.00it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32256/214001 [00:29<02:47, 1088.00it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32288/214001 [00:30<02:47, 1088.00it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32320/214001 [00:30<02:49, 1072.99it/s, train_loss=0.592]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32320/214001 [00:30<02:49, 1072.99it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32352/214001 [00:30<02:49, 1072.99it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32384/214001 [00:30<02:49, 1072.99it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32416/214001 [00:30<02:49, 1072.99it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32448/214001 [00:30<02:52, 1051.24it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32448/214001 [00:30<02:52, 1051.24it/s, train_loss=0.591]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32480/214001 [00:30<02:52, 1051.24it/s, train_loss=0.59] \u001b[A\n",
            "Epoch 1:  15%|█▌        | 32512/214001 [00:30<02:52, 1051.24it/s, train_loss=0.59]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32544/214001 [00:30<02:52, 1051.24it/s, train_loss=0.59]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32576/214001 [00:30<02:59, 1012.50it/s, train_loss=0.59]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32576/214001 [00:30<02:59, 1012.50it/s, train_loss=0.59]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32608/214001 [00:30<02:59, 1012.50it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32640/214001 [00:30<02:59, 1012.50it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32672/214001 [00:30<02:59, 1012.50it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32704/214001 [00:30<03:06, 972.73it/s, train_loss=0.589] \u001b[A\n",
            "Epoch 1:  15%|█▌        | 32704/214001 [00:30<03:06, 972.73it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32736/214001 [00:30<03:06, 972.73it/s, train_loss=0.589]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32768/214001 [00:30<03:06, 972.73it/s, train_loss=0.588]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32800/214001 [00:30<03:06, 972.73it/s, train_loss=0.587]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32832/214001 [00:30<03:07, 964.59it/s, train_loss=0.587]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32832/214001 [00:30<03:07, 964.59it/s, train_loss=0.587]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32864/214001 [00:30<03:07, 964.59it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32896/214001 [00:30<03:07, 964.59it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32928/214001 [00:30<03:07, 964.59it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32960/214001 [00:30<03:04, 982.90it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32960/214001 [00:30<03:04, 982.90it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 32992/214001 [00:30<03:04, 982.90it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 33024/214001 [00:30<03:04, 982.90it/s, train_loss=0.585]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 33056/214001 [00:30<03:04, 982.90it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 33088/214001 [00:30<02:56, 1027.46it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 33088/214001 [00:30<02:56, 1027.46it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 33120/214001 [00:30<02:56, 1027.46it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 33152/214001 [00:30<02:56, 1027.46it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33184/214001 [00:30<02:55, 1027.46it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33216/214001 [00:30<02:48, 1073.98it/s, train_loss=0.586]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33216/214001 [00:30<02:48, 1073.98it/s, train_loss=0.585]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33248/214001 [00:30<02:48, 1073.98it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33280/214001 [00:30<02:48, 1073.98it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33312/214001 [00:31<02:48, 1073.98it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33344/214001 [00:31<02:53, 1041.07it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33344/214001 [00:31<02:53, 1041.07it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33376/214001 [00:31<02:53, 1041.07it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33408/214001 [00:31<02:53, 1041.07it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33440/214001 [00:31<02:53, 1041.07it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33472/214001 [00:31<02:49, 1067.31it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33472/214001 [00:31<02:49, 1067.31it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33504/214001 [00:31<02:49, 1067.31it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33536/214001 [00:31<02:49, 1067.31it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33568/214001 [00:31<02:49, 1067.31it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33600/214001 [00:31<02:47, 1077.52it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33600/214001 [00:31<02:47, 1077.52it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33632/214001 [00:31<02:47, 1077.52it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33664/214001 [00:31<02:47, 1077.52it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33696/214001 [00:31<02:47, 1077.52it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33728/214001 [00:31<02:46, 1079.93it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33728/214001 [00:31<02:46, 1079.93it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33760/214001 [00:31<02:46, 1079.93it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33792/214001 [00:31<02:46, 1079.93it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33824/214001 [00:31<02:46, 1079.93it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33856/214001 [00:31<02:41, 1113.88it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33856/214001 [00:31<02:41, 1113.88it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33888/214001 [00:31<02:41, 1113.88it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33920/214001 [00:31<02:41, 1113.88it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33952/214001 [00:31<02:41, 1113.88it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33984/214001 [00:31<02:43, 1100.34it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 33984/214001 [00:31<02:43, 1100.34it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34016/214001 [00:31<02:43, 1100.34it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34048/214001 [00:31<02:43, 1100.34it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34080/214001 [00:31<02:43, 1100.34it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34112/214001 [00:31<02:45, 1086.10it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34112/214001 [00:31<02:45, 1086.10it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34144/214001 [00:31<02:45, 1086.10it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34176/214001 [00:31<02:45, 1086.10it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34208/214001 [00:31<02:45, 1086.10it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34240/214001 [00:31<02:43, 1097.39it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34240/214001 [00:31<02:43, 1097.39it/s, train_loss=0.584]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34272/214001 [00:31<02:43, 1097.39it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34304/214001 [00:31<02:43, 1097.39it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34336/214001 [00:31<02:43, 1097.39it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34368/214001 [00:31<02:40, 1121.83it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34368/214001 [00:31<02:40, 1121.83it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34400/214001 [00:31<02:40, 1121.83it/s, train_loss=0.583]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34432/214001 [00:32<02:40, 1121.83it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34464/214001 [00:32<02:40, 1121.83it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34496/214001 [00:32<02:36, 1150.52it/s, train_loss=0.582]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34496/214001 [00:32<02:36, 1150.52it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34528/214001 [00:32<02:35, 1150.52it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34560/214001 [00:32<02:35, 1150.52it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34592/214001 [00:32<02:35, 1150.52it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34624/214001 [00:32<02:38, 1131.20it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34624/214001 [00:32<02:38, 1131.20it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34656/214001 [00:32<02:38, 1131.20it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34688/214001 [00:32<02:38, 1131.20it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34720/214001 [00:32<02:38, 1131.20it/s, train_loss=0.58] \u001b[A\n",
            "Epoch 1:  16%|█▌        | 34752/214001 [00:32<02:48, 1061.65it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 34752/214001 [00:32<02:48, 1061.65it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 34784/214001 [00:32<02:48, 1061.65it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 34816/214001 [00:32<02:48, 1061.65it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 34848/214001 [00:32<02:48, 1061.65it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 34880/214001 [00:32<02:49, 1055.82it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 34880/214001 [00:32<02:49, 1055.82it/s, train_loss=0.58] \u001b[A\n",
            "Epoch 1:  16%|█▋        | 34912/214001 [00:32<02:49, 1055.82it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 34944/214001 [00:32<02:49, 1055.82it/s, train_loss=0.581]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 34976/214001 [00:32<02:49, 1055.82it/s, train_loss=0.58] \u001b[A\n",
            "Epoch 1:  16%|█▋        | 35008/214001 [00:32<02:55, 1022.68it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35008/214001 [00:32<02:55, 1022.68it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35040/214001 [00:32<02:54, 1022.68it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35072/214001 [00:32<02:54, 1022.68it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35104/214001 [00:32<02:54, 1022.68it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35136/214001 [00:32<02:57, 1007.87it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35136/214001 [00:32<02:57, 1007.87it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35168/214001 [00:32<02:57, 1007.87it/s, train_loss=0.58]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35200/214001 [00:32<02:57, 1007.87it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35232/214001 [00:32<02:57, 1007.87it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35264/214001 [00:32<02:55, 1021.13it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35264/214001 [00:32<02:55, 1021.13it/s, train_loss=0.579]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 35296/214001 [00:32<02:55, 1021.13it/s, train_loss=0.578]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35328/214001 [00:32<02:54, 1021.13it/s, train_loss=0.578]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35360/214001 [00:32<02:54, 1021.13it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35392/214001 [00:32<02:45, 1079.52it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35392/214001 [00:32<02:45, 1079.52it/s, train_loss=0.577]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35424/214001 [00:32<02:45, 1079.52it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35456/214001 [00:32<02:45, 1079.52it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35488/214001 [00:33<02:45, 1079.52it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35520/214001 [00:33<02:38, 1129.27it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35520/214001 [00:33<02:38, 1129.27it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35552/214001 [00:33<02:38, 1129.27it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35584/214001 [00:33<02:37, 1129.27it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35616/214001 [00:33<02:37, 1129.27it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35648/214001 [00:33<02:33, 1162.72it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35648/214001 [00:33<02:33, 1162.72it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35680/214001 [00:33<02:33, 1162.72it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35712/214001 [00:33<02:33, 1162.72it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35744/214001 [00:33<02:33, 1162.72it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35776/214001 [00:33<02:30, 1181.91it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35776/214001 [00:33<02:30, 1181.91it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35808/214001 [00:33<02:30, 1181.91it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35840/214001 [00:33<02:30, 1181.91it/s, train_loss=0.576]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35872/214001 [00:33<02:30, 1181.91it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35904/214001 [00:33<02:29, 1195.05it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35904/214001 [00:33<02:29, 1195.05it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35936/214001 [00:33<02:29, 1195.05it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 35968/214001 [00:33<02:28, 1195.05it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36000/214001 [00:33<02:28, 1195.05it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36032/214001 [00:33<02:26, 1217.24it/s, train_loss=0.575]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36032/214001 [00:33<02:26, 1217.24it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36064/214001 [00:33<02:26, 1217.24it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36096/214001 [00:33<02:26, 1217.24it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36128/214001 [00:33<02:26, 1217.24it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36160/214001 [00:33<02:24, 1227.92it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36160/214001 [00:33<02:24, 1227.92it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36192/214001 [00:33<02:24, 1227.92it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36224/214001 [00:33<02:24, 1227.92it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36256/214001 [00:33<02:24, 1227.92it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36288/214001 [00:33<02:24, 1227.89it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36288/214001 [00:33<02:24, 1227.89it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36320/214001 [00:33<02:24, 1227.89it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36352/214001 [00:33<02:24, 1227.89it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36384/214001 [00:33<02:24, 1227.89it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36416/214001 [00:33<02:24, 1229.54it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36416/214001 [00:33<02:24, 1229.54it/s, train_loss=0.574]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36448/214001 [00:33<02:24, 1229.54it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36480/214001 [00:33<02:24, 1229.54it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36512/214001 [00:33<02:24, 1229.54it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36544/214001 [00:33<02:30, 1176.75it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36544/214001 [00:33<02:30, 1176.75it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36576/214001 [00:33<02:30, 1176.75it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36608/214001 [00:33<02:30, 1176.75it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36640/214001 [00:33<02:30, 1176.75it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36672/214001 [00:33<02:30, 1178.26it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36672/214001 [00:33<02:30, 1178.26it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36704/214001 [00:34<02:30, 1178.26it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36736/214001 [00:34<02:30, 1178.26it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36768/214001 [00:34<02:30, 1178.26it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36800/214001 [00:34<02:31, 1169.09it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36800/214001 [00:34<02:31, 1169.09it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36832/214001 [00:34<02:31, 1169.09it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36864/214001 [00:34<02:31, 1169.09it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36896/214001 [00:34<02:31, 1169.09it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36928/214001 [00:34<02:38, 1116.32it/s, train_loss=0.573]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36928/214001 [00:34<02:38, 1116.32it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36960/214001 [00:34<02:38, 1116.32it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 36992/214001 [00:34<02:38, 1116.32it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37024/214001 [00:34<02:38, 1116.32it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37056/214001 [00:34<02:38, 1113.17it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37056/214001 [00:34<02:38, 1113.17it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37088/214001 [00:34<02:38, 1113.17it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37120/214001 [00:34<02:38, 1113.17it/s, train_loss=0.572]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37152/214001 [00:34<02:38, 1113.17it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37184/214001 [00:34<02:40, 1102.05it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37184/214001 [00:34<02:40, 1102.05it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37216/214001 [00:34<02:40, 1102.05it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37248/214001 [00:34<02:40, 1102.05it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37280/214001 [00:34<02:40, 1102.05it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37312/214001 [00:34<02:41, 1093.94it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37312/214001 [00:34<02:41, 1093.94it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37344/214001 [00:34<02:41, 1093.94it/s, train_loss=0.571]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37376/214001 [00:34<02:41, 1093.94it/s, train_loss=0.57] \u001b[A\n",
            "Epoch 1:  17%|█▋        | 37408/214001 [00:34<02:41, 1093.94it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37440/214001 [00:34<02:42, 1088.02it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 37440/214001 [00:34<02:42, 1088.02it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37472/214001 [00:34<02:42, 1088.02it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37504/214001 [00:34<02:42, 1088.02it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37536/214001 [00:34<02:42, 1088.02it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37568/214001 [00:34<02:45, 1066.91it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37568/214001 [00:34<02:45, 1066.91it/s, train_loss=0.57]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37600/214001 [00:34<02:45, 1066.91it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37632/214001 [00:34<02:45, 1066.91it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37664/214001 [00:34<02:45, 1066.91it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37696/214001 [00:34<02:43, 1076.28it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37696/214001 [00:34<02:43, 1076.28it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37728/214001 [00:34<02:43, 1076.28it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37760/214001 [00:35<02:43, 1076.28it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37792/214001 [00:35<02:43, 1076.28it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37824/214001 [00:35<02:39, 1103.36it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37824/214001 [00:35<02:39, 1103.36it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37856/214001 [00:35<02:39, 1103.36it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37888/214001 [00:35<02:39, 1103.36it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37920/214001 [00:35<02:39, 1103.36it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37952/214001 [00:35<02:36, 1126.12it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37952/214001 [00:35<02:36, 1126.12it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 37984/214001 [00:35<02:36, 1126.12it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38016/214001 [00:35<02:36, 1126.12it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38048/214001 [00:35<02:36, 1126.12it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38080/214001 [00:35<02:34, 1141.86it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38080/214001 [00:35<02:34, 1141.86it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38112/214001 [00:35<02:34, 1141.86it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38144/214001 [00:35<02:34, 1141.86it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38176/214001 [00:35<02:33, 1141.86it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38208/214001 [00:35<02:31, 1160.83it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38208/214001 [00:35<02:31, 1160.83it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38240/214001 [00:35<02:31, 1160.83it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38272/214001 [00:35<02:31, 1160.83it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38304/214001 [00:35<02:31, 1160.83it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38336/214001 [00:35<02:32, 1151.02it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38336/214001 [00:35<02:32, 1151.02it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38368/214001 [00:35<02:32, 1151.02it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38400/214001 [00:35<02:32, 1151.02it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38432/214001 [00:35<02:32, 1151.02it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38464/214001 [00:35<02:30, 1163.31it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38464/214001 [00:35<02:30, 1163.31it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38496/214001 [00:35<02:30, 1163.31it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38528/214001 [00:35<02:30, 1163.31it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38560/214001 [00:35<02:30, 1163.31it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38592/214001 [00:35<02:28, 1179.25it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38592/214001 [00:35<02:28, 1179.25it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38624/214001 [00:35<02:28, 1179.25it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38656/214001 [00:35<02:28, 1179.25it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38688/214001 [00:35<02:28, 1179.25it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38720/214001 [00:35<02:27, 1191.60it/s, train_loss=0.569]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38720/214001 [00:35<02:27, 1191.60it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38752/214001 [00:35<02:27, 1191.60it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38784/214001 [00:35<02:27, 1191.60it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38816/214001 [00:35<02:27, 1191.60it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38848/214001 [00:35<02:25, 1205.23it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38848/214001 [00:35<02:25, 1205.23it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38880/214001 [00:35<02:25, 1205.23it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38912/214001 [00:35<02:25, 1205.23it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38944/214001 [00:35<02:25, 1205.23it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38976/214001 [00:35<02:23, 1218.18it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 38976/214001 [00:36<02:23, 1218.18it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39008/214001 [00:36<02:23, 1218.18it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39040/214001 [00:36<02:23, 1218.18it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39072/214001 [00:36<02:23, 1218.18it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39104/214001 [00:36<02:21, 1233.60it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39104/214001 [00:36<02:21, 1233.60it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39136/214001 [00:36<02:21, 1233.60it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39168/214001 [00:36<02:21, 1233.60it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39200/214001 [00:36<02:21, 1233.60it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39232/214001 [00:36<02:23, 1221.97it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39232/214001 [00:36<02:23, 1221.97it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39264/214001 [00:36<02:22, 1221.97it/s, train_loss=0.568]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39296/214001 [00:36<02:22, 1221.97it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39328/214001 [00:36<02:22, 1221.97it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39360/214001 [00:36<02:30, 1162.83it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39360/214001 [00:36<02:30, 1162.83it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39392/214001 [00:36<02:30, 1162.83it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39424/214001 [00:36<02:30, 1162.83it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39456/214001 [00:36<02:30, 1162.83it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39488/214001 [00:36<02:38, 1102.95it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39488/214001 [00:36<02:38, 1102.95it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39520/214001 [00:36<02:38, 1102.95it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39552/214001 [00:36<02:38, 1102.95it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 39584/214001 [00:36<02:38, 1102.95it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39616/214001 [00:36<02:38, 1101.52it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39616/214001 [00:36<02:38, 1101.52it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39648/214001 [00:36<02:38, 1101.52it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39680/214001 [00:36<02:38, 1101.52it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39712/214001 [00:36<02:38, 1101.52it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39744/214001 [00:36<02:37, 1106.20it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39744/214001 [00:36<02:37, 1106.20it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39776/214001 [00:36<02:37, 1106.20it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39808/214001 [00:36<02:37, 1106.20it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39840/214001 [00:36<02:37, 1106.20it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39872/214001 [00:36<02:37, 1104.30it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39872/214001 [00:36<02:37, 1104.30it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39904/214001 [00:36<02:37, 1104.30it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39936/214001 [00:36<02:37, 1104.30it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 39968/214001 [00:36<02:37, 1104.30it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 40000/214001 [00:36<02:39, 1088.49it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 40000/214001 [00:36<02:39, 1088.49it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 40032/214001 [00:36<02:39, 1088.49it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 40064/214001 [00:36<02:39, 1088.49it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 40096/214001 [00:37<02:39, 1088.49it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40128/214001 [00:37<02:35, 1115.71it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40128/214001 [00:37<02:35, 1115.71it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40160/214001 [00:37<02:35, 1115.71it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40192/214001 [00:37<02:35, 1115.71it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40224/214001 [00:37<02:35, 1115.71it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40256/214001 [00:37<02:35, 1116.46it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40256/214001 [00:37<02:35, 1116.46it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40288/214001 [00:37<02:35, 1116.46it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40320/214001 [00:37<02:35, 1116.46it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40352/214001 [00:37<02:35, 1116.46it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40384/214001 [00:37<02:37, 1102.27it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40384/214001 [00:37<02:37, 1102.27it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40416/214001 [00:37<02:37, 1102.27it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40448/214001 [00:37<02:37, 1102.27it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40480/214001 [00:37<02:37, 1102.27it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40512/214001 [00:37<02:33, 1130.69it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40512/214001 [00:37<02:33, 1130.69it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40544/214001 [00:37<02:33, 1130.69it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40576/214001 [00:37<02:33, 1130.69it/s, train_loss=0.567]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40608/214001 [00:37<02:33, 1130.69it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40640/214001 [00:37<02:34, 1122.76it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40640/214001 [00:37<02:34, 1122.76it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40672/214001 [00:37<02:34, 1122.76it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40704/214001 [00:37<02:34, 1122.76it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40736/214001 [00:37<02:34, 1122.76it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40768/214001 [00:37<02:32, 1136.78it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40768/214001 [00:37<02:32, 1136.78it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40800/214001 [00:37<02:32, 1136.78it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40832/214001 [00:37<02:32, 1136.78it/s, train_loss=0.566]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40864/214001 [00:37<02:32, 1136.78it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40896/214001 [00:37<02:32, 1132.80it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40896/214001 [00:37<02:32, 1132.80it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40928/214001 [00:37<02:32, 1132.80it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40960/214001 [00:37<02:32, 1132.80it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 40992/214001 [00:37<02:32, 1132.80it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41024/214001 [00:37<02:31, 1143.59it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41024/214001 [00:37<02:31, 1143.59it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41056/214001 [00:37<02:31, 1143.59it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41088/214001 [00:37<02:31, 1143.59it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41120/214001 [00:37<02:31, 1143.59it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41152/214001 [00:37<02:31, 1143.43it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41152/214001 [00:37<02:31, 1143.43it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41184/214001 [00:37<02:31, 1143.43it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41216/214001 [00:38<02:31, 1143.43it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41248/214001 [00:38<02:31, 1143.43it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41280/214001 [00:38<02:29, 1154.90it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41280/214001 [00:38<02:29, 1154.90it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41312/214001 [00:38<02:29, 1154.90it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41344/214001 [00:38<02:29, 1154.90it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41376/214001 [00:38<02:29, 1154.90it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41408/214001 [00:38<02:26, 1176.90it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41408/214001 [00:38<02:26, 1176.90it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41440/214001 [00:38<02:26, 1176.90it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41472/214001 [00:38<02:26, 1176.90it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41504/214001 [00:38<02:26, 1176.90it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41536/214001 [00:38<02:29, 1155.03it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41536/214001 [00:38<02:29, 1155.03it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41568/214001 [00:38<02:29, 1155.03it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41600/214001 [00:38<02:29, 1155.03it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41632/214001 [00:38<02:29, 1155.03it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41664/214001 [00:38<02:26, 1175.87it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41664/214001 [00:38<02:26, 1175.87it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41696/214001 [00:38<02:26, 1175.87it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 41728/214001 [00:38<02:26, 1175.87it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41760/214001 [00:38<02:26, 1175.87it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41792/214001 [00:38<02:25, 1186.67it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41792/214001 [00:38<02:25, 1186.67it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41824/214001 [00:38<02:25, 1186.67it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41856/214001 [00:38<02:25, 1186.67it/s, train_loss=0.565]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41888/214001 [00:38<02:25, 1186.67it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41920/214001 [00:38<02:25, 1185.63it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41920/214001 [00:38<02:25, 1185.63it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41952/214001 [00:38<02:25, 1185.63it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 41984/214001 [00:38<02:25, 1185.63it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42016/214001 [00:38<02:25, 1185.63it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42048/214001 [00:38<02:25, 1179.31it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42048/214001 [00:38<02:25, 1179.31it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42080/214001 [00:38<02:25, 1179.31it/s, train_loss=0.564]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42112/214001 [00:38<02:25, 1179.31it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42144/214001 [00:38<02:25, 1179.31it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42176/214001 [00:38<02:27, 1166.75it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42176/214001 [00:38<02:27, 1166.75it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42208/214001 [00:38<02:27, 1166.75it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42240/214001 [00:38<02:27, 1166.75it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42272/214001 [00:38<02:27, 1166.75it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42304/214001 [00:38<02:25, 1178.40it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42304/214001 [00:38<02:25, 1178.40it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42336/214001 [00:38<02:25, 1178.40it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42368/214001 [00:38<02:25, 1178.40it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42400/214001 [00:39<02:25, 1178.40it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42432/214001 [00:39<02:27, 1167.12it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42432/214001 [00:39<02:27, 1167.12it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42464/214001 [00:39<02:26, 1167.12it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42496/214001 [00:39<02:26, 1167.12it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42528/214001 [00:39<02:26, 1167.12it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42560/214001 [00:39<02:31, 1131.32it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42560/214001 [00:39<02:31, 1131.32it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42592/214001 [00:39<02:31, 1131.32it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42624/214001 [00:39<02:31, 1131.32it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42656/214001 [00:39<02:31, 1131.32it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42688/214001 [00:39<02:28, 1153.47it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42688/214001 [00:39<02:28, 1153.47it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42720/214001 [00:39<02:28, 1153.47it/s, train_loss=0.563]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42752/214001 [00:39<02:28, 1153.47it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 42784/214001 [00:39<02:28, 1153.47it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 42816/214001 [00:39<02:28, 1149.21it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 42816/214001 [00:39<02:28, 1149.21it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 42848/214001 [00:39<02:28, 1149.21it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 42880/214001 [00:39<02:28, 1149.21it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 42912/214001 [00:39<02:28, 1149.21it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 42944/214001 [00:39<02:28, 1150.94it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 42944/214001 [00:39<02:28, 1150.94it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 42976/214001 [00:39<02:28, 1150.94it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43008/214001 [00:39<02:28, 1150.94it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43040/214001 [00:39<02:28, 1150.94it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43072/214001 [00:39<02:27, 1162.28it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43072/214001 [00:39<02:27, 1162.28it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43104/214001 [00:39<02:27, 1162.28it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43136/214001 [00:39<02:27, 1162.28it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43168/214001 [00:39<02:26, 1162.28it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43200/214001 [00:39<02:29, 1139.54it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43200/214001 [00:39<02:29, 1139.54it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43232/214001 [00:39<02:29, 1139.54it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43264/214001 [00:39<02:29, 1139.54it/s, train_loss=0.562]\u001b[A\n",
            "Epoch 1:  20%|██        | 43296/214001 [00:39<02:29, 1139.54it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43328/214001 [00:39<02:28, 1151.62it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43328/214001 [00:39<02:28, 1151.62it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43360/214001 [00:39<02:28, 1151.62it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43392/214001 [00:39<02:28, 1151.62it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43424/214001 [00:39<02:28, 1151.62it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43456/214001 [00:39<02:26, 1166.45it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43456/214001 [00:39<02:26, 1166.45it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43488/214001 [00:39<02:26, 1166.45it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43520/214001 [00:39<02:26, 1166.45it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43552/214001 [00:40<02:26, 1166.45it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43584/214001 [00:40<02:26, 1161.28it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43584/214001 [00:40<02:26, 1161.28it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43616/214001 [00:40<02:26, 1161.28it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  20%|██        | 43648/214001 [00:40<02:26, 1161.28it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43680/214001 [00:40<02:26, 1161.28it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43712/214001 [00:40<02:27, 1156.47it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43712/214001 [00:40<02:27, 1156.47it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43744/214001 [00:40<02:27, 1156.47it/s, train_loss=0.561]\u001b[A\n",
            "Epoch 1:  20%|██        | 43776/214001 [00:40<02:27, 1156.47it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  20%|██        | 43808/214001 [00:40<02:27, 1156.47it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  20%|██        | 43840/214001 [00:40<02:25, 1168.36it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  20%|██        | 43840/214001 [00:40<02:25, 1168.36it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 43872/214001 [00:40<02:25, 1168.36it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 43904/214001 [00:40<02:25, 1168.36it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 43936/214001 [00:40<02:25, 1168.36it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  21%|██        | 43968/214001 [00:40<02:23, 1187.63it/s, train_loss=0.56]\u001b[A\n",
            "Epoch 1:  21%|██        | 43968/214001 [00:40<02:23, 1187.63it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44000/214001 [00:40<02:23, 1187.63it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44032/214001 [00:40<02:23, 1187.63it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44064/214001 [00:40<02:23, 1187.63it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44096/214001 [00:40<02:21, 1202.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44096/214001 [00:40<02:21, 1202.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44128/214001 [00:40<02:21, 1202.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44160/214001 [00:40<02:21, 1202.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44192/214001 [00:40<02:21, 1202.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44224/214001 [00:40<02:20, 1206.92it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44224/214001 [00:40<02:20, 1206.92it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44256/214001 [00:40<02:20, 1206.92it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44288/214001 [00:40<02:20, 1206.92it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  21%|██        | 44320/214001 [00:40<02:20, 1206.92it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44352/214001 [00:40<02:22, 1191.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44352/214001 [00:40<02:22, 1191.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44384/214001 [00:40<02:22, 1191.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44416/214001 [00:40<02:22, 1191.65it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  21%|██        | 44448/214001 [00:40<02:22, 1191.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44480/214001 [00:40<02:22, 1189.34it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44480/214001 [00:40<02:22, 1189.34it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44512/214001 [00:40<02:22, 1189.34it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44544/214001 [00:40<02:22, 1189.34it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44576/214001 [00:40<02:22, 1189.34it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44608/214001 [00:40<02:22, 1190.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44608/214001 [00:40<02:22, 1190.36it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44640/214001 [00:40<02:22, 1190.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44672/214001 [00:40<02:22, 1190.36it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44704/214001 [00:40<02:22, 1190.36it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44736/214001 [00:40<02:21, 1194.14it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44736/214001 [00:41<02:21, 1194.14it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44768/214001 [00:41<02:21, 1194.14it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44800/214001 [00:41<02:21, 1194.14it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44832/214001 [00:41<02:21, 1194.14it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44864/214001 [00:41<02:23, 1181.53it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44864/214001 [00:41<02:23, 1181.53it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44896/214001 [00:41<02:23, 1181.53it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 44928/214001 [00:41<02:23, 1181.53it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44960/214001 [00:41<02:23, 1181.53it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44992/214001 [00:41<02:25, 1160.89it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 44992/214001 [00:41<02:25, 1160.89it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  21%|██        | 45024/214001 [00:41<02:25, 1160.89it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45056/214001 [00:41<02:25, 1160.89it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45088/214001 [00:41<02:25, 1160.89it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45120/214001 [00:41<02:23, 1175.21it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45120/214001 [00:41<02:23, 1175.21it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45152/214001 [00:41<02:23, 1175.21it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45184/214001 [00:41<02:23, 1175.21it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45216/214001 [00:41<02:23, 1175.21it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45248/214001 [00:41<02:22, 1180.13it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45248/214001 [00:41<02:22, 1180.13it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 45280/214001 [00:41<02:22, 1180.13it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45312/214001 [00:41<02:22, 1180.13it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  21%|██        | 45344/214001 [00:41<02:22, 1180.13it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 45376/214001 [00:41<02:21, 1190.93it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 45376/214001 [00:41<02:21, 1190.93it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 45408/214001 [00:41<02:21, 1190.93it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██        | 45440/214001 [00:41<02:21, 1190.93it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  21%|██        | 45472/214001 [00:41<02:21, 1190.93it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45504/214001 [00:41<02:19, 1205.29it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45504/214001 [00:41<02:19, 1205.29it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45536/214001 [00:41<02:19, 1205.29it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45568/214001 [00:41<02:19, 1205.29it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45600/214001 [00:41<02:19, 1205.29it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45632/214001 [00:41<02:21, 1188.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45632/214001 [00:41<02:21, 1188.65it/s, train_loss=0.56] \u001b[A\n",
            "Epoch 1:  21%|██▏       | 45664/214001 [00:41<02:21, 1188.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45696/214001 [00:41<02:21, 1188.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45728/214001 [00:41<02:21, 1188.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45760/214001 [00:41<02:25, 1159.11it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45760/214001 [00:41<02:25, 1159.11it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45792/214001 [00:41<02:25, 1159.11it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45824/214001 [00:41<02:25, 1159.11it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45856/214001 [00:41<02:25, 1159.11it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45888/214001 [00:41<02:24, 1161.59it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45888/214001 [00:41<02:24, 1161.59it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45920/214001 [00:42<02:24, 1161.59it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45952/214001 [00:42<02:24, 1161.59it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 45984/214001 [00:42<02:24, 1161.59it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46016/214001 [00:42<02:28, 1131.81it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46016/214001 [00:42<02:28, 1131.81it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46048/214001 [00:42<02:28, 1131.81it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46080/214001 [00:42<02:28, 1131.81it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46112/214001 [00:42<02:28, 1131.81it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46144/214001 [00:42<02:27, 1138.82it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46144/214001 [00:42<02:27, 1138.82it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46176/214001 [00:42<02:27, 1138.82it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46208/214001 [00:42<02:27, 1138.82it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46240/214001 [00:42<02:27, 1138.82it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46272/214001 [00:42<02:25, 1154.64it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46272/214001 [00:42<02:25, 1154.64it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46304/214001 [00:42<02:25, 1154.64it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46336/214001 [00:42<02:25, 1154.64it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46368/214001 [00:42<02:25, 1154.64it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46400/214001 [00:42<02:25, 1150.16it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46400/214001 [00:42<02:25, 1150.16it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46432/214001 [00:42<02:25, 1150.16it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46464/214001 [00:42<02:25, 1150.16it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46496/214001 [00:42<02:25, 1150.16it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46528/214001 [00:42<02:22, 1175.78it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46528/214001 [00:42<02:22, 1175.78it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46560/214001 [00:42<02:22, 1175.78it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46592/214001 [00:42<02:22, 1175.78it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46624/214001 [00:42<02:22, 1175.78it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46656/214001 [00:42<02:22, 1174.75it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46656/214001 [00:42<02:22, 1174.75it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46688/214001 [00:42<02:22, 1174.75it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46720/214001 [00:42<02:22, 1174.75it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46752/214001 [00:42<02:22, 1174.75it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46784/214001 [00:42<02:25, 1148.82it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46784/214001 [00:42<02:25, 1148.82it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46816/214001 [00:42<02:25, 1148.82it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46848/214001 [00:42<02:25, 1148.82it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46880/214001 [00:42<02:25, 1148.82it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46912/214001 [00:42<02:27, 1134.56it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46912/214001 [00:42<02:27, 1134.56it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46944/214001 [00:42<02:27, 1134.56it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 46976/214001 [00:42<02:27, 1134.56it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47008/214001 [00:42<02:27, 1134.56it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47040/214001 [00:42<02:35, 1074.57it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47040/214001 [00:43<02:35, 1074.57it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47072/214001 [00:43<02:35, 1074.57it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47104/214001 [00:43<02:35, 1074.57it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47136/214001 [00:43<02:35, 1074.57it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47168/214001 [00:43<02:39, 1048.63it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47168/214001 [00:43<02:39, 1048.63it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47200/214001 [00:43<02:39, 1048.63it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47232/214001 [00:43<02:39, 1048.63it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47264/214001 [00:43<02:39, 1048.63it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47296/214001 [00:43<02:38, 1049.88it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47296/214001 [00:43<02:38, 1049.88it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47328/214001 [00:43<02:38, 1049.88it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47360/214001 [00:43<02:38, 1049.88it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47392/214001 [00:43<02:38, 1049.88it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47424/214001 [00:43<02:33, 1085.89it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47424/214001 [00:43<02:33, 1085.89it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47456/214001 [00:43<02:33, 1085.89it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47488/214001 [00:43<02:33, 1085.89it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47520/214001 [00:43<02:33, 1085.89it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47552/214001 [00:43<02:27, 1125.58it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47552/214001 [00:43<02:27, 1125.58it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47584/214001 [00:43<02:27, 1125.58it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47616/214001 [00:43<02:27, 1125.58it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47648/214001 [00:43<02:27, 1125.58it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47680/214001 [00:43<02:28, 1116.79it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47680/214001 [00:43<02:28, 1116.79it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47712/214001 [00:43<02:28, 1116.79it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47744/214001 [00:43<02:28, 1116.79it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47776/214001 [00:43<02:28, 1116.79it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47808/214001 [00:43<02:27, 1129.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47808/214001 [00:43<02:27, 1129.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47840/214001 [00:43<02:27, 1129.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47872/214001 [00:43<02:27, 1129.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47904/214001 [00:43<02:27, 1129.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47936/214001 [00:43<02:27, 1123.31it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47936/214001 [00:43<02:27, 1123.31it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 47968/214001 [00:43<02:27, 1123.31it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 48000/214001 [00:43<02:27, 1123.31it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 48032/214001 [00:43<02:27, 1123.31it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 48064/214001 [00:43<02:39, 1042.06it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 48064/214001 [00:43<02:39, 1042.06it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 48096/214001 [00:44<02:39, 1042.06it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 48128/214001 [00:44<02:39, 1042.06it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48160/214001 [00:44<02:39, 1042.06it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48192/214001 [00:44<02:34, 1070.13it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48192/214001 [00:44<02:34, 1070.13it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48224/214001 [00:44<02:34, 1070.13it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48256/214001 [00:44<02:34, 1070.13it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48288/214001 [00:44<02:34, 1070.13it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48320/214001 [00:44<02:31, 1096.64it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48320/214001 [00:44<02:31, 1096.64it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48352/214001 [00:44<02:31, 1096.64it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48384/214001 [00:44<02:31, 1096.64it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48416/214001 [00:44<02:30, 1096.64it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48448/214001 [00:44<02:29, 1104.49it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48448/214001 [00:44<02:29, 1104.49it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48480/214001 [00:44<02:29, 1104.49it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48512/214001 [00:44<02:29, 1104.49it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48544/214001 [00:44<02:29, 1104.49it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48576/214001 [00:44<02:24, 1144.63it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48576/214001 [00:44<02:24, 1144.63it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48608/214001 [00:44<02:24, 1144.63it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48640/214001 [00:44<02:24, 1144.63it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48672/214001 [00:44<02:24, 1144.63it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48704/214001 [00:44<02:32, 1083.43it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48704/214001 [00:44<02:32, 1083.43it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48736/214001 [00:44<02:32, 1083.43it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48768/214001 [00:44<02:32, 1083.43it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48800/214001 [00:44<02:32, 1083.43it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48832/214001 [00:44<02:41, 1025.33it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48832/214001 [00:44<02:41, 1025.33it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48864/214001 [00:44<02:41, 1025.33it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48896/214001 [00:44<02:41, 1025.33it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48928/214001 [00:44<02:40, 1025.33it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48960/214001 [00:44<02:49, 973.92it/s, train_loss=0.559] \u001b[A\n",
            "Epoch 1:  23%|██▎       | 48960/214001 [00:44<02:49, 973.92it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 48992/214001 [00:44<02:49, 973.92it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49024/214001 [00:44<02:49, 973.92it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49056/214001 [00:44<02:49, 973.92it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49088/214001 [00:44<02:45, 995.28it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49088/214001 [00:44<02:45, 995.28it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49120/214001 [00:44<02:45, 995.28it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49152/214001 [00:45<02:45, 995.28it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49184/214001 [00:45<02:45, 995.28it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49216/214001 [00:45<02:43, 1005.48it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49216/214001 [00:45<02:43, 1005.48it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49248/214001 [00:45<02:43, 1005.48it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49280/214001 [00:45<02:43, 1005.48it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49312/214001 [00:45<02:43, 1005.48it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49344/214001 [00:45<02:38, 1037.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49344/214001 [00:45<02:38, 1037.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49376/214001 [00:45<02:38, 1037.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49408/214001 [00:45<02:38, 1037.65it/s, train_loss=0.559]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49440/214001 [00:45<02:38, 1037.65it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49472/214001 [00:45<02:33, 1071.30it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49472/214001 [00:45<02:33, 1071.30it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49504/214001 [00:45<02:33, 1071.30it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49536/214001 [00:45<02:33, 1071.30it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49568/214001 [00:45<02:33, 1071.30it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49600/214001 [00:45<02:34, 1065.78it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49600/214001 [00:45<02:34, 1065.78it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49632/214001 [00:45<02:34, 1065.78it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49664/214001 [00:45<02:34, 1065.78it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49696/214001 [00:45<02:34, 1065.78it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49728/214001 [00:45<02:27, 1113.55it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49728/214001 [00:45<02:27, 1113.55it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49760/214001 [00:45<02:27, 1113.55it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49792/214001 [00:45<02:27, 1113.55it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49824/214001 [00:45<02:27, 1113.55it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49856/214001 [00:45<02:23, 1147.34it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49856/214001 [00:45<02:23, 1147.34it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49888/214001 [00:45<02:23, 1147.34it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49920/214001 [00:45<02:23, 1147.34it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49952/214001 [00:45<02:22, 1147.34it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49984/214001 [00:45<02:19, 1171.73it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 49984/214001 [00:45<02:19, 1171.73it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50016/214001 [00:45<02:19, 1171.73it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50048/214001 [00:45<02:19, 1171.73it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50080/214001 [00:45<02:19, 1171.73it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50112/214001 [00:45<02:25, 1125.02it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50112/214001 [00:45<02:25, 1125.02it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50144/214001 [00:45<02:25, 1125.02it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50176/214001 [00:45<02:25, 1125.02it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50208/214001 [00:45<02:25, 1125.02it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50240/214001 [00:45<02:30, 1091.39it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50240/214001 [00:45<02:30, 1091.39it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 50272/214001 [00:46<02:30, 1091.39it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50304/214001 [00:46<02:29, 1091.39it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50336/214001 [00:46<02:29, 1091.39it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50368/214001 [00:46<02:31, 1078.01it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50368/214001 [00:46<02:31, 1078.01it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50400/214001 [00:46<02:31, 1078.01it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50432/214001 [00:46<02:31, 1078.01it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50464/214001 [00:46<02:31, 1078.01it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50496/214001 [00:46<02:27, 1111.74it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50496/214001 [00:46<02:27, 1111.74it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50528/214001 [00:46<02:27, 1111.74it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50560/214001 [00:46<02:27, 1111.74it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50592/214001 [00:46<02:26, 1111.74it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50624/214001 [00:46<02:22, 1150.16it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50624/214001 [00:46<02:22, 1150.16it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50656/214001 [00:46<02:22, 1150.16it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50688/214001 [00:46<02:21, 1150.16it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50720/214001 [00:46<02:21, 1150.16it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50752/214001 [00:46<02:20, 1159.66it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50752/214001 [00:46<02:20, 1159.66it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50784/214001 [00:46<02:20, 1159.66it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 50816/214001 [00:46<02:20, 1159.66it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 50848/214001 [00:46<02:20, 1159.66it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 50880/214001 [00:46<02:18, 1173.84it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 50880/214001 [00:46<02:18, 1173.84it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 50912/214001 [00:46<02:18, 1173.84it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 50944/214001 [00:46<02:18, 1173.84it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 50976/214001 [00:46<02:18, 1173.84it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51008/214001 [00:46<02:16, 1190.77it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51008/214001 [00:46<02:16, 1190.77it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51040/214001 [00:46<02:16, 1190.77it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51072/214001 [00:46<02:16, 1190.77it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51104/214001 [00:46<02:16, 1190.77it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51136/214001 [00:46<02:14, 1211.21it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51136/214001 [00:46<02:14, 1211.21it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51168/214001 [00:46<02:14, 1211.21it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51200/214001 [00:46<02:14, 1211.21it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51232/214001 [00:46<02:14, 1211.21it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51264/214001 [00:46<02:18, 1175.60it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51264/214001 [00:46<02:18, 1175.60it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51296/214001 [00:46<02:18, 1175.60it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51328/214001 [00:46<02:18, 1175.60it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51360/214001 [00:46<02:18, 1175.60it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51392/214001 [00:46<02:15, 1200.03it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51392/214001 [00:46<02:15, 1200.03it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51424/214001 [00:46<02:15, 1200.03it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51456/214001 [00:46<02:15, 1200.03it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51488/214001 [00:47<02:15, 1200.03it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51520/214001 [00:47<02:15, 1203.20it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51520/214001 [00:47<02:15, 1203.20it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51552/214001 [00:47<02:15, 1203.20it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51584/214001 [00:47<02:14, 1203.20it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51616/214001 [00:47<02:14, 1203.20it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51648/214001 [00:47<02:17, 1182.64it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51648/214001 [00:47<02:17, 1182.64it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51680/214001 [00:47<02:17, 1182.64it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51712/214001 [00:47<02:17, 1182.64it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51744/214001 [00:47<02:17, 1182.64it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51776/214001 [00:47<02:16, 1189.73it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51776/214001 [00:47<02:16, 1189.73it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51808/214001 [00:47<02:16, 1189.73it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51840/214001 [00:47<02:16, 1189.73it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51872/214001 [00:47<02:16, 1189.73it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51904/214001 [00:47<02:16, 1189.73it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51936/214001 [00:47<02:12, 1226.43it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51936/214001 [00:47<02:12, 1226.43it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 51968/214001 [00:47<02:12, 1226.43it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52000/214001 [00:47<02:12, 1226.43it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52032/214001 [00:47<02:12, 1226.43it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52064/214001 [00:47<02:16, 1182.33it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52064/214001 [00:47<02:16, 1182.33it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52096/214001 [00:47<02:16, 1182.33it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52128/214001 [00:47<02:16, 1182.33it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52160/214001 [00:47<02:16, 1182.33it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52192/214001 [00:47<02:16, 1186.11it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52192/214001 [00:47<02:16, 1186.11it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52224/214001 [00:47<02:16, 1186.11it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52256/214001 [00:47<02:16, 1186.11it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52288/214001 [00:47<02:16, 1186.11it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52320/214001 [00:47<02:14, 1199.14it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52320/214001 [00:47<02:14, 1199.14it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52352/214001 [00:47<02:14, 1199.14it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52384/214001 [00:47<02:14, 1199.14it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 52416/214001 [00:47<02:14, 1199.14it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52448/214001 [00:47<02:19, 1160.67it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52448/214001 [00:47<02:19, 1160.67it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52480/214001 [00:47<02:19, 1160.67it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52512/214001 [00:47<02:19, 1160.67it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52544/214001 [00:47<02:19, 1160.67it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52576/214001 [00:47<02:26, 1100.01it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52576/214001 [00:47<02:26, 1100.01it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52608/214001 [00:48<02:26, 1100.01it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52640/214001 [00:48<02:26, 1100.01it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52672/214001 [00:48<02:26, 1100.01it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52704/214001 [00:48<02:31, 1065.93it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52704/214001 [00:48<02:31, 1065.93it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52736/214001 [00:48<02:31, 1065.93it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52768/214001 [00:48<02:31, 1065.93it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52800/214001 [00:48<02:31, 1065.93it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52832/214001 [00:48<02:30, 1069.98it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52832/214001 [00:48<02:30, 1069.98it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52864/214001 [00:48<02:30, 1069.98it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52896/214001 [00:48<02:30, 1069.98it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52928/214001 [00:48<02:30, 1069.98it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52960/214001 [00:48<02:31, 1059.90it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52960/214001 [00:48<02:31, 1059.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 52992/214001 [00:48<02:31, 1059.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53024/214001 [00:48<02:31, 1059.90it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53056/214001 [00:48<02:31, 1059.90it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53088/214001 [00:48<02:35, 1031.95it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53088/214001 [00:48<02:35, 1031.95it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53120/214001 [00:48<02:35, 1031.95it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53152/214001 [00:48<02:35, 1031.95it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53184/214001 [00:48<02:35, 1031.95it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53216/214001 [00:48<02:42, 991.36it/s, train_loss=0.558] \u001b[A\n",
            "Epoch 1:  25%|██▍       | 53216/214001 [00:48<02:42, 991.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53248/214001 [00:48<02:42, 991.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53280/214001 [00:48<02:42, 991.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53312/214001 [00:48<02:42, 991.36it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53344/214001 [00:48<02:47, 956.88it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53344/214001 [00:48<02:47, 956.88it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53376/214001 [00:48<02:47, 956.88it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53408/214001 [00:48<02:47, 956.88it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53440/214001 [00:48<02:47, 956.88it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53472/214001 [00:48<02:49, 947.08it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 53472/214001 [00:48<02:49, 947.08it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53504/214001 [00:48<02:49, 947.08it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53536/214001 [00:48<02:49, 947.08it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53568/214001 [00:48<02:49, 947.08it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53600/214001 [00:48<02:41, 994.32it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53600/214001 [00:49<02:41, 994.32it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53632/214001 [00:49<02:41, 994.32it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53664/214001 [00:49<02:41, 994.32it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53696/214001 [00:49<02:41, 994.32it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53728/214001 [00:49<02:35, 1029.67it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53728/214001 [00:49<02:35, 1029.67it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53760/214001 [00:49<02:35, 1029.67it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53792/214001 [00:49<02:35, 1029.67it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53824/214001 [00:49<02:35, 1029.67it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53856/214001 [00:49<02:36, 1024.68it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53856/214001 [00:49<02:36, 1024.68it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53888/214001 [00:49<02:36, 1024.68it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53920/214001 [00:49<02:36, 1024.68it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53952/214001 [00:49<02:36, 1024.68it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53984/214001 [00:49<02:29, 1070.41it/s, train_loss=0.558]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 53984/214001 [00:49<02:29, 1070.41it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54016/214001 [00:49<02:29, 1070.41it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54048/214001 [00:49<02:29, 1070.41it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54080/214001 [00:49<02:29, 1070.41it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54112/214001 [00:49<02:24, 1107.20it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54112/214001 [00:49<02:24, 1107.20it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54144/214001 [00:49<02:24, 1107.20it/s, train_loss=0.557]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54176/214001 [00:49<02:24, 1107.20it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54208/214001 [00:49<02:24, 1107.20it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54240/214001 [00:49<02:27, 1085.92it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54240/214001 [00:49<02:27, 1085.92it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54272/214001 [00:49<02:27, 1085.92it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54304/214001 [00:49<02:27, 1085.92it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54336/214001 [00:49<02:27, 1085.92it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54368/214001 [00:49<02:32, 1049.36it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54368/214001 [00:49<02:32, 1049.36it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54400/214001 [00:49<02:32, 1049.36it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54432/214001 [00:49<02:32, 1049.36it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54464/214001 [00:49<02:32, 1049.36it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54496/214001 [00:49<02:25, 1095.02it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54496/214001 [00:49<02:25, 1095.02it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54528/214001 [00:49<02:25, 1095.02it/s, train_loss=0.556]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 54560/214001 [00:49<02:25, 1095.02it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54592/214001 [00:49<02:25, 1095.02it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54624/214001 [00:49<02:20, 1130.43it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54624/214001 [00:49<02:20, 1130.43it/s, train_loss=0.555]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54656/214001 [00:49<02:20, 1130.43it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54688/214001 [00:49<02:20, 1130.43it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54720/214001 [00:50<02:20, 1130.43it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54752/214001 [00:50<02:17, 1157.26it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54752/214001 [00:50<02:17, 1157.26it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54784/214001 [00:50<02:17, 1157.26it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54816/214001 [00:50<02:17, 1157.26it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54848/214001 [00:50<02:17, 1157.26it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54880/214001 [00:50<02:16, 1168.08it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54880/214001 [00:50<02:16, 1168.08it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54912/214001 [00:50<02:16, 1168.08it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54944/214001 [00:50<02:16, 1168.08it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 54976/214001 [00:50<02:16, 1168.08it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55008/214001 [00:50<02:16, 1167.08it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55008/214001 [00:50<02:16, 1167.08it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55040/214001 [00:50<02:16, 1167.08it/s, train_loss=0.554]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55072/214001 [00:50<02:16, 1167.08it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55104/214001 [00:50<02:16, 1167.08it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55136/214001 [00:50<02:15, 1169.95it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55136/214001 [00:50<02:15, 1169.95it/s, train_loss=0.553]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55168/214001 [00:50<02:15, 1169.95it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55200/214001 [00:50<02:15, 1169.95it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55232/214001 [00:50<02:15, 1169.95it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55264/214001 [00:50<02:15, 1174.29it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55264/214001 [00:50<02:15, 1174.29it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55296/214001 [00:50<02:15, 1174.29it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55328/214001 [00:50<02:15, 1174.29it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55360/214001 [00:50<02:15, 1174.29it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55392/214001 [00:50<02:17, 1155.52it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55392/214001 [00:50<02:17, 1155.52it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55424/214001 [00:50<02:17, 1155.52it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  26%|██▌       | 55456/214001 [00:50<02:17, 1155.52it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55488/214001 [00:50<02:17, 1155.52it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  26%|██▌       | 55520/214001 [00:50<02:17, 1149.32it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55520/214001 [00:50<02:17, 1149.32it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55552/214001 [00:50<02:17, 1149.32it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55584/214001 [00:50<02:17, 1149.32it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55616/214001 [00:50<02:17, 1149.32it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55648/214001 [00:50<02:19, 1135.50it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55648/214001 [00:50<02:19, 1135.50it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55680/214001 [00:50<02:19, 1135.50it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55712/214001 [00:50<02:19, 1135.50it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55744/214001 [00:50<02:19, 1135.50it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55776/214001 [00:50<02:26, 1078.58it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55776/214001 [00:50<02:26, 1078.58it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55808/214001 [00:50<02:26, 1078.58it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  26%|██▌       | 55840/214001 [00:51<02:26, 1078.58it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55872/214001 [00:51<02:26, 1078.58it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55904/214001 [00:51<02:27, 1073.84it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55904/214001 [00:51<02:27, 1073.84it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55936/214001 [00:51<02:27, 1073.84it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 55968/214001 [00:51<02:27, 1073.84it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56000/214001 [00:51<02:27, 1073.84it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56032/214001 [00:51<02:23, 1102.77it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56032/214001 [00:51<02:23, 1102.77it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56064/214001 [00:51<02:23, 1102.77it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56096/214001 [00:51<02:23, 1102.77it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56128/214001 [00:51<02:23, 1102.77it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  26%|██▌       | 56160/214001 [00:51<02:23, 1103.56it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 56160/214001 [00:51<02:23, 1103.56it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56192/214001 [00:51<02:23, 1103.56it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56224/214001 [00:51<02:22, 1103.56it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56256/214001 [00:51<02:22, 1103.56it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56288/214001 [00:51<02:22, 1103.95it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56288/214001 [00:51<02:22, 1103.95it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56320/214001 [00:51<02:22, 1103.95it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56352/214001 [00:51<02:22, 1103.95it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56384/214001 [00:51<02:22, 1103.95it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  26%|██▋       | 56416/214001 [00:51<02:25, 1082.50it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56416/214001 [00:51<02:25, 1082.50it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56448/214001 [00:51<02:25, 1082.50it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56480/214001 [00:51<02:25, 1082.50it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56512/214001 [00:51<02:25, 1082.50it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56544/214001 [00:51<02:28, 1058.89it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56544/214001 [00:51<02:28, 1058.89it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56576/214001 [00:51<02:28, 1058.89it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56608/214001 [00:51<02:28, 1058.89it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56640/214001 [00:51<02:28, 1058.89it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56672/214001 [00:51<02:33, 1027.03it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56672/214001 [00:51<02:33, 1027.03it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 56704/214001 [00:51<02:33, 1027.03it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56736/214001 [00:51<02:33, 1027.03it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56768/214001 [00:51<02:33, 1027.03it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56800/214001 [00:51<02:34, 1017.91it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56800/214001 [00:51<02:34, 1017.91it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56832/214001 [00:51<02:34, 1017.91it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56864/214001 [00:51<02:34, 1017.91it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56896/214001 [00:52<02:34, 1017.91it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56928/214001 [00:52<02:37, 996.62it/s, train_loss=0.551] \u001b[A\n",
            "Epoch 1:  27%|██▋       | 56928/214001 [00:52<02:37, 996.62it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56960/214001 [00:52<02:37, 996.62it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 56992/214001 [00:52<02:37, 996.62it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57024/214001 [00:52<02:37, 996.62it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57056/214001 [00:52<02:34, 1017.21it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57056/214001 [00:52<02:34, 1017.21it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57088/214001 [00:52<02:34, 1017.21it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57120/214001 [00:52<02:34, 1017.21it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57152/214001 [00:52<02:34, 1017.21it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57184/214001 [00:52<02:29, 1048.47it/s, train_loss=0.552]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57184/214001 [00:52<02:29, 1048.47it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57216/214001 [00:52<02:29, 1048.47it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57248/214001 [00:52<02:29, 1048.47it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57280/214001 [00:52<02:29, 1048.47it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57312/214001 [00:52<02:24, 1081.24it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57312/214001 [00:52<02:24, 1081.24it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57344/214001 [00:52<02:24, 1081.24it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57376/214001 [00:52<02:24, 1081.24it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57408/214001 [00:52<02:24, 1081.24it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57440/214001 [00:52<02:22, 1100.92it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57440/214001 [00:52<02:22, 1100.92it/s, train_loss=0.551]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57472/214001 [00:52<02:22, 1100.92it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  27%|██▋       | 57504/214001 [00:52<02:22, 1100.92it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57536/214001 [00:52<02:22, 1100.92it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  27%|██▋       | 57568/214001 [00:52<02:22, 1095.86it/s, train_loss=0.55]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57568/214001 [00:52<02:22, 1095.86it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57600/214001 [00:52<02:22, 1095.86it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57632/214001 [00:52<02:22, 1095.86it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57664/214001 [00:52<02:22, 1095.86it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57696/214001 [00:52<02:25, 1076.25it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57696/214001 [00:52<02:25, 1076.25it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57728/214001 [00:52<02:25, 1076.25it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57760/214001 [00:52<02:25, 1076.25it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57792/214001 [00:52<02:25, 1076.25it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57824/214001 [00:52<02:21, 1101.27it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57824/214001 [00:52<02:21, 1101.27it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57856/214001 [00:52<02:21, 1101.27it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57888/214001 [00:52<02:21, 1101.27it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57920/214001 [00:52<02:21, 1101.27it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57952/214001 [00:52<02:20, 1111.95it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57952/214001 [00:52<02:20, 1111.95it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 57984/214001 [00:53<02:20, 1111.95it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58016/214001 [00:53<02:20, 1111.95it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58048/214001 [00:53<02:20, 1111.95it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58080/214001 [00:53<02:18, 1123.40it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58080/214001 [00:53<02:18, 1123.40it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58112/214001 [00:53<02:18, 1123.40it/s, train_loss=0.55] \u001b[A\n",
            "Epoch 1:  27%|██▋       | 58144/214001 [00:53<02:18, 1123.40it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58176/214001 [00:53<02:18, 1123.40it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58208/214001 [00:53<02:14, 1157.14it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58208/214001 [00:53<02:14, 1157.14it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58240/214001 [00:53<02:14, 1157.14it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58272/214001 [00:53<02:14, 1157.14it/s, train_loss=0.549]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58304/214001 [00:53<02:14, 1157.14it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58336/214001 [00:53<02:16, 1139.15it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58336/214001 [00:53<02:16, 1139.15it/s, train_loss=0.548]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58368/214001 [00:53<02:16, 1139.15it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58400/214001 [00:53<02:16, 1139.15it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58432/214001 [00:53<02:16, 1139.15it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58464/214001 [00:53<02:20, 1106.84it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58464/214001 [00:53<02:20, 1106.84it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58496/214001 [00:53<02:20, 1106.84it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58528/214001 [00:53<02:20, 1106.84it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58560/214001 [00:53<02:20, 1106.84it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58592/214001 [00:53<02:21, 1097.83it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58592/214001 [00:53<02:21, 1097.83it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58624/214001 [00:53<02:21, 1097.83it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58656/214001 [00:53<02:21, 1097.83it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58688/214001 [00:53<02:21, 1097.83it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58720/214001 [00:53<02:22, 1086.98it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58720/214001 [00:53<02:22, 1086.98it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58752/214001 [00:53<02:22, 1086.98it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58784/214001 [00:53<02:22, 1086.98it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58816/214001 [00:53<02:22, 1086.98it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58848/214001 [00:53<02:30, 1029.77it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 58848/214001 [00:53<02:30, 1029.77it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 58880/214001 [00:53<02:30, 1029.77it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 58912/214001 [00:53<02:30, 1029.77it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 58944/214001 [00:53<02:30, 1029.77it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 58976/214001 [00:53<02:33, 1007.73it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 58976/214001 [00:53<02:33, 1007.73it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59008/214001 [00:53<02:33, 1007.73it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59040/214001 [00:54<02:33, 1007.73it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59072/214001 [00:54<02:33, 1007.73it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59104/214001 [00:54<02:34, 1002.34it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59104/214001 [00:54<02:34, 1002.34it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59136/214001 [00:54<02:34, 1002.34it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59168/214001 [00:54<02:34, 1002.34it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59200/214001 [00:54<02:34, 1002.34it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59232/214001 [00:54<02:34, 1001.93it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59232/214001 [00:54<02:34, 1001.93it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59264/214001 [00:54<02:34, 1001.93it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59296/214001 [00:54<02:34, 1001.93it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59328/214001 [00:54<02:34, 1001.93it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59360/214001 [00:54<02:33, 1006.02it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59360/214001 [00:54<02:33, 1006.02it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59392/214001 [00:54<02:33, 1006.02it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59424/214001 [00:54<02:33, 1006.02it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59456/214001 [00:54<02:33, 1006.02it/s, train_loss=0.547]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59488/214001 [00:54<02:34, 999.51it/s, train_loss=0.547] \u001b[A\n",
            "Epoch 1:  28%|██▊       | 59488/214001 [00:54<02:34, 999.51it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59520/214001 [00:54<02:34, 999.51it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59552/214001 [00:54<02:34, 999.51it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59584/214001 [00:54<02:34, 999.51it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59616/214001 [00:54<02:28, 1037.65it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59616/214001 [00:54<02:28, 1037.65it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59648/214001 [00:54<02:28, 1037.65it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59680/214001 [00:54<02:28, 1037.65it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59712/214001 [00:54<02:28, 1037.65it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59744/214001 [00:54<02:30, 1025.00it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59744/214001 [00:54<02:30, 1025.00it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59776/214001 [00:54<02:30, 1025.00it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59808/214001 [00:54<02:30, 1025.00it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59840/214001 [00:54<02:30, 1025.00it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59872/214001 [00:54<02:27, 1045.40it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59872/214001 [00:54<02:27, 1045.40it/s, train_loss=0.546]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59904/214001 [00:54<02:27, 1045.40it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59936/214001 [00:54<02:27, 1045.40it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 59968/214001 [00:54<02:27, 1045.40it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60000/214001 [00:54<02:28, 1038.00it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60000/214001 [00:54<02:28, 1038.00it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60032/214001 [00:54<02:28, 1038.00it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60064/214001 [00:55<02:28, 1038.00it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60096/214001 [00:55<02:28, 1038.00it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60128/214001 [00:55<02:29, 1027.06it/s, train_loss=0.545]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60128/214001 [00:55<02:29, 1027.06it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60160/214001 [00:55<02:29, 1027.06it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60192/214001 [00:55<02:29, 1027.06it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60224/214001 [00:55<02:29, 1027.06it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60256/214001 [00:55<02:25, 1053.25it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60256/214001 [00:55<02:25, 1053.25it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60288/214001 [00:55<02:25, 1053.25it/s, train_loss=0.544]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60320/214001 [00:55<02:25, 1053.25it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60352/214001 [00:55<02:25, 1053.25it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60384/214001 [00:55<02:30, 1018.36it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60384/214001 [00:55<02:30, 1018.36it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60416/214001 [00:55<02:30, 1018.36it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60448/214001 [00:55<02:30, 1018.36it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60480/214001 [00:55<02:30, 1018.36it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60512/214001 [00:55<02:30, 1020.76it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60512/214001 [00:55<02:30, 1020.76it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60544/214001 [00:55<02:30, 1020.76it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60576/214001 [00:55<02:30, 1020.76it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60608/214001 [00:55<02:30, 1020.76it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60640/214001 [00:55<02:28, 1030.02it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60640/214001 [00:55<02:28, 1030.02it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60672/214001 [00:55<02:28, 1030.02it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60704/214001 [00:55<02:28, 1030.02it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60736/214001 [00:55<02:28, 1030.02it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60768/214001 [00:55<02:24, 1063.02it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60768/214001 [00:55<02:24, 1063.02it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60800/214001 [00:55<02:24, 1063.02it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60832/214001 [00:55<02:24, 1063.02it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60864/214001 [00:55<02:24, 1063.02it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60896/214001 [00:55<02:23, 1068.81it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60896/214001 [00:55<02:23, 1068.81it/s, train_loss=0.543]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60928/214001 [00:55<02:23, 1068.81it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 60960/214001 [00:55<02:23, 1068.81it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 60992/214001 [00:55<02:23, 1068.81it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61024/214001 [00:55<02:22, 1076.82it/s, train_loss=0.542]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61024/214001 [00:55<02:22, 1076.82it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61056/214001 [00:55<02:22, 1076.82it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61088/214001 [00:55<02:22, 1076.82it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61120/214001 [00:55<02:21, 1076.82it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61152/214001 [00:55<02:21, 1082.60it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61152/214001 [00:56<02:21, 1082.60it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61184/214001 [00:56<02:21, 1082.60it/s, train_loss=0.541]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61216/214001 [00:56<02:21, 1082.60it/s, train_loss=0.54] \u001b[A\n",
            "Epoch 1:  29%|██▊       | 61248/214001 [00:56<02:21, 1082.60it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61280/214001 [00:56<02:22, 1070.43it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61280/214001 [00:56<02:22, 1070.43it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61312/214001 [00:56<02:22, 1070.43it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61344/214001 [00:56<02:22, 1070.43it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61376/214001 [00:56<02:22, 1070.43it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61408/214001 [00:56<02:26, 1038.54it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61408/214001 [00:56<02:26, 1038.54it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61440/214001 [00:56<02:26, 1038.54it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61472/214001 [00:56<02:26, 1038.54it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 61504/214001 [00:56<02:26, 1038.54it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61536/214001 [00:56<02:29, 1017.97it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61536/214001 [00:56<02:29, 1017.97it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61568/214001 [00:56<02:29, 1017.97it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61600/214001 [00:56<02:29, 1017.97it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61632/214001 [00:56<02:29, 1017.97it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61664/214001 [00:56<02:29, 1017.06it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61664/214001 [00:56<02:29, 1017.06it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61696/214001 [00:56<02:29, 1017.06it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61728/214001 [00:56<02:29, 1017.06it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61760/214001 [00:56<02:29, 1017.06it/s, train_loss=0.54] \u001b[A\n",
            "Epoch 1:  29%|██▉       | 61792/214001 [00:56<02:27, 1035.37it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61792/214001 [00:56<02:27, 1035.37it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61824/214001 [00:56<02:26, 1035.37it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61856/214001 [00:56<02:26, 1035.37it/s, train_loss=0.54]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61888/214001 [00:56<02:26, 1035.37it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61920/214001 [00:56<02:25, 1048.44it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61920/214001 [00:56<02:25, 1048.44it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61952/214001 [00:56<02:25, 1048.44it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 61984/214001 [00:56<02:24, 1048.44it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62016/214001 [00:56<02:24, 1048.44it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62048/214001 [00:56<02:26, 1038.99it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62048/214001 [00:56<02:26, 1038.99it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62080/214001 [00:56<02:26, 1038.99it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62112/214001 [00:56<02:26, 1038.99it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62144/214001 [00:56<02:26, 1038.99it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62176/214001 [00:57<02:28, 1023.84it/s, train_loss=0.539]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62176/214001 [00:57<02:28, 1023.84it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62208/214001 [00:57<02:28, 1023.84it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62240/214001 [00:57<02:28, 1023.84it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62272/214001 [00:57<02:28, 1023.84it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62304/214001 [00:57<02:29, 1016.80it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62304/214001 [00:57<02:29, 1016.80it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62336/214001 [00:57<02:29, 1016.80it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62368/214001 [00:57<02:29, 1016.80it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62400/214001 [00:57<02:29, 1016.80it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62432/214001 [00:57<02:26, 1036.05it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62432/214001 [00:57<02:26, 1036.05it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62464/214001 [00:57<02:26, 1036.05it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62496/214001 [00:57<02:26, 1036.05it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62528/214001 [00:57<02:26, 1036.05it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62560/214001 [00:57<02:24, 1048.46it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62560/214001 [00:57<02:24, 1048.46it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62592/214001 [00:57<02:24, 1048.46it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62624/214001 [00:57<02:24, 1048.46it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62656/214001 [00:57<02:24, 1048.46it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62688/214001 [00:57<02:23, 1056.53it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62688/214001 [00:57<02:23, 1056.53it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62720/214001 [00:57<02:23, 1056.53it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62752/214001 [00:57<02:23, 1056.53it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62784/214001 [00:57<02:23, 1056.53it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62816/214001 [00:57<02:25, 1041.00it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62816/214001 [00:57<02:25, 1041.00it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62848/214001 [00:57<02:25, 1041.00it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62880/214001 [00:57<02:25, 1041.00it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62912/214001 [00:57<02:25, 1041.00it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62944/214001 [00:57<02:24, 1042.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62944/214001 [00:57<02:24, 1042.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 62976/214001 [00:57<02:24, 1042.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63008/214001 [00:57<02:24, 1042.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63040/214001 [00:57<02:24, 1042.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63072/214001 [00:57<02:21, 1066.78it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63072/214001 [00:57<02:21, 1066.78it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 63104/214001 [00:57<02:21, 1066.78it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63136/214001 [00:57<02:21, 1066.78it/s, train_loss=0.538]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63168/214001 [00:57<02:21, 1066.78it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63200/214001 [00:57<02:18, 1090.42it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63200/214001 [00:57<02:18, 1090.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63232/214001 [00:58<02:18, 1090.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63264/214001 [00:58<02:18, 1090.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63296/214001 [00:58<02:18, 1090.42it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63328/214001 [00:58<02:15, 1112.79it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63328/214001 [00:58<02:15, 1112.79it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63360/214001 [00:58<02:15, 1112.79it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63392/214001 [00:58<02:15, 1112.79it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63424/214001 [00:58<02:15, 1112.79it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63456/214001 [00:58<02:11, 1144.10it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63456/214001 [00:58<02:11, 1144.10it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63488/214001 [00:58<02:11, 1144.10it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63520/214001 [00:58<02:11, 1144.10it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63552/214001 [00:58<02:11, 1144.10it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63584/214001 [00:58<02:09, 1163.68it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63584/214001 [00:58<02:09, 1163.68it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63616/214001 [00:58<02:09, 1163.68it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63648/214001 [00:58<02:09, 1163.68it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63680/214001 [00:58<02:09, 1163.68it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63712/214001 [00:58<02:09, 1156.55it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63712/214001 [00:58<02:09, 1156.55it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63744/214001 [00:58<02:09, 1156.55it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63776/214001 [00:58<02:09, 1156.55it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63808/214001 [00:58<02:09, 1156.55it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63840/214001 [00:58<02:08, 1172.80it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63840/214001 [00:58<02:08, 1172.80it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63872/214001 [00:58<02:08, 1172.80it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63904/214001 [00:58<02:07, 1172.80it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63936/214001 [00:58<02:07, 1172.80it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63968/214001 [00:58<02:11, 1144.84it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 63968/214001 [00:58<02:11, 1144.84it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64000/214001 [00:58<02:11, 1144.84it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64032/214001 [00:58<02:10, 1144.84it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64064/214001 [00:58<02:10, 1144.84it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64096/214001 [00:58<02:12, 1131.23it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64096/214001 [00:58<02:12, 1131.23it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64128/214001 [00:58<02:12, 1131.23it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64160/214001 [00:58<02:12, 1131.23it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 64192/214001 [00:58<02:12, 1131.23it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64224/214001 [00:58<02:12, 1129.75it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64224/214001 [00:58<02:12, 1129.75it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64256/214001 [00:58<02:12, 1129.75it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64288/214001 [00:58<02:12, 1129.75it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64320/214001 [00:58<02:12, 1129.75it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64352/214001 [00:58<02:10, 1147.01it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64352/214001 [00:58<02:10, 1147.01it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64384/214001 [00:59<02:10, 1147.01it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64416/214001 [00:59<02:10, 1147.01it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64448/214001 [00:59<02:10, 1147.01it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64480/214001 [00:59<02:11, 1140.27it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64480/214001 [00:59<02:11, 1140.27it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64512/214001 [00:59<02:11, 1140.27it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64544/214001 [00:59<02:11, 1140.27it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64576/214001 [00:59<02:11, 1140.27it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64608/214001 [00:59<02:10, 1149.03it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64608/214001 [00:59<02:10, 1149.03it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64640/214001 [00:59<02:09, 1149.03it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64672/214001 [00:59<02:09, 1149.03it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64704/214001 [00:59<02:09, 1149.03it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64736/214001 [00:59<02:09, 1148.46it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64736/214001 [00:59<02:09, 1148.46it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64768/214001 [00:59<02:09, 1148.46it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64800/214001 [00:59<02:09, 1148.46it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64832/214001 [00:59<02:09, 1148.46it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64864/214001 [00:59<02:07, 1165.25it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64864/214001 [00:59<02:07, 1165.25it/s, train_loss=0.537]\u001b[A\n",
            "Epoch 1:  30%|███       | 64896/214001 [00:59<02:07, 1165.25it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64928/214001 [00:59<02:07, 1165.25it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64960/214001 [00:59<02:07, 1165.25it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64992/214001 [00:59<02:12, 1121.29it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 64992/214001 [00:59<02:12, 1121.29it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 65024/214001 [00:59<02:12, 1121.29it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 65056/214001 [00:59<02:12, 1121.29it/s, train_loss=0.536]\u001b[A\n",
            "Epoch 1:  30%|███       | 65088/214001 [00:59<02:12, 1121.29it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  30%|███       | 65120/214001 [00:59<02:13, 1112.29it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  30%|███       | 65120/214001 [00:59<02:13, 1112.29it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  30%|███       | 65152/214001 [00:59<02:13, 1112.29it/s, train_loss=0.535]\u001b[A\n",
            "Epoch 1:  30%|███       | 65184/214001 [00:59<02:13, 1112.29it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  30%|███       | 65216/214001 [00:59<02:13, 1112.29it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  30%|███       | 65248/214001 [00:59<02:17, 1085.42it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  30%|███       | 65248/214001 [00:59<02:17, 1085.42it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  31%|███       | 65280/214001 [00:59<02:17, 1085.42it/s, train_loss=0.534]\u001b[A\n",
            "Epoch 1:  31%|███       | 65312/214001 [00:59<02:16, 1085.42it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65344/214001 [00:59<02:16, 1085.42it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65376/214001 [00:59<02:19, 1067.96it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65376/214001 [00:59<02:19, 1067.96it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65408/214001 [00:59<02:19, 1067.96it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65440/214001 [00:59<02:19, 1067.96it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65472/214001 [00:59<02:19, 1067.96it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65504/214001 [01:00<02:18, 1075.11it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65504/214001 [01:00<02:18, 1075.11it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65536/214001 [01:00<02:18, 1075.11it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65568/214001 [01:00<02:18, 1075.11it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65600/214001 [01:00<02:18, 1075.11it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65632/214001 [01:00<02:16, 1084.94it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65632/214001 [01:00<02:16, 1084.94it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65664/214001 [01:00<02:16, 1084.94it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65696/214001 [01:00<02:16, 1084.94it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65728/214001 [01:00<02:16, 1084.94it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65760/214001 [01:00<02:23, 1030.08it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65760/214001 [01:00<02:23, 1030.08it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65792/214001 [01:00<02:23, 1030.08it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 65824/214001 [01:00<02:23, 1030.08it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65856/214001 [01:00<02:23, 1030.08it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65888/214001 [01:00<02:29, 989.90it/s, train_loss=0.533] \u001b[A\n",
            "Epoch 1:  31%|███       | 65888/214001 [01:00<02:29, 989.90it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65920/214001 [01:00<02:29, 989.90it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65952/214001 [01:00<02:29, 989.90it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 65984/214001 [01:00<02:29, 989.90it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 66016/214001 [01:00<02:31, 979.33it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 66016/214001 [01:00<02:31, 979.33it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 66048/214001 [01:00<02:31, 979.33it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 66080/214001 [01:00<02:31, 979.33it/s, train_loss=0.533]\u001b[A\n",
            "Epoch 1:  31%|███       | 66112/214001 [01:00<02:31, 979.33it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 66144/214001 [01:00<02:35, 951.57it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 66144/214001 [01:00<02:35, 951.57it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 66176/214001 [01:00<02:35, 951.57it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 66208/214001 [01:00<02:35, 951.57it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 66240/214001 [01:00<02:40, 922.18it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 66240/214001 [01:00<02:40, 922.18it/s, train_loss=0.532]\u001b[A\n",
            "Epoch 1:  31%|███       | 66272/214001 [01:00<02:40, 922.18it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66304/214001 [01:00<02:40, 922.18it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66336/214001 [01:00<02:40, 922.18it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66368/214001 [01:00<02:37, 935.37it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66368/214001 [01:00<02:37, 935.37it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66400/214001 [01:00<02:37, 935.37it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66432/214001 [01:01<02:37, 935.37it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66464/214001 [01:01<02:36, 940.07it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66464/214001 [01:01<02:36, 940.07it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66496/214001 [01:01<02:36, 940.07it/s, train_loss=0.531]\u001b[A\n",
            "Epoch 1:  31%|███       | 66528/214001 [01:01<02:36, 940.07it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  31%|███       | 66560/214001 [01:01<02:36, 940.07it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  31%|███       | 66592/214001 [01:01<02:35, 948.75it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  31%|███       | 66592/214001 [01:01<02:35, 948.75it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  31%|███       | 66624/214001 [01:01<02:35, 948.75it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███       | 66656/214001 [01:01<02:35, 948.75it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███       | 66688/214001 [01:01<02:36, 938.77it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███       | 66688/214001 [01:01<02:36, 938.77it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  31%|███       | 66720/214001 [01:01<02:36, 938.77it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███       | 66752/214001 [01:01<02:36, 938.77it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███       | 66784/214001 [01:01<02:46, 885.86it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███       | 66784/214001 [01:01<02:46, 885.86it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███       | 66816/214001 [01:01<02:46, 885.86it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███       | 66848/214001 [01:01<02:46, 885.86it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66880/214001 [01:01<02:42, 903.80it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66880/214001 [01:01<02:42, 903.80it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  31%|███▏      | 66912/214001 [01:01<02:42, 903.80it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66944/214001 [01:01<02:42, 903.80it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66976/214001 [01:01<02:44, 894.64it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 66976/214001 [01:01<02:44, 894.64it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67008/214001 [01:01<02:44, 894.64it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67040/214001 [01:01<02:44, 894.64it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  31%|███▏      | 67072/214001 [01:01<02:47, 874.81it/s, train_loss=0.53]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67072/214001 [01:01<02:47, 874.81it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67104/214001 [01:01<02:47, 874.81it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67136/214001 [01:01<02:47, 874.81it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67168/214001 [01:01<02:47, 878.29it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67168/214001 [01:01<02:47, 878.29it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67200/214001 [01:01<02:47, 878.29it/s, train_loss=0.53] \u001b[A\n",
            "Epoch 1:  31%|███▏      | 67232/214001 [01:01<02:47, 878.29it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67264/214001 [01:01<02:43, 898.37it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67264/214001 [01:01<02:43, 898.37it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67296/214001 [01:01<02:43, 898.37it/s, train_loss=0.529]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67328/214001 [01:02<02:43, 898.37it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67360/214001 [01:02<02:43, 898.30it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67360/214001 [01:02<02:43, 898.30it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 67392/214001 [01:02<02:43, 898.30it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67424/214001 [01:02<02:43, 898.30it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67456/214001 [01:02<02:47, 875.30it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67456/214001 [01:02<02:47, 875.30it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67488/214001 [01:02<02:47, 875.30it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67520/214001 [01:02<02:47, 875.30it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67552/214001 [01:02<02:47, 875.30it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67584/214001 [01:02<02:39, 916.27it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67584/214001 [01:02<02:39, 916.27it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67616/214001 [01:02<02:39, 916.27it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67648/214001 [01:02<02:39, 916.27it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67680/214001 [01:02<02:39, 916.27it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67712/214001 [01:02<02:34, 945.09it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67712/214001 [01:02<02:34, 945.09it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67744/214001 [01:02<02:34, 945.09it/s, train_loss=0.528]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67776/214001 [01:02<02:34, 945.09it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67808/214001 [01:02<02:34, 948.00it/s, train_loss=0.527]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67808/214001 [01:02<02:34, 948.00it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67840/214001 [01:02<02:34, 948.00it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67872/214001 [01:02<02:34, 948.00it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67904/214001 [01:02<02:36, 931.02it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67904/214001 [01:02<02:36, 931.02it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67936/214001 [01:02<02:36, 931.02it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 67968/214001 [01:02<02:36, 931.02it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68000/214001 [01:02<02:38, 924.04it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68000/214001 [01:02<02:38, 924.04it/s, train_loss=0.526]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68032/214001 [01:02<02:37, 924.04it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68064/214001 [01:02<02:37, 924.04it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68096/214001 [01:02<02:37, 924.04it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68128/214001 [01:02<02:31, 964.79it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68128/214001 [01:02<02:31, 964.79it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68160/214001 [01:02<02:31, 964.79it/s, train_loss=0.525]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68192/214001 [01:02<02:31, 964.79it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68224/214001 [01:02<02:31, 964.79it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68256/214001 [01:02<02:24, 1008.20it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68256/214001 [01:02<02:24, 1008.20it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68288/214001 [01:02<02:24, 1008.20it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68320/214001 [01:03<02:24, 1008.20it/s, train_loss=0.524]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68352/214001 [01:03<02:24, 1008.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68384/214001 [01:03<02:21, 1031.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68384/214001 [01:03<02:21, 1031.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68416/214001 [01:03<02:21, 1031.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68448/214001 [01:03<02:21, 1031.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68480/214001 [01:03<02:21, 1031.20it/s, train_loss=0.523]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68512/214001 [01:03<02:27, 988.78it/s, train_loss=0.523] \u001b[A\n",
            "Epoch 1:  32%|███▏      | 68512/214001 [01:03<02:27, 988.78it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68544/214001 [01:03<02:27, 988.78it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68576/214001 [01:03<02:27, 988.78it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68608/214001 [01:03<02:27, 988.78it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68640/214001 [01:03<02:27, 985.34it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68640/214001 [01:03<02:27, 985.34it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68672/214001 [01:03<02:27, 985.34it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68704/214001 [01:03<02:27, 985.34it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68736/214001 [01:03<02:27, 985.34it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68768/214001 [01:03<02:25, 997.66it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68768/214001 [01:03<02:25, 997.66it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68800/214001 [01:03<02:25, 997.66it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68832/214001 [01:03<02:25, 997.66it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68864/214001 [01:03<02:25, 997.66it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68896/214001 [01:03<02:24, 1002.70it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68896/214001 [01:03<02:24, 1002.70it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68928/214001 [01:03<02:24, 1002.70it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 68960/214001 [01:03<02:24, 1002.70it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  32%|███▏      | 68992/214001 [01:03<02:24, 1002.70it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69024/214001 [01:03<02:25, 994.90it/s, train_loss=0.521] \u001b[A\n",
            "Epoch 1:  32%|███▏      | 69024/214001 [01:03<02:25, 994.90it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69056/214001 [01:03<02:25, 994.90it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69088/214001 [01:03<02:25, 994.90it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69120/214001 [01:03<02:25, 994.90it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69152/214001 [01:03<02:29, 968.45it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69152/214001 [01:03<02:29, 968.45it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69184/214001 [01:03<02:29, 968.45it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69216/214001 [01:03<02:29, 968.45it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69248/214001 [01:03<02:29, 968.45it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69280/214001 [01:04<02:32, 951.40it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69280/214001 [01:04<02:32, 951.40it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69312/214001 [01:04<02:32, 951.40it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69344/214001 [01:04<02:32, 951.40it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69376/214001 [01:04<02:35, 929.29it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69376/214001 [01:04<02:35, 929.29it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69408/214001 [01:04<02:35, 929.29it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69440/214001 [01:04<02:35, 929.29it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  32%|███▏      | 69472/214001 [01:04<02:37, 917.95it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69472/214001 [01:04<02:37, 917.95it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69504/214001 [01:04<02:37, 917.95it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 69536/214001 [01:04<02:37, 917.95it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69568/214001 [01:04<02:36, 920.27it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69568/214001 [01:04<02:36, 920.27it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69600/214001 [01:04<02:36, 920.27it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69632/214001 [01:04<02:36, 920.27it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69664/214001 [01:04<02:36, 923.20it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69664/214001 [01:04<02:36, 923.20it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69696/214001 [01:04<02:36, 923.20it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69728/214001 [01:04<02:36, 923.20it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69760/214001 [01:04<02:36, 923.20it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69792/214001 [01:04<02:32, 947.84it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69792/214001 [01:04<02:32, 947.84it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69824/214001 [01:04<02:32, 947.84it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69856/214001 [01:04<02:32, 947.84it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69888/214001 [01:04<02:32, 947.84it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69920/214001 [01:04<02:29, 962.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69920/214001 [01:04<02:29, 962.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69952/214001 [01:04<02:29, 962.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 69984/214001 [01:04<02:29, 962.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70016/214001 [01:04<02:33, 939.87it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70016/214001 [01:04<02:33, 939.87it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70048/214001 [01:04<02:33, 939.87it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70080/214001 [01:04<02:33, 939.87it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70112/214001 [01:04<02:37, 913.82it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70112/214001 [01:04<02:37, 913.82it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 70144/214001 [01:04<02:37, 913.82it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70176/214001 [01:05<02:37, 913.82it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70208/214001 [01:05<02:38, 905.69it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70208/214001 [01:05<02:38, 905.69it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70240/214001 [01:05<02:38, 905.69it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70272/214001 [01:05<02:38, 905.69it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70304/214001 [01:05<02:42, 882.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70304/214001 [01:05<02:42, 882.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70336/214001 [01:05<02:42, 882.09it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70368/214001 [01:05<02:42, 882.09it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70400/214001 [01:05<02:39, 902.09it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70400/214001 [01:05<02:39, 902.09it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70432/214001 [01:05<02:39, 902.09it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70464/214001 [01:05<02:39, 902.09it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70496/214001 [01:05<02:37, 910.10it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70496/214001 [01:05<02:37, 910.10it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70528/214001 [01:05<02:37, 910.10it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70560/214001 [01:05<02:37, 910.10it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70592/214001 [01:05<02:37, 910.10it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70624/214001 [01:05<02:25, 987.27it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70624/214001 [01:05<02:25, 987.27it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70656/214001 [01:05<02:25, 987.27it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 70688/214001 [01:05<02:25, 987.27it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70720/214001 [01:05<02:25, 987.27it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 70752/214001 [01:05<02:20, 1020.42it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70752/214001 [01:05<02:20, 1020.42it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70784/214001 [01:05<02:20, 1020.42it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70816/214001 [01:05<02:20, 1020.42it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70848/214001 [01:05<02:20, 1020.42it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70880/214001 [01:05<02:17, 1037.26it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70880/214001 [01:05<02:17, 1037.26it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70912/214001 [01:05<02:17, 1037.26it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70944/214001 [01:05<02:17, 1037.26it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 70976/214001 [01:05<02:17, 1037.26it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71008/214001 [01:05<02:19, 1025.61it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71008/214001 [01:05<02:19, 1025.61it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71040/214001 [01:05<02:19, 1025.61it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71072/214001 [01:05<02:19, 1025.61it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71104/214001 [01:05<02:19, 1025.61it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71136/214001 [01:05<02:15, 1055.73it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71136/214001 [01:05<02:15, 1055.73it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71168/214001 [01:05<02:15, 1055.73it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71200/214001 [01:05<02:15, 1055.73it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71232/214001 [01:06<02:15, 1055.73it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 71264/214001 [01:06<02:11, 1087.12it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71264/214001 [01:06<02:11, 1087.12it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71296/214001 [01:06<02:11, 1087.12it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71328/214001 [01:06<02:11, 1087.12it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71360/214001 [01:06<02:11, 1087.12it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71392/214001 [01:06<02:12, 1075.95it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71392/214001 [01:06<02:12, 1075.95it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71424/214001 [01:06<02:12, 1075.95it/s, train_loss=0.522]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71456/214001 [01:06<02:12, 1075.95it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71488/214001 [01:06<02:12, 1075.95it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71520/214001 [01:06<02:10, 1092.53it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71520/214001 [01:06<02:10, 1092.53it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71552/214001 [01:06<02:10, 1092.53it/s, train_loss=0.521]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71584/214001 [01:06<02:10, 1092.53it/s, train_loss=0.52] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 71616/214001 [01:06<02:10, 1092.53it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71648/214001 [01:06<02:06, 1120.92it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71648/214001 [01:06<02:06, 1120.92it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 71680/214001 [01:06<02:06, 1120.92it/s, train_loss=0.52]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71712/214001 [01:06<02:06, 1120.92it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71744/214001 [01:06<02:06, 1120.92it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71776/214001 [01:06<02:10, 1089.82it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71776/214001 [01:06<02:10, 1089.82it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71808/214001 [01:06<02:10, 1089.82it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71840/214001 [01:06<02:10, 1089.82it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71872/214001 [01:06<02:10, 1089.82it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71904/214001 [01:06<02:05, 1130.66it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71904/214001 [01:06<02:05, 1130.66it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71936/214001 [01:06<02:05, 1130.66it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 71968/214001 [01:06<02:05, 1130.66it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72000/214001 [01:06<02:05, 1130.66it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72032/214001 [01:06<02:02, 1155.53it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72032/214001 [01:06<02:02, 1155.53it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72064/214001 [01:06<02:02, 1155.53it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72096/214001 [01:06<02:02, 1155.53it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72128/214001 [01:06<02:02, 1155.53it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72160/214001 [01:06<02:02, 1157.28it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72160/214001 [01:06<02:02, 1157.28it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72192/214001 [01:06<02:02, 1157.28it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 72224/214001 [01:06<02:02, 1157.28it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72256/214001 [01:06<02:02, 1157.28it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72288/214001 [01:06<02:02, 1159.43it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72288/214001 [01:06<02:02, 1159.43it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72320/214001 [01:06<02:02, 1159.43it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72352/214001 [01:07<02:02, 1159.43it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72384/214001 [01:07<02:02, 1159.43it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72416/214001 [01:07<02:04, 1138.42it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72416/214001 [01:07<02:04, 1138.42it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72448/214001 [01:07<02:04, 1138.42it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72480/214001 [01:07<02:04, 1138.42it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72512/214001 [01:07<02:04, 1138.42it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72544/214001 [01:07<02:04, 1137.73it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72544/214001 [01:07<02:04, 1137.73it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72576/214001 [01:07<02:04, 1137.73it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72608/214001 [01:07<02:04, 1137.73it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72640/214001 [01:07<02:04, 1137.73it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72672/214001 [01:07<02:03, 1146.44it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72672/214001 [01:07<02:03, 1146.44it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72704/214001 [01:07<02:03, 1146.44it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72736/214001 [01:07<02:03, 1146.44it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72768/214001 [01:07<02:03, 1146.44it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72800/214001 [01:07<02:02, 1153.67it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72800/214001 [01:07<02:02, 1153.67it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72832/214001 [01:07<02:02, 1153.67it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72864/214001 [01:07<02:02, 1153.67it/s, train_loss=0.519]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72896/214001 [01:07<02:02, 1153.67it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72928/214001 [01:07<02:01, 1158.83it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72928/214001 [01:07<02:01, 1158.83it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72960/214001 [01:07<02:01, 1158.83it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 72992/214001 [01:07<02:01, 1158.83it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73024/214001 [01:07<02:01, 1158.83it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73056/214001 [01:07<02:02, 1149.88it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73056/214001 [01:07<02:02, 1149.88it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73088/214001 [01:07<02:02, 1149.88it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73120/214001 [01:07<02:02, 1149.88it/s, train_loss=0.518]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73152/214001 [01:07<02:02, 1149.88it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73184/214001 [01:07<02:00, 1163.86it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73184/214001 [01:07<02:00, 1163.86it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73216/214001 [01:07<02:00, 1163.86it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73248/214001 [01:07<02:00, 1163.86it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73280/214001 [01:07<02:00, 1163.86it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73312/214001 [01:07<01:59, 1174.87it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73312/214001 [01:07<01:59, 1174.87it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73344/214001 [01:07<01:59, 1174.87it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73376/214001 [01:07<01:59, 1174.87it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73408/214001 [01:07<01:59, 1174.87it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73440/214001 [01:07<01:58, 1184.99it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73440/214001 [01:07<01:58, 1184.99it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73472/214001 [01:07<01:58, 1184.99it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73504/214001 [01:07<01:58, 1184.99it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73536/214001 [01:08<01:58, 1184.99it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73568/214001 [01:08<01:57, 1193.03it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73568/214001 [01:08<01:57, 1193.03it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73600/214001 [01:08<01:57, 1193.03it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73632/214001 [01:08<01:57, 1193.03it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73664/214001 [01:08<01:57, 1193.03it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73696/214001 [01:08<01:59, 1169.41it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73696/214001 [01:08<01:59, 1169.41it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73728/214001 [01:08<01:59, 1169.41it/s, train_loss=0.517]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73760/214001 [01:08<01:59, 1169.41it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73792/214001 [01:08<01:59, 1169.41it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73824/214001 [01:08<02:00, 1168.03it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 73824/214001 [01:08<02:00, 1168.03it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73856/214001 [01:08<01:59, 1168.03it/s, train_loss=0.516]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73888/214001 [01:08<01:59, 1168.03it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73920/214001 [01:08<01:59, 1168.03it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73952/214001 [01:08<01:58, 1185.77it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73952/214001 [01:08<01:58, 1185.77it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 73984/214001 [01:08<01:58, 1185.77it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74016/214001 [01:08<01:58, 1185.77it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74048/214001 [01:08<01:58, 1185.77it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74080/214001 [01:08<01:56, 1198.67it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74080/214001 [01:08<01:56, 1198.67it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74112/214001 [01:08<01:56, 1198.67it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74144/214001 [01:08<01:56, 1198.67it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74176/214001 [01:08<01:56, 1198.67it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74208/214001 [01:08<02:00, 1155.77it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74208/214001 [01:08<02:00, 1155.77it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74240/214001 [01:08<02:00, 1155.77it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74272/214001 [01:08<02:00, 1155.77it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74304/214001 [01:08<02:00, 1155.77it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74336/214001 [01:08<01:59, 1164.47it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74336/214001 [01:08<01:59, 1164.47it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74368/214001 [01:08<01:59, 1164.47it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74400/214001 [01:08<01:59, 1164.47it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74432/214001 [01:08<01:59, 1164.47it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74464/214001 [01:08<02:03, 1134.37it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74464/214001 [01:08<02:03, 1134.37it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74496/214001 [01:08<02:02, 1134.37it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74528/214001 [01:08<02:02, 1134.37it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74560/214001 [01:08<02:02, 1134.37it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74592/214001 [01:08<02:03, 1132.65it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74592/214001 [01:08<02:03, 1132.65it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74624/214001 [01:08<02:03, 1132.65it/s, train_loss=0.515]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74656/214001 [01:08<02:03, 1132.65it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74688/214001 [01:09<02:02, 1132.65it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74720/214001 [01:09<02:00, 1156.40it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74720/214001 [01:09<02:00, 1156.40it/s, train_loss=0.514]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74752/214001 [01:09<02:00, 1156.40it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74784/214001 [01:09<02:00, 1156.40it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74816/214001 [01:09<02:00, 1156.40it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74848/214001 [01:09<01:59, 1164.16it/s, train_loss=0.513]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74848/214001 [01:09<01:59, 1164.16it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 74880/214001 [01:09<01:59, 1164.16it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 74912/214001 [01:09<01:59, 1164.16it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 74944/214001 [01:09<01:59, 1164.16it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 74976/214001 [01:09<01:59, 1164.85it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 74976/214001 [01:09<01:59, 1164.85it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75008/214001 [01:09<01:59, 1164.85it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75040/214001 [01:09<01:59, 1164.85it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75072/214001 [01:09<01:59, 1164.85it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75104/214001 [01:09<02:04, 1120.03it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75104/214001 [01:09<02:04, 1120.03it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75136/214001 [01:09<02:03, 1120.03it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75168/214001 [01:09<02:03, 1120.03it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75200/214001 [01:09<02:03, 1120.03it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75232/214001 [01:09<02:04, 1118.46it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75232/214001 [01:09<02:04, 1118.46it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75264/214001 [01:09<02:04, 1118.46it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75296/214001 [01:09<02:04, 1118.46it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75328/214001 [01:09<02:03, 1118.46it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75360/214001 [01:09<02:08, 1082.47it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75360/214001 [01:09<02:08, 1082.47it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75392/214001 [01:09<02:08, 1082.47it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75424/214001 [01:09<02:08, 1082.47it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75456/214001 [01:09<02:07, 1082.47it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75488/214001 [01:09<02:05, 1105.38it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75488/214001 [01:09<02:05, 1105.38it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75520/214001 [01:09<02:05, 1105.38it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75552/214001 [01:09<02:05, 1105.38it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75584/214001 [01:09<02:05, 1105.38it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75616/214001 [01:09<02:02, 1126.16it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75616/214001 [01:09<02:02, 1126.16it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75648/214001 [01:09<02:02, 1126.16it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75680/214001 [01:09<02:02, 1126.16it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75712/214001 [01:09<02:02, 1126.16it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75744/214001 [01:09<02:00, 1146.42it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75744/214001 [01:09<02:00, 1146.42it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75776/214001 [01:09<02:00, 1146.42it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75808/214001 [01:10<02:00, 1146.42it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75840/214001 [01:10<02:00, 1146.42it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75872/214001 [01:10<01:59, 1157.17it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75872/214001 [01:10<01:59, 1157.17it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75904/214001 [01:10<01:59, 1157.17it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75936/214001 [01:10<01:59, 1157.17it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 75968/214001 [01:10<01:59, 1157.17it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76000/214001 [01:10<02:02, 1126.97it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76000/214001 [01:10<02:02, 1126.97it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76032/214001 [01:10<02:02, 1126.97it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76064/214001 [01:10<02:02, 1126.97it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76096/214001 [01:10<02:02, 1126.97it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76128/214001 [01:10<02:07, 1078.35it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76128/214001 [01:10<02:07, 1078.35it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76160/214001 [01:10<02:07, 1078.35it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76192/214001 [01:10<02:07, 1078.35it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76224/214001 [01:10<02:07, 1078.35it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76256/214001 [01:10<03:00, 763.00it/s, train_loss=0.512] \u001b[A\n",
            "Epoch 1:  36%|███▌      | 76256/214001 [01:10<03:00, 763.00it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76288/214001 [01:10<03:00, 763.00it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76320/214001 [01:10<03:00, 763.00it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76352/214001 [01:10<03:42, 618.54it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76352/214001 [01:10<03:42, 618.54it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76384/214001 [01:10<03:42, 618.54it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76416/214001 [01:11<03:42, 618.54it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76448/214001 [01:11<04:02, 567.51it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76448/214001 [01:11<04:02, 567.51it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76480/214001 [01:11<04:02, 567.51it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76512/214001 [01:11<04:02, 567.51it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76544/214001 [01:11<04:37, 494.69it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76544/214001 [01:11<04:37, 494.69it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76576/214001 [01:11<04:37, 494.69it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76608/214001 [01:11<05:04, 451.45it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76608/214001 [01:11<05:04, 451.45it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76640/214001 [01:11<05:04, 451.45it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76672/214001 [01:11<05:11, 440.52it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76672/214001 [01:11<05:11, 440.52it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76704/214001 [01:11<05:11, 440.52it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76736/214001 [01:11<05:11, 440.52it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76768/214001 [01:11<05:11, 440.52it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76800/214001 [01:11<04:02, 566.05it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76800/214001 [01:11<04:02, 566.05it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76832/214001 [01:11<04:02, 566.05it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76864/214001 [01:11<04:02, 566.05it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76896/214001 [01:11<04:02, 566.05it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76928/214001 [01:11<03:18, 690.83it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76928/214001 [01:11<03:18, 690.83it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76960/214001 [01:11<03:18, 690.83it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 76992/214001 [01:11<03:18, 690.83it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77024/214001 [01:11<03:18, 690.83it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77056/214001 [01:11<02:48, 811.52it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77056/214001 [01:12<02:48, 811.52it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77088/214001 [01:12<02:48, 811.52it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77120/214001 [01:12<02:48, 811.52it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77152/214001 [01:12<02:48, 811.52it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  36%|███▌      | 77184/214001 [01:12<02:29, 913.85it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77184/214001 [01:12<02:29, 913.85it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77216/214001 [01:12<02:29, 913.85it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77248/214001 [01:12<02:29, 913.85it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77280/214001 [01:12<02:29, 913.85it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77312/214001 [01:12<02:16, 998.82it/s, train_loss=0.512]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77312/214001 [01:12<02:16, 998.82it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77344/214001 [01:12<02:16, 998.82it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77376/214001 [01:12<02:16, 998.82it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77408/214001 [01:12<02:16, 998.82it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77440/214001 [01:12<02:08, 1058.74it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77440/214001 [01:12<02:08, 1058.74it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77472/214001 [01:12<02:08, 1058.74it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  36%|███▌      | 77504/214001 [01:12<02:08, 1058.74it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77536/214001 [01:12<02:08, 1058.74it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77568/214001 [01:12<02:05, 1087.77it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 77568/214001 [01:12<02:05, 1087.77it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77600/214001 [01:12<02:05, 1087.77it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77632/214001 [01:12<02:05, 1087.77it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  36%|███▋      | 77664/214001 [01:12<02:05, 1087.77it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77696/214001 [01:12<02:03, 1106.91it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77696/214001 [01:12<02:03, 1106.91it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77728/214001 [01:12<02:03, 1106.91it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77760/214001 [01:12<02:03, 1106.91it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77792/214001 [01:12<02:03, 1106.91it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77824/214001 [01:12<02:04, 1091.08it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77824/214001 [01:12<02:04, 1091.08it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77856/214001 [01:12<02:04, 1091.08it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77888/214001 [01:12<02:04, 1091.08it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77920/214001 [01:12<02:04, 1091.08it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77952/214001 [01:12<02:09, 1052.07it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77952/214001 [01:12<02:09, 1052.07it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 77984/214001 [01:12<02:09, 1052.07it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 78016/214001 [01:12<02:09, 1052.07it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 78048/214001 [01:12<02:09, 1052.07it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 78080/214001 [01:12<02:05, 1080.29it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 78080/214001 [01:12<02:05, 1080.29it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78112/214001 [01:12<02:05, 1080.29it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78144/214001 [01:12<02:05, 1080.29it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78176/214001 [01:12<02:05, 1080.29it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78208/214001 [01:12<02:01, 1118.36it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78208/214001 [01:13<02:01, 1118.36it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78240/214001 [01:13<02:01, 1118.36it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  37%|███▋      | 78272/214001 [01:13<02:01, 1118.36it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78304/214001 [01:13<02:01, 1118.36it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78336/214001 [01:13<01:58, 1144.23it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78336/214001 [01:13<01:58, 1144.23it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78368/214001 [01:13<01:58, 1144.23it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  37%|███▋      | 78400/214001 [01:13<01:58, 1144.23it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78432/214001 [01:13<01:58, 1144.23it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78464/214001 [01:13<01:56, 1166.16it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78464/214001 [01:13<01:56, 1166.16it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78496/214001 [01:13<01:56, 1166.16it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78528/214001 [01:13<01:56, 1166.16it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78560/214001 [01:13<01:56, 1166.16it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  37%|███▋      | 78592/214001 [01:13<01:54, 1180.27it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78592/214001 [01:13<01:54, 1180.27it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78624/214001 [01:13<01:54, 1180.27it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78656/214001 [01:13<01:54, 1180.27it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78688/214001 [01:13<01:54, 1180.27it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78720/214001 [01:13<01:53, 1191.93it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78720/214001 [01:13<01:53, 1191.93it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78752/214001 [01:13<01:53, 1191.93it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78784/214001 [01:13<01:53, 1191.93it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78816/214001 [01:13<01:53, 1191.93it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78848/214001 [01:13<01:52, 1203.45it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78848/214001 [01:13<01:52, 1203.45it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78880/214001 [01:13<01:52, 1203.45it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78912/214001 [01:13<01:52, 1203.45it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78944/214001 [01:13<01:52, 1203.45it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78976/214001 [01:13<01:51, 1215.09it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 78976/214001 [01:13<01:51, 1215.09it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79008/214001 [01:13<01:51, 1215.09it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79040/214001 [01:13<01:51, 1215.09it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79072/214001 [01:13<01:51, 1215.09it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  37%|███▋      | 79104/214001 [01:13<01:53, 1189.56it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79104/214001 [01:13<01:53, 1189.56it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79136/214001 [01:13<01:53, 1189.56it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79168/214001 [01:13<01:53, 1189.56it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79200/214001 [01:13<01:53, 1189.56it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79232/214001 [01:13<01:56, 1156.41it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79232/214001 [01:13<01:56, 1156.41it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79264/214001 [01:13<01:56, 1156.41it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79296/214001 [01:13<01:56, 1156.41it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79328/214001 [01:13<01:56, 1156.41it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79360/214001 [01:13<01:56, 1158.05it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79360/214001 [01:13<01:56, 1158.05it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  37%|███▋      | 79392/214001 [01:14<01:56, 1158.05it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79424/214001 [01:14<01:56, 1158.05it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79456/214001 [01:14<01:56, 1158.05it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79488/214001 [01:14<02:03, 1087.32it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79488/214001 [01:14<02:03, 1087.32it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79520/214001 [01:14<02:03, 1087.32it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79552/214001 [01:14<02:03, 1087.32it/s, train_loss=0.511]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79584/214001 [01:14<02:03, 1087.32it/s, train_loss=0.51] \u001b[A\n",
            "Epoch 1:  37%|███▋      | 79616/214001 [01:14<02:01, 1103.11it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79616/214001 [01:14<02:01, 1103.11it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79648/214001 [01:14<02:01, 1103.11it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79680/214001 [01:14<02:01, 1103.11it/s, train_loss=0.51]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79712/214001 [01:14<02:01, 1103.11it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79744/214001 [01:14<01:59, 1124.57it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79744/214001 [01:14<01:59, 1124.57it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79776/214001 [01:14<01:59, 1124.57it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79808/214001 [01:14<01:59, 1124.57it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79840/214001 [01:14<01:59, 1124.57it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79872/214001 [01:14<01:58, 1136.10it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79872/214001 [01:14<01:58, 1136.10it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79904/214001 [01:14<01:58, 1136.10it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79936/214001 [01:14<01:58, 1136.10it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 79968/214001 [01:14<01:57, 1136.10it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80000/214001 [01:14<01:57, 1144.39it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80000/214001 [01:14<01:57, 1144.39it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80032/214001 [01:14<01:57, 1144.39it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80064/214001 [01:14<01:57, 1144.39it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80096/214001 [01:14<01:57, 1144.39it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80128/214001 [01:14<01:57, 1143.60it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80128/214001 [01:14<01:57, 1143.60it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80160/214001 [01:14<01:57, 1143.60it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80192/214001 [01:14<01:57, 1143.60it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 80224/214001 [01:14<01:56, 1143.60it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80256/214001 [01:14<01:58, 1126.56it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80256/214001 [01:14<01:58, 1126.56it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80288/214001 [01:14<01:58, 1126.56it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80320/214001 [01:14<01:58, 1126.56it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80352/214001 [01:14<01:58, 1126.56it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80384/214001 [01:14<02:01, 1099.62it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80384/214001 [01:14<02:01, 1099.62it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80416/214001 [01:14<02:01, 1099.62it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80448/214001 [01:14<02:01, 1099.62it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80480/214001 [01:14<02:01, 1099.62it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80512/214001 [01:14<01:57, 1138.18it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80512/214001 [01:15<01:57, 1138.18it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80544/214001 [01:15<01:57, 1138.18it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80576/214001 [01:15<01:57, 1138.18it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80608/214001 [01:15<01:57, 1138.18it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80640/214001 [01:15<01:56, 1140.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80640/214001 [01:15<01:56, 1140.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80672/214001 [01:15<01:56, 1140.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80704/214001 [01:15<01:56, 1140.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80736/214001 [01:15<01:56, 1140.38it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80768/214001 [01:15<01:56, 1142.31it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80768/214001 [01:15<01:56, 1142.31it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80800/214001 [01:15<01:56, 1142.31it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80832/214001 [01:15<01:56, 1142.31it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80864/214001 [01:15<01:56, 1142.31it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80896/214001 [01:15<01:53, 1172.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80896/214001 [01:15<01:53, 1172.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80928/214001 [01:15<01:53, 1172.54it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80960/214001 [01:15<01:53, 1172.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 80992/214001 [01:15<01:53, 1172.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81024/214001 [01:15<01:51, 1196.32it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81024/214001 [01:15<01:51, 1196.32it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81056/214001 [01:15<01:51, 1196.32it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81088/214001 [01:15<01:51, 1196.32it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81120/214001 [01:15<01:51, 1196.32it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81152/214001 [01:15<01:50, 1204.34it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81152/214001 [01:15<01:50, 1204.34it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81184/214001 [01:15<01:50, 1204.34it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81216/214001 [01:15<01:50, 1204.34it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81248/214001 [01:15<01:50, 1204.34it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81280/214001 [01:15<01:55, 1145.54it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81280/214001 [01:15<01:55, 1145.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81312/214001 [01:15<01:55, 1145.54it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81344/214001 [01:15<01:55, 1145.54it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81376/214001 [01:15<01:55, 1145.54it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81408/214001 [01:15<01:56, 1137.13it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81408/214001 [01:15<01:56, 1137.13it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81440/214001 [01:15<01:56, 1137.13it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81472/214001 [01:15<01:56, 1137.13it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81504/214001 [01:15<01:56, 1137.13it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81536/214001 [01:15<01:54, 1151.92it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81536/214001 [01:15<01:54, 1151.92it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81568/214001 [01:15<01:54, 1151.92it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81600/214001 [01:15<01:54, 1151.92it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81632/214001 [01:15<01:54, 1151.92it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81664/214001 [01:15<01:55, 1148.48it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81664/214001 [01:15<01:55, 1148.48it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81696/214001 [01:16<01:55, 1148.48it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81728/214001 [01:16<01:55, 1148.48it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81760/214001 [01:16<01:55, 1148.48it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81792/214001 [01:16<01:52, 1180.19it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81792/214001 [01:16<01:52, 1180.19it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81824/214001 [01:16<01:51, 1180.19it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81856/214001 [01:16<01:51, 1180.19it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81888/214001 [01:16<01:51, 1180.19it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81920/214001 [01:16<01:50, 1193.89it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81920/214001 [01:16<01:50, 1193.89it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81952/214001 [01:16<01:50, 1193.89it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 81984/214001 [01:16<01:50, 1193.89it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82016/214001 [01:16<01:50, 1193.89it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82048/214001 [01:16<01:53, 1162.48it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82048/214001 [01:16<01:53, 1162.48it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82080/214001 [01:16<01:53, 1162.48it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82112/214001 [01:16<01:53, 1162.48it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82144/214001 [01:16<01:53, 1162.48it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82176/214001 [01:16<01:57, 1124.97it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82176/214001 [01:16<01:57, 1124.97it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82208/214001 [01:16<01:57, 1124.97it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82240/214001 [01:16<01:57, 1124.97it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82272/214001 [01:16<01:57, 1124.97it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82304/214001 [01:16<01:57, 1117.74it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82304/214001 [01:16<01:57, 1117.74it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82336/214001 [01:16<01:57, 1117.74it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 82368/214001 [01:16<01:57, 1117.74it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82400/214001 [01:16<01:57, 1117.74it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82432/214001 [01:16<01:56, 1125.61it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82432/214001 [01:16<01:56, 1125.61it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82464/214001 [01:16<01:56, 1125.61it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82496/214001 [01:16<01:56, 1125.61it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82528/214001 [01:16<01:56, 1125.61it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82560/214001 [01:16<01:55, 1136.09it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82560/214001 [01:16<01:55, 1136.09it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82592/214001 [01:16<01:55, 1136.09it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82624/214001 [01:16<01:55, 1136.09it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82656/214001 [01:16<01:55, 1136.09it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82688/214001 [01:16<01:53, 1153.75it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82688/214001 [01:16<01:53, 1153.75it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82720/214001 [01:16<01:53, 1153.75it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82752/214001 [01:16<01:53, 1153.75it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82784/214001 [01:16<01:53, 1153.75it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82816/214001 [01:16<01:56, 1127.73it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82816/214001 [01:17<01:56, 1127.73it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82848/214001 [01:17<01:56, 1127.73it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82880/214001 [01:17<01:56, 1127.73it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 82912/214001 [01:17<01:56, 1127.73it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 82944/214001 [01:17<01:57, 1119.07it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 82944/214001 [01:17<01:57, 1119.07it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 82976/214001 [01:17<01:57, 1119.07it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83008/214001 [01:17<01:57, 1119.07it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83040/214001 [01:17<01:57, 1119.07it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83072/214001 [01:17<01:54, 1139.84it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83072/214001 [01:17<01:54, 1139.84it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83104/214001 [01:17<01:54, 1139.84it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83136/214001 [01:17<01:54, 1139.84it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83168/214001 [01:17<01:54, 1139.84it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83200/214001 [01:17<01:54, 1142.03it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83200/214001 [01:17<01:54, 1142.03it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83232/214001 [01:17<01:54, 1142.03it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83264/214001 [01:17<01:54, 1142.03it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83296/214001 [01:17<01:54, 1142.03it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83328/214001 [01:17<01:56, 1122.05it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83328/214001 [01:17<01:56, 1122.05it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83360/214001 [01:17<01:56, 1122.05it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83392/214001 [01:17<01:56, 1122.05it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83424/214001 [01:17<01:56, 1122.05it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83456/214001 [01:17<01:55, 1127.46it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83456/214001 [01:17<01:55, 1127.46it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83488/214001 [01:17<01:55, 1127.46it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83520/214001 [01:17<01:55, 1127.46it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83552/214001 [01:17<01:55, 1127.46it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83584/214001 [01:17<01:53, 1153.37it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83584/214001 [01:17<01:53, 1153.37it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83616/214001 [01:17<01:53, 1153.37it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83648/214001 [01:17<01:53, 1153.37it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83680/214001 [01:17<01:52, 1153.37it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83712/214001 [01:17<01:59, 1087.63it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83712/214001 [01:17<01:59, 1087.63it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83744/214001 [01:17<01:59, 1087.63it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83776/214001 [01:17<01:59, 1087.63it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83808/214001 [01:17<01:59, 1087.63it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83840/214001 [01:17<02:03, 1052.52it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83840/214001 [01:17<02:03, 1052.52it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83872/214001 [01:17<02:03, 1052.52it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83904/214001 [01:18<02:03, 1052.52it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83936/214001 [01:18<02:03, 1052.52it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83968/214001 [01:18<02:04, 1047.27it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 83968/214001 [01:18<02:04, 1047.27it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84000/214001 [01:18<02:04, 1047.27it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84032/214001 [01:18<02:04, 1047.27it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84064/214001 [01:18<02:04, 1047.27it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84096/214001 [01:18<01:57, 1104.83it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84096/214001 [01:18<01:57, 1104.83it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84128/214001 [01:18<01:57, 1104.83it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84160/214001 [01:18<01:57, 1104.83it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84192/214001 [01:18<01:57, 1104.83it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84224/214001 [01:18<01:53, 1145.90it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84224/214001 [01:18<01:53, 1145.90it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84256/214001 [01:18<01:53, 1145.90it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84288/214001 [01:18<01:53, 1145.90it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84320/214001 [01:18<01:53, 1145.90it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84352/214001 [01:18<01:50, 1175.59it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84352/214001 [01:18<01:50, 1175.59it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84384/214001 [01:18<01:50, 1175.59it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84416/214001 [01:18<01:50, 1175.59it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84448/214001 [01:18<01:50, 1175.59it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84480/214001 [01:18<01:48, 1193.59it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84480/214001 [01:18<01:48, 1193.59it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 84512/214001 [01:18<01:48, 1193.59it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84544/214001 [01:18<01:48, 1193.59it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84576/214001 [01:18<01:48, 1193.59it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84608/214001 [01:18<01:49, 1182.81it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84608/214001 [01:18<01:49, 1182.81it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84640/214001 [01:18<01:49, 1182.81it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84672/214001 [01:18<01:49, 1182.81it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84704/214001 [01:18<01:49, 1182.81it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84736/214001 [01:18<01:48, 1196.66it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84736/214001 [01:18<01:48, 1196.66it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84768/214001 [01:18<01:47, 1196.66it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84800/214001 [01:18<01:47, 1196.66it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84832/214001 [01:18<01:47, 1196.66it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84864/214001 [01:18<01:53, 1138.65it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84864/214001 [01:18<01:53, 1138.65it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84896/214001 [01:18<01:53, 1138.65it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84928/214001 [01:18<01:53, 1138.65it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84960/214001 [01:18<01:53, 1138.65it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84992/214001 [01:18<01:54, 1126.87it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 84992/214001 [01:18<01:54, 1126.87it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85024/214001 [01:18<01:54, 1126.87it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85056/214001 [01:18<01:54, 1126.87it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85088/214001 [01:19<01:54, 1126.87it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85120/214001 [01:19<01:54, 1126.30it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85120/214001 [01:19<01:54, 1126.30it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85152/214001 [01:19<01:54, 1126.30it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85184/214001 [01:19<01:54, 1126.30it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85216/214001 [01:19<01:54, 1126.30it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85248/214001 [01:19<01:51, 1155.16it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85248/214001 [01:19<01:51, 1155.16it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85280/214001 [01:19<01:51, 1155.16it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85312/214001 [01:19<01:51, 1155.16it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85344/214001 [01:19<01:51, 1155.16it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85376/214001 [01:19<01:49, 1179.94it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85376/214001 [01:19<01:49, 1179.94it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85408/214001 [01:19<01:48, 1179.94it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85440/214001 [01:19<01:48, 1179.94it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85472/214001 [01:19<01:48, 1179.94it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85504/214001 [01:19<01:46, 1206.22it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85504/214001 [01:19<01:46, 1206.22it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85536/214001 [01:19<01:46, 1206.22it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85568/214001 [01:19<01:46, 1206.22it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 85600/214001 [01:19<01:46, 1206.22it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 85632/214001 [01:19<01:45, 1217.56it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 85632/214001 [01:19<01:45, 1217.56it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 85664/214001 [01:19<01:45, 1217.56it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 85696/214001 [01:19<01:45, 1217.56it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 85728/214001 [01:19<01:45, 1217.56it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 85760/214001 [01:19<01:44, 1224.30it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 85760/214001 [01:19<01:44, 1224.30it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 85792/214001 [01:19<01:44, 1224.30it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 85824/214001 [01:19<01:44, 1224.30it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 85856/214001 [01:19<01:44, 1224.30it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 85888/214001 [01:19<01:44, 1221.57it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 85888/214001 [01:19<01:44, 1221.57it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 85920/214001 [01:19<01:44, 1221.57it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 85952/214001 [01:19<01:44, 1221.57it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 85984/214001 [01:19<01:44, 1221.57it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86016/214001 [01:19<01:46, 1206.43it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86016/214001 [01:19<01:46, 1206.43it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86048/214001 [01:19<01:46, 1206.43it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86080/214001 [01:19<01:46, 1206.43it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86112/214001 [01:19<01:46, 1206.43it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86144/214001 [01:19<01:54, 1121.14it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86144/214001 [01:19<01:54, 1121.14it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86176/214001 [01:19<01:54, 1121.14it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86208/214001 [01:19<01:53, 1121.14it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86240/214001 [01:20<01:53, 1121.14it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86272/214001 [01:20<01:58, 1081.20it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86272/214001 [01:20<01:58, 1081.20it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86304/214001 [01:20<01:58, 1081.20it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86336/214001 [01:20<01:58, 1081.20it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86368/214001 [01:20<01:58, 1081.20it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86400/214001 [01:20<01:56, 1091.38it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86400/214001 [01:20<01:56, 1091.38it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86432/214001 [01:20<01:56, 1091.38it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86464/214001 [01:20<01:56, 1091.38it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86496/214001 [01:20<01:56, 1091.38it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86528/214001 [01:20<01:52, 1128.60it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86528/214001 [01:20<01:52, 1128.60it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86560/214001 [01:20<01:52, 1128.60it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86592/214001 [01:20<01:52, 1128.60it/s, train_loss=0.509]\u001b[A\n",
            "Epoch 1:  40%|████      | 86624/214001 [01:20<01:52, 1128.60it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86656/214001 [01:20<01:49, 1160.43it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  40%|████      | 86656/214001 [01:20<01:49, 1160.43it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86688/214001 [01:20<01:49, 1160.43it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86720/214001 [01:20<01:49, 1160.43it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86752/214001 [01:20<01:49, 1160.43it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86784/214001 [01:20<01:47, 1188.59it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86784/214001 [01:20<01:47, 1188.59it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86816/214001 [01:20<01:47, 1188.59it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86848/214001 [01:20<01:46, 1188.59it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86880/214001 [01:20<01:46, 1188.59it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86912/214001 [01:20<01:45, 1199.52it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86912/214001 [01:20<01:45, 1199.52it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86944/214001 [01:20<01:45, 1199.52it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 86976/214001 [01:20<01:45, 1199.52it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 87008/214001 [01:20<01:45, 1199.52it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  41%|████      | 87040/214001 [01:20<01:45, 1202.26it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  41%|████      | 87040/214001 [01:20<01:45, 1202.26it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 87072/214001 [01:20<01:45, 1202.26it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 87104/214001 [01:20<01:45, 1202.26it/s, train_loss=0.508]\u001b[A\n",
            "Epoch 1:  41%|████      | 87136/214001 [01:20<01:45, 1202.26it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  41%|████      | 87168/214001 [01:20<01:55, 1099.55it/s, train_loss=0.507]\u001b[A\n",
            "Epoch 1:  41%|████      | 87168/214001 [01:20<01:55, 1099.55it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87200/214001 [01:20<01:55, 1099.55it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87232/214001 [01:20<01:55, 1099.55it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87264/214001 [01:20<01:55, 1099.55it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87296/214001 [01:20<02:04, 1015.86it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87296/214001 [01:20<02:04, 1015.86it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87328/214001 [01:20<02:04, 1015.86it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87360/214001 [01:21<02:04, 1015.86it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87392/214001 [01:21<02:04, 1015.86it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87424/214001 [01:21<02:09, 980.06it/s, train_loss=0.505] \u001b[A\n",
            "Epoch 1:  41%|████      | 87424/214001 [01:21<02:09, 980.06it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87456/214001 [01:21<02:09, 980.06it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87488/214001 [01:21<02:09, 980.06it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 87520/214001 [01:21<02:09, 980.06it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 87552/214001 [01:21<02:11, 960.49it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 87552/214001 [01:21<02:11, 960.49it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87584/214001 [01:21<02:11, 960.49it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87616/214001 [01:21<02:11, 960.49it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87648/214001 [01:21<02:11, 960.49it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87680/214001 [01:21<02:12, 949.81it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87680/214001 [01:21<02:12, 949.81it/s, train_loss=0.506]\u001b[A\n",
            "Epoch 1:  41%|████      | 87712/214001 [01:21<02:12, 949.81it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87744/214001 [01:21<02:12, 949.81it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87776/214001 [01:21<02:12, 949.81it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87808/214001 [01:21<02:09, 972.71it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87808/214001 [01:21<02:09, 972.71it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 87840/214001 [01:21<02:09, 972.71it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87872/214001 [01:21<02:09, 972.71it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87904/214001 [01:21<02:09, 972.71it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87936/214001 [01:21<02:06, 995.00it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87936/214001 [01:21<02:06, 995.00it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 87968/214001 [01:21<02:06, 995.00it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  41%|████      | 88000/214001 [01:21<02:06, 995.00it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88032/214001 [01:21<02:06, 995.00it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88064/214001 [01:21<02:05, 999.90it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88064/214001 [01:21<02:05, 999.90it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88096/214001 [01:21<02:05, 999.90it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88128/214001 [01:21<02:05, 999.90it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88160/214001 [01:21<02:05, 999.90it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88192/214001 [01:21<02:05, 1000.30it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88192/214001 [01:21<02:05, 1000.30it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88224/214001 [01:21<02:05, 1000.30it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████      | 88256/214001 [01:21<02:05, 1000.30it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88288/214001 [01:21<02:05, 1000.30it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88320/214001 [01:21<02:05, 1002.96it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88320/214001 [01:22<02:05, 1002.96it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88352/214001 [01:22<02:05, 1002.96it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88384/214001 [01:22<02:05, 1002.96it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88416/214001 [01:22<02:05, 1002.96it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88448/214001 [01:22<02:00, 1038.94it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88448/214001 [01:22<02:00, 1038.94it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88480/214001 [01:22<02:00, 1038.94it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88512/214001 [01:22<02:00, 1038.94it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88544/214001 [01:22<02:00, 1038.94it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88576/214001 [01:22<02:00, 1038.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88576/214001 [01:22<02:00, 1038.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88608/214001 [01:22<02:00, 1038.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88640/214001 [01:22<02:00, 1038.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88672/214001 [01:22<02:00, 1038.17it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88704/214001 [01:22<01:56, 1073.05it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88704/214001 [01:22<01:56, 1073.05it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88736/214001 [01:22<01:56, 1073.05it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88768/214001 [01:22<01:56, 1073.05it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 88800/214001 [01:22<01:56, 1073.05it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88832/214001 [01:22<01:54, 1097.05it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88832/214001 [01:22<01:54, 1097.05it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88864/214001 [01:22<01:54, 1097.05it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88896/214001 [01:22<01:54, 1097.05it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88928/214001 [01:22<01:54, 1097.05it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88960/214001 [01:22<01:50, 1131.09it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88960/214001 [01:22<01:50, 1131.09it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 88992/214001 [01:22<01:50, 1131.09it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89024/214001 [01:22<01:50, 1131.09it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89056/214001 [01:22<01:50, 1131.09it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89088/214001 [01:22<01:51, 1120.87it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89088/214001 [01:22<01:51, 1120.87it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89120/214001 [01:22<01:51, 1120.87it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89152/214001 [01:22<01:51, 1120.87it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89184/214001 [01:22<01:51, 1120.87it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89216/214001 [01:22<01:52, 1106.50it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89216/214001 [01:22<01:52, 1106.50it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89248/214001 [01:22<01:52, 1106.50it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89280/214001 [01:22<01:52, 1106.50it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89312/214001 [01:22<01:52, 1106.50it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89344/214001 [01:22<01:48, 1147.98it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89344/214001 [01:22<01:48, 1147.98it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89376/214001 [01:22<01:48, 1147.98it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89408/214001 [01:22<01:48, 1147.98it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89440/214001 [01:22<01:48, 1147.98it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89472/214001 [01:22<01:48, 1148.43it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89472/214001 [01:23<01:48, 1148.43it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89504/214001 [01:23<01:48, 1148.43it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89536/214001 [01:23<01:48, 1148.43it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89568/214001 [01:23<01:48, 1148.43it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89600/214001 [01:23<01:53, 1098.11it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89600/214001 [01:23<01:53, 1098.11it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89632/214001 [01:23<01:53, 1098.11it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89664/214001 [01:23<01:53, 1098.11it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89696/214001 [01:23<01:53, 1098.11it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89728/214001 [01:23<01:53, 1093.52it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89728/214001 [01:23<01:53, 1093.52it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89760/214001 [01:23<01:53, 1093.52it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89792/214001 [01:23<01:53, 1093.52it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89824/214001 [01:23<01:53, 1093.52it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89856/214001 [01:23<01:50, 1119.15it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89856/214001 [01:23<01:50, 1119.15it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89888/214001 [01:23<01:50, 1119.15it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89920/214001 [01:23<01:50, 1119.15it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89952/214001 [01:23<01:50, 1119.15it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89984/214001 [01:23<01:48, 1139.04it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 89984/214001 [01:23<01:48, 1139.04it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90016/214001 [01:23<01:48, 1139.04it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90048/214001 [01:23<01:48, 1139.04it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90080/214001 [01:23<01:48, 1139.04it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90112/214001 [01:23<01:49, 1132.10it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90112/214001 [01:23<01:49, 1132.10it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90144/214001 [01:23<01:49, 1132.10it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90176/214001 [01:23<01:49, 1132.10it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90208/214001 [01:23<01:49, 1132.10it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90240/214001 [01:23<01:46, 1159.61it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90240/214001 [01:23<01:46, 1159.61it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90272/214001 [01:23<01:46, 1159.61it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90304/214001 [01:23<01:46, 1159.61it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90336/214001 [01:23<01:46, 1159.61it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90368/214001 [01:23<01:44, 1188.64it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90368/214001 [01:23<01:44, 1188.64it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90400/214001 [01:23<01:43, 1188.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90432/214001 [01:23<01:43, 1188.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90464/214001 [01:23<01:43, 1188.64it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90496/214001 [01:23<01:42, 1208.52it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90496/214001 [01:23<01:42, 1208.52it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90528/214001 [01:23<01:42, 1208.52it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90560/214001 [01:23<01:42, 1208.52it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90592/214001 [01:23<01:42, 1208.52it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90624/214001 [01:23<01:41, 1212.74it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90624/214001 [01:24<01:41, 1212.74it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90656/214001 [01:24<01:41, 1212.74it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90688/214001 [01:24<01:41, 1212.74it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90720/214001 [01:24<01:41, 1212.74it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90752/214001 [01:24<01:41, 1210.55it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90752/214001 [01:24<01:41, 1210.55it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90784/214001 [01:24<01:41, 1210.55it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90816/214001 [01:24<01:41, 1210.55it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90848/214001 [01:24<01:41, 1210.55it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90880/214001 [01:24<01:45, 1166.11it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90880/214001 [01:24<01:45, 1166.11it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90912/214001 [01:24<01:45, 1166.11it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 90944/214001 [01:24<01:45, 1166.11it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 90976/214001 [01:24<01:45, 1166.11it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91008/214001 [01:24<01:48, 1130.88it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91008/214001 [01:24<01:48, 1130.88it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91040/214001 [01:24<01:48, 1130.88it/s, train_loss=0.505]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91072/214001 [01:24<01:48, 1130.88it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91104/214001 [01:24<01:48, 1130.88it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91136/214001 [01:24<01:48, 1136.07it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91136/214001 [01:24<01:48, 1136.07it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91168/214001 [01:24<01:48, 1136.07it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91200/214001 [01:24<01:48, 1136.07it/s, train_loss=0.504]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91232/214001 [01:24<01:48, 1136.07it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91264/214001 [01:24<01:51, 1098.92it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91264/214001 [01:24<01:51, 1098.92it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91296/214001 [01:24<01:51, 1098.92it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91328/214001 [01:24<01:51, 1098.92it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91360/214001 [01:24<01:51, 1098.92it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91392/214001 [01:24<01:51, 1101.35it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91392/214001 [01:24<01:51, 1101.35it/s, train_loss=0.503]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91424/214001 [01:24<01:51, 1101.35it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91456/214001 [01:24<01:51, 1101.35it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91488/214001 [01:24<01:51, 1101.35it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91520/214001 [01:24<01:54, 1073.37it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91520/214001 [01:24<01:54, 1073.37it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91552/214001 [01:24<01:54, 1073.37it/s, train_loss=0.502]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91584/214001 [01:24<01:54, 1073.37it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91616/214001 [01:24<01:54, 1073.37it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91648/214001 [01:24<01:53, 1079.41it/s, train_loss=0.501]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91648/214001 [01:24<01:53, 1079.41it/s, train_loss=0.5]  \u001b[A\n",
            "Epoch 1:  43%|████▎     | 91680/214001 [01:24<01:53, 1079.41it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91712/214001 [01:25<01:53, 1079.41it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91744/214001 [01:25<01:53, 1079.41it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91776/214001 [01:25<01:51, 1095.00it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91776/214001 [01:25<01:51, 1095.00it/s, train_loss=0.5]  \u001b[A\n",
            "Epoch 1:  43%|████▎     | 91808/214001 [01:25<01:51, 1095.00it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91840/214001 [01:25<01:51, 1095.00it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91872/214001 [01:25<01:51, 1095.00it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91904/214001 [01:25<01:49, 1110.14it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91904/214001 [01:25<01:49, 1110.14it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 91936/214001 [01:25<01:49, 1110.14it/s, train_loss=0.5]  \u001b[A\n",
            "Epoch 1:  43%|████▎     | 91968/214001 [01:25<01:49, 1110.14it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92000/214001 [01:25<01:49, 1110.14it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92032/214001 [01:25<01:51, 1092.36it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92032/214001 [01:25<01:51, 1092.36it/s, train_loss=0.5]  \u001b[A\n",
            "Epoch 1:  43%|████▎     | 92064/214001 [01:25<01:51, 1092.36it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92096/214001 [01:25<01:51, 1092.36it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92128/214001 [01:25<01:51, 1092.36it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92160/214001 [01:25<01:50, 1100.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92160/214001 [01:25<01:50, 1100.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92192/214001 [01:25<01:50, 1100.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92224/214001 [01:25<01:50, 1100.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92256/214001 [01:25<01:50, 1100.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92288/214001 [01:25<01:49, 1110.14it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92288/214001 [01:25<01:49, 1110.14it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92320/214001 [01:25<01:49, 1110.14it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92352/214001 [01:25<01:49, 1110.14it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92384/214001 [01:25<01:49, 1110.14it/s, train_loss=0.5]  \u001b[A\n",
            "Epoch 1:  43%|████▎     | 92416/214001 [01:25<01:50, 1101.44it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92416/214001 [01:25<01:50, 1101.44it/s, train_loss=0.5]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92448/214001 [01:25<01:50, 1101.44it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92480/214001 [01:25<01:50, 1101.44it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92512/214001 [01:25<01:50, 1101.44it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92544/214001 [01:25<01:47, 1128.77it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92544/214001 [01:25<01:47, 1128.77it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92576/214001 [01:25<01:47, 1128.77it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92608/214001 [01:25<01:47, 1128.77it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92640/214001 [01:25<01:47, 1128.77it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92672/214001 [01:25<01:44, 1163.88it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92672/214001 [01:25<01:44, 1163.88it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92704/214001 [01:25<01:44, 1163.88it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92736/214001 [01:25<01:44, 1163.88it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92768/214001 [01:25<01:44, 1163.88it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92800/214001 [01:25<01:42, 1183.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92800/214001 [01:25<01:42, 1183.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92832/214001 [01:25<01:42, 1183.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92864/214001 [01:26<01:42, 1183.92it/s, train_loss=0.499]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92896/214001 [01:26<01:42, 1183.92it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92928/214001 [01:26<01:44, 1154.67it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92928/214001 [01:26<01:44, 1154.67it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92960/214001 [01:26<01:44, 1154.67it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 92992/214001 [01:26<01:44, 1154.67it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 93024/214001 [01:26<01:44, 1154.67it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 93056/214001 [01:26<01:45, 1147.96it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 93056/214001 [01:26<01:45, 1147.96it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 93088/214001 [01:26<01:45, 1147.96it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93120/214001 [01:26<01:45, 1147.96it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93152/214001 [01:26<01:45, 1147.96it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93184/214001 [01:26<01:44, 1161.29it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93184/214001 [01:26<01:44, 1161.29it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93216/214001 [01:26<01:44, 1161.29it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93248/214001 [01:26<01:43, 1161.29it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93280/214001 [01:26<01:43, 1161.29it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93312/214001 [01:26<01:43, 1162.46it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93312/214001 [01:26<01:43, 1162.46it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93344/214001 [01:26<01:43, 1162.46it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93376/214001 [01:26<01:43, 1162.46it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93408/214001 [01:26<01:43, 1162.46it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93440/214001 [01:26<01:41, 1187.73it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93440/214001 [01:26<01:41, 1187.73it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93472/214001 [01:26<01:41, 1187.73it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93504/214001 [01:26<01:41, 1187.73it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93536/214001 [01:26<01:41, 1187.73it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93568/214001 [01:26<01:40, 1197.66it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93568/214001 [01:26<01:40, 1197.66it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 93600/214001 [01:26<01:40, 1197.66it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93632/214001 [01:26<01:40, 1197.66it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93664/214001 [01:26<01:40, 1197.66it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93696/214001 [01:26<01:39, 1205.60it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93696/214001 [01:26<01:39, 1205.60it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93728/214001 [01:26<01:39, 1205.60it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93760/214001 [01:26<01:39, 1205.60it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93792/214001 [01:26<01:39, 1205.60it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93824/214001 [01:26<01:39, 1204.04it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93824/214001 [01:26<01:39, 1204.04it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93856/214001 [01:26<01:39, 1204.04it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93888/214001 [01:26<01:39, 1204.04it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93920/214001 [01:26<01:39, 1204.04it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93952/214001 [01:26<01:43, 1163.58it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93952/214001 [01:26<01:43, 1163.58it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 93984/214001 [01:26<01:43, 1163.58it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94016/214001 [01:26<01:43, 1163.58it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94048/214001 [01:27<01:43, 1163.58it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94080/214001 [01:27<01:43, 1159.68it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94080/214001 [01:27<01:43, 1159.68it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94112/214001 [01:27<01:43, 1159.68it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94144/214001 [01:27<01:43, 1159.68it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94176/214001 [01:27<01:43, 1159.68it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94208/214001 [01:27<01:44, 1149.49it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94208/214001 [01:27<01:44, 1149.49it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94240/214001 [01:27<01:44, 1149.49it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94272/214001 [01:27<01:44, 1149.49it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94304/214001 [01:27<01:44, 1149.49it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94336/214001 [01:27<01:43, 1153.50it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94336/214001 [01:27<01:43, 1153.50it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94368/214001 [01:27<01:43, 1153.50it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94400/214001 [01:27<01:43, 1153.50it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94432/214001 [01:27<01:43, 1153.50it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94464/214001 [01:27<01:43, 1155.13it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94464/214001 [01:27<01:43, 1155.13it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94496/214001 [01:27<01:43, 1155.13it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94528/214001 [01:27<01:43, 1155.13it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94560/214001 [01:27<01:43, 1155.13it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94592/214001 [01:27<01:42, 1161.43it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94592/214001 [01:27<01:42, 1161.43it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94624/214001 [01:27<01:42, 1161.43it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94656/214001 [01:27<01:42, 1161.43it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94688/214001 [01:27<01:42, 1161.43it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94720/214001 [01:27<01:42, 1167.61it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94720/214001 [01:27<01:42, 1167.61it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94752/214001 [01:27<01:42, 1167.61it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94784/214001 [01:27<01:42, 1167.61it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94816/214001 [01:27<01:42, 1167.61it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94848/214001 [01:27<01:43, 1150.91it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94848/214001 [01:27<01:43, 1150.91it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94880/214001 [01:27<01:43, 1150.91it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94912/214001 [01:27<01:43, 1150.91it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94944/214001 [01:27<01:43, 1150.91it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94976/214001 [01:27<01:43, 1151.61it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 94976/214001 [01:27<01:43, 1151.61it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95008/214001 [01:27<01:43, 1151.61it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95040/214001 [01:27<01:43, 1151.61it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95072/214001 [01:27<01:43, 1151.61it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95104/214001 [01:27<01:45, 1123.82it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95104/214001 [01:27<01:45, 1123.82it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95136/214001 [01:27<01:45, 1123.82it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95168/214001 [01:28<01:45, 1123.82it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 95200/214001 [01:28<01:45, 1123.82it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95232/214001 [01:28<01:46, 1113.63it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95232/214001 [01:28<01:46, 1113.63it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95264/214001 [01:28<01:46, 1113.63it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95296/214001 [01:28<01:46, 1113.63it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95328/214001 [01:28<01:46, 1113.63it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95360/214001 [01:28<01:43, 1142.27it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95360/214001 [01:28<01:43, 1142.27it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95392/214001 [01:28<01:43, 1142.27it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95424/214001 [01:28<01:43, 1142.27it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95456/214001 [01:28<01:43, 1142.27it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95488/214001 [01:28<01:41, 1167.87it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95488/214001 [01:28<01:41, 1167.87it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95520/214001 [01:28<01:41, 1167.87it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95552/214001 [01:28<01:41, 1167.87it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95584/214001 [01:28<01:41, 1167.87it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95616/214001 [01:28<01:39, 1187.97it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95616/214001 [01:28<01:39, 1187.97it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95648/214001 [01:28<01:39, 1187.97it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95680/214001 [01:28<01:39, 1187.97it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95712/214001 [01:28<01:39, 1187.97it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95744/214001 [01:28<01:40, 1179.68it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95744/214001 [01:28<01:40, 1179.68it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95776/214001 [01:28<01:40, 1179.68it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95808/214001 [01:28<01:40, 1179.68it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95840/214001 [01:28<01:40, 1179.68it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95872/214001 [01:28<01:39, 1186.94it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95872/214001 [01:28<01:39, 1186.94it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95904/214001 [01:28<01:39, 1186.94it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95936/214001 [01:28<01:39, 1186.94it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 95968/214001 [01:28<01:39, 1186.94it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96000/214001 [01:28<01:38, 1196.03it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96000/214001 [01:28<01:38, 1196.03it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96032/214001 [01:28<01:38, 1196.03it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96064/214001 [01:28<01:38, 1196.03it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96096/214001 [01:28<01:38, 1196.03it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96128/214001 [01:28<01:37, 1212.85it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96128/214001 [01:28<01:37, 1212.85it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96160/214001 [01:28<01:37, 1212.85it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96192/214001 [01:28<01:37, 1212.85it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96224/214001 [01:28<01:37, 1212.85it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96256/214001 [01:28<01:36, 1223.27it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96256/214001 [01:28<01:36, 1223.27it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 96288/214001 [01:28<01:36, 1223.27it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96320/214001 [01:28<01:36, 1223.27it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96352/214001 [01:28<01:36, 1223.27it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96384/214001 [01:28<01:36, 1225.03it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96384/214001 [01:29<01:36, 1225.03it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96416/214001 [01:29<01:35, 1225.03it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96448/214001 [01:29<01:35, 1225.03it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96480/214001 [01:29<01:35, 1225.03it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96512/214001 [01:29<01:35, 1233.18it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96512/214001 [01:29<01:35, 1233.18it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96544/214001 [01:29<01:35, 1233.18it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96576/214001 [01:29<01:35, 1233.18it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96608/214001 [01:29<01:35, 1233.18it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96640/214001 [01:29<01:38, 1193.50it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96640/214001 [01:29<01:38, 1193.50it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96672/214001 [01:29<01:38, 1193.50it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96704/214001 [01:29<01:38, 1193.50it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96736/214001 [01:29<01:38, 1193.50it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96768/214001 [01:29<01:41, 1157.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96768/214001 [01:29<01:41, 1157.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96800/214001 [01:29<01:41, 1157.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96832/214001 [01:29<01:41, 1157.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96864/214001 [01:29<01:41, 1157.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96896/214001 [01:29<01:40, 1168.44it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96896/214001 [01:29<01:40, 1168.44it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96928/214001 [01:29<01:40, 1168.44it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96960/214001 [01:29<01:40, 1168.44it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 96992/214001 [01:29<01:40, 1168.44it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97024/214001 [01:29<01:40, 1164.73it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97024/214001 [01:29<01:40, 1164.73it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97056/214001 [01:29<01:40, 1164.73it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97088/214001 [01:29<01:40, 1164.73it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97120/214001 [01:29<01:40, 1164.73it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97152/214001 [01:29<01:40, 1164.21it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97152/214001 [01:29<01:40, 1164.21it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97184/214001 [01:29<01:40, 1164.21it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97216/214001 [01:29<01:40, 1164.21it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97248/214001 [01:29<01:40, 1164.21it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97280/214001 [01:29<01:43, 1125.61it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97280/214001 [01:29<01:43, 1125.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97312/214001 [01:29<01:43, 1125.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 97344/214001 [01:29<01:43, 1125.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97376/214001 [01:29<01:43, 1125.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97408/214001 [01:29<01:44, 1113.64it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97408/214001 [01:29<01:44, 1113.64it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97440/214001 [01:29<01:44, 1113.64it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97472/214001 [01:29<01:44, 1113.64it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97504/214001 [01:29<01:44, 1113.64it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97536/214001 [01:30<01:46, 1095.49it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97536/214001 [01:30<01:46, 1095.49it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97568/214001 [01:30<01:46, 1095.49it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97600/214001 [01:30<01:46, 1095.49it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97632/214001 [01:30<01:46, 1095.49it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97664/214001 [01:30<01:43, 1129.30it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97664/214001 [01:30<01:43, 1129.30it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97696/214001 [01:30<01:42, 1129.30it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97728/214001 [01:30<01:42, 1129.30it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97760/214001 [01:30<01:42, 1129.30it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97792/214001 [01:30<01:40, 1153.29it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97792/214001 [01:30<01:40, 1153.29it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97824/214001 [01:30<01:40, 1153.29it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97856/214001 [01:30<01:40, 1153.29it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97888/214001 [01:30<01:40, 1153.29it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97920/214001 [01:30<01:38, 1175.24it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97920/214001 [01:30<01:38, 1175.24it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97952/214001 [01:30<01:38, 1175.24it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 97984/214001 [01:30<01:38, 1175.24it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98016/214001 [01:30<01:38, 1175.24it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98048/214001 [01:30<01:37, 1193.28it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98048/214001 [01:30<01:37, 1193.28it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98080/214001 [01:30<01:37, 1193.28it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98112/214001 [01:30<01:37, 1193.28it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98144/214001 [01:30<01:37, 1193.28it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98176/214001 [01:30<01:40, 1149.70it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98176/214001 [01:30<01:40, 1149.70it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98208/214001 [01:30<01:40, 1149.70it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98240/214001 [01:30<01:40, 1149.70it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98272/214001 [01:30<01:40, 1149.70it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98304/214001 [01:30<01:39, 1161.45it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98304/214001 [01:30<01:39, 1161.45it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98336/214001 [01:30<01:39, 1161.45it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98368/214001 [01:30<01:39, 1161.45it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98400/214001 [01:30<01:39, 1161.45it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98432/214001 [01:30<01:38, 1168.53it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98432/214001 [01:30<01:38, 1168.53it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98464/214001 [01:30<01:38, 1168.53it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98496/214001 [01:30<01:38, 1168.53it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98528/214001 [01:30<01:38, 1168.53it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98560/214001 [01:30<01:38, 1166.78it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98560/214001 [01:30<01:38, 1166.78it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98592/214001 [01:30<01:38, 1166.78it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98624/214001 [01:30<01:38, 1166.78it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98656/214001 [01:30<01:38, 1166.78it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98688/214001 [01:30<01:40, 1145.74it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98688/214001 [01:31<01:40, 1145.74it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98720/214001 [01:31<01:40, 1145.74it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98752/214001 [01:31<01:40, 1145.74it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98784/214001 [01:31<01:40, 1145.74it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98816/214001 [01:31<01:41, 1130.10it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98816/214001 [01:31<01:41, 1130.10it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98848/214001 [01:31<01:41, 1130.10it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98880/214001 [01:31<01:41, 1130.10it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98912/214001 [01:31<01:41, 1130.10it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98944/214001 [01:31<01:40, 1139.87it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 98944/214001 [01:31<01:40, 1139.87it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 98976/214001 [01:31<01:40, 1139.87it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99008/214001 [01:31<01:40, 1139.87it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99040/214001 [01:31<01:40, 1139.87it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99072/214001 [01:31<01:39, 1158.82it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99072/214001 [01:31<01:39, 1158.82it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99104/214001 [01:31<01:39, 1158.82it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99136/214001 [01:31<01:39, 1158.82it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99168/214001 [01:31<01:39, 1158.82it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99200/214001 [01:31<01:37, 1174.25it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99200/214001 [01:31<01:37, 1174.25it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99232/214001 [01:31<01:37, 1174.25it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99264/214001 [01:31<01:37, 1174.25it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99296/214001 [01:31<01:37, 1174.25it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99328/214001 [01:31<01:38, 1165.15it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99328/214001 [01:31<01:38, 1165.15it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99360/214001 [01:31<01:38, 1165.15it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99392/214001 [01:31<01:38, 1165.15it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99424/214001 [01:31<01:38, 1165.15it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99456/214001 [01:31<01:39, 1146.34it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99456/214001 [01:31<01:39, 1146.34it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 99488/214001 [01:31<01:39, 1146.34it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99520/214001 [01:31<01:39, 1146.34it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99552/214001 [01:31<01:39, 1146.34it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99584/214001 [01:31<01:41, 1123.23it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99584/214001 [01:31<01:41, 1123.23it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99616/214001 [01:31<01:41, 1123.23it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99648/214001 [01:31<01:41, 1123.23it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99680/214001 [01:31<01:41, 1123.23it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99712/214001 [01:31<01:44, 1093.46it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99712/214001 [01:31<01:44, 1093.46it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99744/214001 [01:31<01:44, 1093.46it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99776/214001 [01:31<01:44, 1093.46it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99808/214001 [01:31<01:44, 1093.46it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99840/214001 [01:32<01:41, 1121.78it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99840/214001 [01:32<01:41, 1121.78it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99872/214001 [01:32<01:41, 1121.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99904/214001 [01:32<01:41, 1121.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99936/214001 [01:32<01:41, 1121.78it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99968/214001 [01:32<01:39, 1149.84it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 99968/214001 [01:32<01:39, 1149.84it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100000/214001 [01:32<01:39, 1149.84it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100032/214001 [01:32<01:39, 1149.84it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100064/214001 [01:32<01:39, 1149.84it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100096/214001 [01:32<01:38, 1155.02it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100096/214001 [01:32<01:38, 1155.02it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100128/214001 [01:32<01:38, 1155.02it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100160/214001 [01:32<01:38, 1155.02it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100192/214001 [01:32<01:38, 1155.02it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100224/214001 [01:32<01:41, 1124.96it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100224/214001 [01:32<01:41, 1124.96it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100256/214001 [01:32<01:41, 1124.96it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100288/214001 [01:32<01:41, 1124.96it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100320/214001 [01:32<01:41, 1124.96it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100352/214001 [01:32<01:44, 1091.08it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100352/214001 [01:32<01:44, 1091.08it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100384/214001 [01:32<01:44, 1091.08it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100416/214001 [01:32<01:44, 1091.08it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100448/214001 [01:32<01:44, 1091.08it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100480/214001 [01:32<01:43, 1096.28it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100480/214001 [01:32<01:43, 1096.28it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100512/214001 [01:32<01:43, 1096.28it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100544/214001 [01:32<01:43, 1096.28it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100576/214001 [01:32<01:43, 1096.28it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100608/214001 [01:32<01:42, 1111.60it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100608/214001 [01:32<01:42, 1111.60it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100640/214001 [01:32<01:41, 1111.60it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100672/214001 [01:32<01:41, 1111.60it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100704/214001 [01:32<01:41, 1111.60it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100736/214001 [01:32<01:44, 1086.07it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100736/214001 [01:32<01:44, 1086.07it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100768/214001 [01:32<01:44, 1086.07it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100800/214001 [01:32<01:44, 1086.07it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100832/214001 [01:32<01:44, 1086.07it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100864/214001 [01:32<01:48, 1047.53it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100864/214001 [01:32<01:48, 1047.53it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100896/214001 [01:33<01:47, 1047.53it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100928/214001 [01:33<01:47, 1047.53it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100960/214001 [01:33<01:47, 1047.53it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100992/214001 [01:33<01:46, 1061.19it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 100992/214001 [01:33<01:46, 1061.19it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101024/214001 [01:33<01:46, 1061.19it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101056/214001 [01:33<01:46, 1061.19it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101088/214001 [01:33<01:46, 1061.19it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101120/214001 [01:33<01:43, 1085.95it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101120/214001 [01:33<01:43, 1085.95it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101152/214001 [01:33<01:43, 1085.95it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101184/214001 [01:33<01:43, 1085.95it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101216/214001 [01:33<01:43, 1085.95it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101248/214001 [01:33<01:41, 1111.93it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101248/214001 [01:33<01:41, 1111.93it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101280/214001 [01:33<01:41, 1111.93it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101312/214001 [01:33<01:41, 1111.93it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101344/214001 [01:33<01:41, 1111.93it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101376/214001 [01:33<01:38, 1142.13it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101376/214001 [01:33<01:38, 1142.13it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101408/214001 [01:33<01:38, 1142.13it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101440/214001 [01:33<01:38, 1142.13it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101472/214001 [01:33<01:38, 1142.13it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101504/214001 [01:33<01:37, 1158.19it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101504/214001 [01:33<01:37, 1158.19it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101536/214001 [01:33<01:37, 1158.19it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101568/214001 [01:33<01:37, 1158.19it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101600/214001 [01:33<01:37, 1158.19it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101632/214001 [01:33<01:40, 1119.58it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 101632/214001 [01:33<01:40, 1119.58it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101664/214001 [01:33<01:40, 1119.58it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101696/214001 [01:33<01:40, 1119.58it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101728/214001 [01:33<01:40, 1119.58it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101760/214001 [01:33<01:40, 1112.51it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101760/214001 [01:33<01:40, 1112.51it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101792/214001 [01:33<01:40, 1112.51it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101824/214001 [01:33<01:40, 1112.51it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101856/214001 [01:33<01:40, 1112.51it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101888/214001 [01:33<01:39, 1122.86it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101888/214001 [01:33<01:39, 1122.86it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101920/214001 [01:33<01:39, 1122.86it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101952/214001 [01:33<01:39, 1122.86it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 101984/214001 [01:33<01:39, 1122.86it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102016/214001 [01:33<01:40, 1110.37it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102016/214001 [01:33<01:40, 1110.37it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102048/214001 [01:34<01:40, 1110.37it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102080/214001 [01:34<01:40, 1110.37it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102112/214001 [01:34<01:40, 1110.37it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102144/214001 [01:34<01:39, 1121.37it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102144/214001 [01:34<01:39, 1121.37it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102176/214001 [01:34<01:39, 1121.37it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102208/214001 [01:34<01:39, 1121.37it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102240/214001 [01:34<01:39, 1121.37it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102272/214001 [01:34<01:39, 1120.17it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102272/214001 [01:34<01:39, 1120.17it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102304/214001 [01:34<01:39, 1120.17it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102336/214001 [01:34<01:39, 1120.17it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102368/214001 [01:34<01:39, 1120.17it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102400/214001 [01:34<01:42, 1089.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102400/214001 [01:34<01:42, 1089.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102432/214001 [01:34<01:42, 1089.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102464/214001 [01:34<01:42, 1089.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102496/214001 [01:34<01:42, 1089.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102528/214001 [01:34<01:44, 1064.29it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102528/214001 [01:34<01:44, 1064.29it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102560/214001 [01:34<01:44, 1064.29it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102592/214001 [01:34<01:44, 1064.29it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102624/214001 [01:34<01:44, 1064.29it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102656/214001 [01:34<01:47, 1039.58it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102656/214001 [01:34<01:47, 1039.58it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102688/214001 [01:34<01:47, 1039.58it/s, train_loss=0.493]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102720/214001 [01:34<01:47, 1039.58it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102752/214001 [01:34<01:47, 1039.58it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102784/214001 [01:34<01:47, 1037.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102784/214001 [01:34<01:47, 1037.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102816/214001 [01:34<01:47, 1037.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102848/214001 [01:34<01:47, 1037.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102880/214001 [01:34<01:47, 1037.05it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102912/214001 [01:34<01:53, 982.99it/s, train_loss=0.494] \u001b[A\n",
            "Epoch 1:  48%|████▊     | 102912/214001 [01:34<01:53, 982.99it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102944/214001 [01:34<01:52, 982.99it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 102976/214001 [01:34<01:52, 982.99it/s, train_loss=0.494]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103008/214001 [01:34<01:52, 982.99it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103040/214001 [01:34<01:52, 987.90it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103040/214001 [01:35<01:52, 987.90it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103072/214001 [01:35<01:52, 987.90it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103104/214001 [01:35<01:52, 987.90it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103136/214001 [01:35<01:52, 987.90it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103168/214001 [01:35<01:53, 975.25it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103168/214001 [01:35<01:53, 975.25it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103200/214001 [01:35<01:53, 975.25it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103232/214001 [01:35<01:53, 975.25it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103264/214001 [01:35<01:53, 975.25it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103296/214001 [01:35<01:59, 928.76it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103296/214001 [01:35<01:59, 928.76it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103328/214001 [01:35<01:59, 928.76it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103360/214001 [01:35<01:59, 928.76it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103392/214001 [01:35<02:00, 919.09it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103392/214001 [01:35<02:00, 919.09it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103424/214001 [01:35<02:00, 919.09it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103456/214001 [01:35<02:00, 919.09it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103488/214001 [01:35<02:00, 919.09it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103520/214001 [01:35<01:57, 940.77it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103520/214001 [01:35<01:57, 940.77it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103552/214001 [01:35<01:57, 940.77it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103584/214001 [01:35<01:57, 940.77it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103616/214001 [01:35<01:57, 937.76it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103616/214001 [01:35<01:57, 937.76it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103648/214001 [01:35<01:57, 937.76it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103680/214001 [01:35<01:57, 937.76it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103712/214001 [01:35<01:59, 924.99it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103712/214001 [01:35<01:59, 924.99it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103744/214001 [01:35<01:59, 924.99it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 103776/214001 [01:35<01:59, 924.99it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103808/214001 [01:35<01:58, 926.88it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103808/214001 [01:35<01:58, 926.88it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103840/214001 [01:35<01:58, 926.88it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103872/214001 [01:35<01:58, 926.88it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103904/214001 [01:35<02:00, 914.13it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103904/214001 [01:35<02:00, 914.13it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103936/214001 [01:35<02:00, 914.13it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 103968/214001 [01:36<02:00, 914.13it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104000/214001 [01:36<02:01, 908.22it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104000/214001 [01:36<02:01, 908.22it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104032/214001 [01:36<02:01, 908.22it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104064/214001 [01:36<02:01, 908.22it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104096/214001 [01:36<02:01, 908.22it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104128/214001 [01:36<01:54, 958.11it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104128/214001 [01:36<01:54, 958.11it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104160/214001 [01:36<01:54, 958.11it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104192/214001 [01:36<01:54, 958.11it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104224/214001 [01:36<01:54, 958.11it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104256/214001 [01:36<01:47, 1020.68it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104256/214001 [01:36<01:47, 1020.68it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104288/214001 [01:36<01:47, 1020.68it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 104320/214001 [01:36<01:47, 1020.68it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104352/214001 [01:36<01:47, 1020.68it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104384/214001 [01:36<01:47, 1020.68it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104416/214001 [01:36<01:38, 1111.55it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104416/214001 [01:36<01:38, 1111.55it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104448/214001 [01:36<01:38, 1111.55it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104480/214001 [01:36<01:38, 1111.55it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104512/214001 [01:36<01:38, 1111.55it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104544/214001 [01:36<01:34, 1157.07it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104544/214001 [01:36<01:34, 1157.07it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104576/214001 [01:36<01:34, 1157.07it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104608/214001 [01:36<01:34, 1157.07it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104640/214001 [01:36<01:34, 1157.07it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104672/214001 [01:36<01:34, 1157.07it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104704/214001 [01:36<01:30, 1203.07it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104704/214001 [01:36<01:30, 1203.07it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104736/214001 [01:36<01:30, 1203.07it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104768/214001 [01:36<01:30, 1203.07it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104800/214001 [01:36<01:30, 1203.07it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104832/214001 [01:36<01:29, 1219.14it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104832/214001 [01:36<01:29, 1219.14it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104864/214001 [01:36<01:29, 1219.14it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104896/214001 [01:36<01:29, 1219.14it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104928/214001 [01:36<01:29, 1219.14it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104960/214001 [01:36<01:30, 1201.92it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104960/214001 [01:36<01:30, 1201.92it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 104992/214001 [01:36<01:30, 1201.92it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105024/214001 [01:36<01:30, 1201.92it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105056/214001 [01:36<01:30, 1201.92it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105088/214001 [01:36<01:31, 1186.02it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105088/214001 [01:36<01:31, 1186.02it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105120/214001 [01:36<01:31, 1186.02it/s, train_loss=0.498]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105152/214001 [01:37<01:31, 1186.02it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105184/214001 [01:37<01:31, 1186.02it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105216/214001 [01:37<01:31, 1185.48it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105216/214001 [01:37<01:31, 1185.48it/s, train_loss=0.497]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105248/214001 [01:37<01:31, 1185.48it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105280/214001 [01:37<01:31, 1185.48it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105312/214001 [01:37<01:31, 1185.48it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105344/214001 [01:37<01:29, 1207.35it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105344/214001 [01:37<01:29, 1207.35it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105376/214001 [01:37<01:29, 1207.35it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105408/214001 [01:37<01:29, 1207.35it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105440/214001 [01:37<01:29, 1207.35it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105472/214001 [01:37<01:34, 1145.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105472/214001 [01:37<01:34, 1145.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105504/214001 [01:37<01:34, 1145.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105536/214001 [01:37<01:34, 1145.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105568/214001 [01:37<01:34, 1145.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105600/214001 [01:37<01:34, 1149.40it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105600/214001 [01:37<01:34, 1149.40it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105632/214001 [01:37<01:34, 1149.40it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105664/214001 [01:37<01:34, 1149.40it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105696/214001 [01:37<01:34, 1149.40it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105728/214001 [01:37<01:32, 1165.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105728/214001 [01:37<01:32, 1165.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105760/214001 [01:37<01:32, 1165.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105792/214001 [01:37<01:32, 1165.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105824/214001 [01:37<01:32, 1165.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105856/214001 [01:37<01:32, 1165.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105888/214001 [01:37<01:29, 1205.17it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105888/214001 [01:37<01:29, 1205.17it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 105920/214001 [01:37<01:29, 1205.17it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 105952/214001 [01:37<01:29, 1205.17it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 105984/214001 [01:37<01:29, 1205.17it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106016/214001 [01:37<01:28, 1214.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106016/214001 [01:37<01:28, 1214.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106048/214001 [01:37<01:28, 1214.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106080/214001 [01:37<01:28, 1214.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106112/214001 [01:37<01:28, 1214.61it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106144/214001 [01:37<01:30, 1197.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106144/214001 [01:37<01:30, 1197.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106176/214001 [01:37<01:30, 1197.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106208/214001 [01:37<01:29, 1197.92it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106240/214001 [01:37<01:29, 1197.92it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106272/214001 [01:37<01:32, 1166.04it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106272/214001 [01:37<01:32, 1166.04it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106304/214001 [01:37<01:32, 1166.04it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106336/214001 [01:38<01:32, 1166.04it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106368/214001 [01:38<01:32, 1166.04it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106400/214001 [01:38<01:32, 1168.13it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106400/214001 [01:38<01:32, 1168.13it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106432/214001 [01:38<01:32, 1168.13it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106464/214001 [01:38<01:32, 1168.13it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106496/214001 [01:38<01:32, 1168.13it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106528/214001 [01:38<01:30, 1193.23it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106528/214001 [01:38<01:30, 1193.23it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106560/214001 [01:38<01:30, 1193.23it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106592/214001 [01:38<01:30, 1193.23it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106624/214001 [01:38<01:29, 1193.23it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106656/214001 [01:38<01:29, 1196.28it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106656/214001 [01:38<01:29, 1196.28it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106688/214001 [01:38<01:29, 1196.28it/s, train_loss=0.495]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106720/214001 [01:38<01:29, 1196.28it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106752/214001 [01:38<01:29, 1196.28it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106784/214001 [01:38<01:28, 1205.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106784/214001 [01:38<01:28, 1205.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106816/214001 [01:38<01:28, 1205.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106848/214001 [01:38<01:28, 1205.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106880/214001 [01:38<01:28, 1205.92it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106912/214001 [01:38<01:27, 1223.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106912/214001 [01:38<01:27, 1223.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 106944/214001 [01:38<01:27, 1223.98it/s, train_loss=0.496]\u001b[A\n",
            "Epoch 1:  50%|█████     | 107008/214001 [01:38<01:38, 1086.01it/s, train_loss=0.496]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.602, test - 0.480\n",
            "F1 test - 0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  50%|█████     | 107008/214001 [01:24<01:24, 1272.93it/s, train_loss=0.464]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.472, test - 0.464\n",
            "F1 test - 0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  50%|█████     | 107008/214001 [01:21<01:21, 1319.54it/s, train_loss=0.444]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.450, test - 0.458\n",
            "F1 test - 0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  50%|█████     | 107008/214001 [01:21<01:21, 1307.47it/s, train_loss=0.426]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.432, test - 0.457\n",
            "F1 test - 0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  50%|█████     | 107008/214001 [01:19<01:19, 1338.61it/s, train_loss=0.405]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.412, test - 0.461\n",
            "F1 test - 0.833\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "\n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.transpose(0, 1).to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for x, y in validation_loader:\n",
        "\n",
        "        x = x.transpose(0, 1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "\n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "\n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "\n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TMaPbh3oWwc"
      },
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_aPjTQcR0vm2",
        "outputId": "03d584f8-2f8c-4e0b-ae8e-7112f6624275"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db_JqhnTIjBm"
      },
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эксперимент - увеличение количества параметров"
      ],
      "metadata": {
        "id": "g2DKfpbZPeT3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "e5BgHdtW2sO3"
      },
      "outputs": [],
      "source": [
        "model = model_with_att(vectors, n_classes, hidden_size=400)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bb2e90-a76d-49d0-df5e-58a2462dcf5a",
        "id": "LepppG1NUYFp"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  50%|█████     | 107008/214001 [03:25<03:25, 520.55it/s, train_loss=0.496]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.589, test - 0.484\n",
            "F1 test - 0.825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  50%|█████     | 107008/214001 [03:27<03:27, 514.54it/s, train_loss=0.466]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.473, test - 0.463\n",
            "F1 test - 0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  50%|█████     | 107008/214001 [03:29<03:28, 511.97it/s, train_loss=0.445]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.449, test - 0.457\n",
            "F1 test - 0.835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  50%|█████     | 107008/214001 [03:28<03:28, 513.44it/s, train_loss=0.424]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.430, test - 0.463\n",
            "F1 test - 0.835\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "\n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.transpose(0, 1).to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for x, y in validation_loader:\n",
        "\n",
        "        x = x.transpose(0, 1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "\n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "\n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "\n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}